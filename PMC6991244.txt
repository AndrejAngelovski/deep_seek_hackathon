
==== Front
JAMA Netw OpenJAMA Netw OpenJAMA Netw OpenJAMA Network Open2574-3805American Medical Association 10.1001/jamanetworkopen.2019.18377zoi190693ResearchOriginal InvestigationOnline OnlyPsychiatryUse of Machine Learning for Predicting Escitalopram Treatment Outcome From Electroencephalography Recordings in Adult Patients With Depression Machine Learning to Predict Escitalopram Outcome From Electroencephalography RecordingsMachine Learning to Predict Escitalopram Outcome From Electroencephalography RecordingsZhdanov Andrey PhD12Atluri Sravya PhD34Wong Willy PhD5Vaghei Yasaman MSc12Daskalakis Zafiris J. MDPhD367Blumberger Daniel M. MD367Frey Benicio N. MDPhD89Giacobbe Peter MD610Lam Raymond W. MD11Milev Roumen MDPhD12Mueller Daniel J. MDPhD36Turecki Gustavo MDPhD13Parikh Sagar V. MD14Rotzinger Susan PhD61015Soares Claudio N. MDPhD1516Brenner Colleen A. PhD17Vila-Rodriguez Fidel MDPhD11McAndrews Mary Pat PhD18Kleffner Killian MSc11Alonso-Prieto Esther PhD11Arnott Stephen R. PhD19Foster Jane A. PhD820Strother Stephen C. PhD1921Uher Rudolf MDPhD2223Kennedy Sidney H. MD6710151820Farzan Faranak PhD123671 School of Mechatronic Systems Engineering, Simon Fraser University, Surrey, British Columbia, Canada2 Centre for Engineering-Led Brain Research, Simon Fraser University, Surrey, British Columbia, Canada3 Temerty Centre for Therapeutic Brain Intervention, Centre for Addiction and Mental Health, Toronto, Ontario, Canada4 Institute of Biomaterial and Biomedical Engineering, Toronto, Ontario, Canada5 The Edward S. Rogers Sr Department of Electrical & Computer Engineering, University of Toronto, Toronto, Ontario, Canada6 Department of Psychiatry, University of Toronto, Toronto, Ontario, Canada7 Institute of Medical Science, Faculty of Medicine, University of Toronto, Toronto, Ontario, Canada8 Department of Psychiatry and Behavioural Neurosciences, McMaster University, Hamilton, Ontario, Canada9 Mood Disorders Program and Women’s Health Concerns Clinic, St Joseph’s Healthcare Hamilton, Hamilton, Ontario, Canada10 Department of Psychiatry, University Health Network, University of Toronto, Toronto, Ontario, Canada11 Department of Psychiatry, University of British Columbia, Vancouver, British Columbia, Canada12 Departments of Psychiatry and Psychology, Queen’s University, Providence Care Hospital, Kingston, Ontario, Canada13 Department of Psychiatry, McGill University, Montreal, Quebec, Canada14 Department of Psychiatry, University of Michigan, Ann Arbor15 Li Ka Shing Knowledge Institute, St Michael's Hospital, Toronto, Ontario, Canada16 Department of Psychiatry, Queen’s University, Kingston, Ontario, Canada17 Department of Psychology, Loma Linda University, Loma Linda, California18 Krembil Research Institute, University Health Network, Toronto, Ontario, Canada19 Rotman Research Institute, Baycrest Centre, Toronto, Ontario, Canada20 St Michael’s Hospital, Toronto, Ontario, Canada21 Department of Medical Biophysics, University of Toronto, Toronto, Ontario, Canada22 Department of Psychiatry, Dalhousie University, Halifax, Nova Scotia, Canada23 Institute of Psychiatry, Psychology & Neuroscience, Social, Genetic and Developmental Psychiatry Centre, King’s College London, London, United KingdomArticle Information
Accepted for Publication: November 4, 2019.

Published: January 3, 2020. doi:10.1001/jamanetworkopen.2019.18377

Open Access: This is an open access article distributed under the terms of the CC-BY License. © 2020 Zhdanov A et al. JAMA Network Open.

Corresponding Author: Faranak Farzan, PhD, School of Mechatronic Systems Engineering, Simon Fraser University, 250-13450 102 Ave, Rm 4138, Surrey, BC V3T0A3, Canada (ffarzan@sfu.ca).Author Contributions: Drs Zhdanov and Atluri are co–first authors and contributed equally to this work. Drs Zhdanov and Atluri had full access to all the data in the study and take responsibility for the integrity of the data and the accuracy of the data analysis.

Concept and design: Atluri, Daskalakis, Frey, Giacobbe, Lam, Milev, Mueller, Parikh, Rotzinger, McAndrews, Foster, Strother, Uher, Kennedy, Farzan.

Acquisition, analysis, or interpretation of data: Zhdanov, Atluri, Wong, Vaghei, Daskalakis, Blumberger, Frey, Lam, Milev, Turecki, Rotzinger, Soares, Brenner, Vila-Rodriguez, McAndrews, Kleffner, Alonso-Prieto, Arnott, Foster, Farzan.

Drafting of the manuscript: Zhdanov, Atluri, Daskalakis, Milev, Mueller, Alonso-Prieto, Farzan.

Critical revision of the manuscript for important intellectual content: All authors.

Statistical analysis: Zhdanov, Atluri, Wong, Mueller, Kleffner, Strother.

Obtained funding: Daskalakis, Frey, Lam, Milev, Turecki, Rotzinger, Soares, Kennedy, Farzan.

Administrative, technical, or material support: Atluri, Vaghei, Daskalakis, Blumberger, Giacobbe, Lam, Milev, Turecki, Parikh, Rotzinger, Vila-Rodriguez, McAndrews, Alonso-Prieto, Arnott, Foster, Kennedy.

Supervision: Wong, Daskalakis, Frey, Milev, Soares, Kennedy, Farzan.

Conflict of Interest Disclosures: Dr Daskalakis reported receiving grants from Brainsway Inc and Magventure Inc during the conduct of the study. Dr Blumberger reported receiving grants from Brain Canada during the conduct of the study and receiving grants from Brainsway and the Canadian Institutes of Health Research and nonfinancial support from Magventure outside the submitted work. Dr Frey reported receiving grants from Pfizer outside the submitted work. Dr Lam reported receiving grants from the Canadian Institutes of Health Research, University Health Network Foundation, and Ontario Brain Institute during the conduct of the study and receiving personal fees from Allergan, Akili, CME Institute, the Canadian Network for Mood and Anxiety Treatments, Janssen, Lundbeck, Lundbeck Institute, Pfizer, Otsuka, Medscape, and Hansoh and receiving grants from Asia-Pacific Economic Cooperation, VGH-UBC Foundation, BC Leading Edge Endowment Fund, Janssen, Lundbeck, Lundbeck Institute, Pfizer, and St Jude Medical outside the submitted work. Dr Milev reported receiving grants from Ontario Brain Institute during the conduct of the study and receiving personal fees from Allergan, Janssen, Kye, Lundbeck, Otsuka, and Pfizer; and receiving grants from Lallemand, Lundbeck, Nubyiota, and Pfizer outside the submitted work. Dr Parikh reported receiving grants from Assurex and Takeda and receiving personal fees from Assurex, Takeda, Mensante, Sunovion, and Lundbeck outside the submitted work. Dr Rotzinger reported receiving grants from Ontario Brain Institute and the Canadian Institutes of Health Research during the conduct of the study and having a patent to Teneurin C-Terminal Associated Peptides and Methods and Uses Thereof issued. Dr Soares reported receiving personal fees from Otsuka and Sunovion and grants from Ontario Brain Institute, SEAMO Innovation Funds, and Ontario Research Fund–Research Excellence outside the submitted work. Dr Vila-Rodriguez reported receiving grants from the Canadian Institutes of Health Research during the conduct of the study and receiving personal fees from Janssen pharmaceutical outside the submitted work. Dr Strother reported receiving Canadian grants from the Ontario Brain Institute, the Canadian Institutes of Health, and Brain Canada and US grants from the National Institute of Health Small Business Innovation Research program during the conduct of the study. Dr Kennedy reported receiving grants from the Ontario Brain Institute during the conduct of the study and receiving grants from Abbott, Janssen, Lundbeck, Otsuka, and Pfizer and personal fees from Alkermes, Allergan, Janssen, Lundbeck, Lundbeck Institute, Otsuka, Pfizer, Servier, and Sunovion outside the submitted work. Dr Farzan reported received funding from Michael Smith Foundation for Health Research, Natural Sciences and Engineering Research Council of Canada Discovery, and Canadian Institutes of Health Research. No other disclosures were reported.

Disclaimer: The opinions, results, and conclusions are those of the authors, and no endorsement by the Ontario Brain Institute is intended or should be inferred.

Additional Information: All study medications were independently purchased at wholesale market values. The Canadian Biomarker Integration Network in Depression is an Integrated Discovery Program performed in partnership with, and financial support from, the Ontario Brain Institute, an independent nonprofit corporation, funded partially by the Ontario government. Additional funding was provided by the Canadian Institutes of Health Research, Lundbeck, Bristol-Myers Squibb, Pfizer, and Servier. Funding and/or in-kind support was provided by the investigators’ academic institutions.

3 1 2020 1 2020 3 1 2020 3 1 e191837710 7 2019 4 11 2019 Copyright 2020 Zhdanov A et al. JAMA Network Open.This is an open access article distributed under the terms of the CC-BY License.jamanetwopen-3-e1918377.pdfThis prognostic study of patients with major depressive disorder estimates how accurately an outcome of escitalopram treatment can be predicted from electroencephalographic data.

Key Points
Question
Is it possible to predict whether the condition of a patient with depression will improve after escitalopram treatment by analyzing their resting-state electroencephalographic signals?

Findings
In this prognostic study of data from 122 patients diagnosed with major depressive disorder, support vector machine classifiers demonstrated an accuracy of 82.4% for predicting escitalopram treatment outcome.

Meaning
When complemented by appropriate analysis methods, resting-state electroencephalographic recordings may be instrumental in improving treatment of patients with depression.

Importance
Social and economic costs of depression are exacerbated by prolonged periods spent identifying treatments that would be effective for a particular patient. Thus, a tool that reliably predicts an individual patient’s response to treatment could significantly reduce the burden of depression.

Objective
To estimate how accurately an outcome of escitalopram treatment can be predicted from electroencephalographic (EEG) data on patients with depression.

Design, Setting, and Participants
This prognostic study used a support vector machine classifier to predict treatment outcome using data from the first Canadian Biomarker Integration Network in Depression (CAN-BIND-1) study. The CAN-BIND-1 study comprised 180 patients (aged 18-60 years) diagnosed with major depressive disorder who had completed 8 weeks of treatment. Of this group, 122 patients had EEG data recorded before the treatment; 115 also had EEG data recorded after the first 2 weeks of treatment.

Interventions
All participants completed 8 weeks of open-label escitalopram (10-20 mg) treatment.

Main Outcomes and Measures
The ability of EEG data to predict treatment outcome, measured as accuracy, specificity, and sensitivity of the classifier at baseline and after the first 2 weeks of treatment. The treatment outcome was defined in terms of change in symptom severity, measured by the Montgomery-Åsberg Depression Rating Scale, before and after 8 weeks of treatment. A patient was designated as a responder if the Montgomery-Åsberg Depression Rating Scale score decreased by at least 50% during the 8 weeks and as a nonresponder if the score decrease was less than 50%.

Results
Of the 122 participants who completed a baseline EEG recording (mean [SD] age, 36.3 [12.7] years; 76 [62.3%] female), the classifier was able to identify responders with an estimated accuracy of 79.2% (sensitivity, 67.3%; specificity, 91.0%) when using only the baseline EEG data. For a subset of 115 participants who had additional EEG data recorded after the first 2 weeks of treatment, use of these data increased the accuracy to 82.4% (sensitivity, 79.2%; specificity, 85.5%).

Conclusions and Relevance
These findings demonstrate the potential utility of EEG as a treatment planning tool for escitalopram therapy. Further development of the classification tools presented in this study holds the promise of expediting the search for optimal treatment for each patient.
==== Body
Introduction
Antidepressant medications are the first-line treatments for patients with major depressive disorder (MDD). However, remission rates are approximately 30% to 40% after 1 medication trial and approximately 50% to 55% after a second separate trial1 and decline progressively with subsequent medication trials.2 Because of the heterogeneity of depression and the lack of consensus on the precise mechanism of action of antidepressants, matching patients to effective treatments has been a daunting task for practitioners. Currently, practitioners use a prolonged trial-and-error process to identify the optimal antidepressant for each patient, with patients often spending months to years experiencing distressing symptoms.2,3 Although clinical interviews and scales are available to confirm the diagnosis and severity of symptoms, they are not sufficient for selecting an appropriate treatment for each patient.4,5 One solution that might help to reduce the time spent in failed trials and accompanying personal and economic burden is to identify biological predictors of response to an antidepressant. A personalized tool for the prediction of response to antidepressants may expedite the treatment and lead to faster relief of symptoms.

One promising technique for identifying biological predictors of response to antidepressant treatment is electroencephalography (EEG), which records the oscillations of brain electric potentials measured from electrodes attached to the scalp. These potentials are produced by the synchronized activity of large (thousands to millions of neurons) neuronal populations inside the brain.6 Converging lines of evidence suggest that features derived from EEG recordings before treatment may predict subsequent clinical response to antidepressants.7,8,9,10,11 Several EEG studies12,13,14,15,16,17,18 have reported that characteristics of resting-state neural oscillations, especially in the alpha and theta bands, may be used to predict the response to antidepressants. Power of posterior alpha activity has been associated with response to fluoxetine and amitriptyline19,20; theta activity with response to imipramine, venlafaxine, and several selective serotonin reuptake inhibitors18,21,22; delta activity with response to imipramine and paroxetine18,23; interhemispheric delta asymmetry with response to fluoxetine24; and increased delta activity in the rostral anterior cingulate cortex with response to nortriptyline, fluoxetine, and venlafaxine.25,26 Several studies27,28,29 have also evaluated the association between nonlinear features of EEG signals (eg, complexity or variability of neural dynamics) and response to antidepressants, such as citalopram, clomipramine, escitalopram, bupropion, and mirtazapine.

The aforementioned works provide compelling evidence that resting-state EEG can be used to predict response to antidepressant medication. However, they fail to address several questions that are important for translating this discovery into a clinical tool. First, they restrict themselves to relatively small and homogeneous feature sets; that is, they do not directly compare large (several thousands and more) numbers of features that represent different perspectives on the EEG signals (eg, spectral power density, entropy, and microstates). Second, many studies report poor prediction accuracy. Third, the estimates of the prediction accuracy reported by the studies are typically biased upward by the lack of an independent testing set. Many of the studies fail to control this bias by appropriate techniques, such as cross-validation.

The shortcomings of the previous studies7,15,16,17,19 stem, to a considerable degree, from relatively small sample sizes available to their authors, typically ranging from 12 to 50 participants. The research described in this publication uses data from a large, Canada-wide, multicenter study, the first Canadian Biomarker Integration Network in Depression (CAN-BIND-1) study,30 to overcome this limitation and address some of the questions remaining from the previous research. In particular, the present study attempts to compare the predictive power of a wide range of diverse features and maximally reduce the bias of the estimate of the prediction accuracy by using cross-validation.

The current study evaluated the predictive power of resting-state EEG signals recorded at baseline (before the treatment was initiated) and 2 weeks after the start of the escitalopram treatment. From the clinical perspective, predicting the treatment outcome from the baseline EEG data alone is preferable because this approach would expedite treatment planning and eliminate the need for the second EEG examination. However, we hypothesized that inclusion of the second time point, 2 weeks after treatment initiation, would identify early changes in brain function that may be predictive of treatment outcome and therefore would result in increased prediction accuracy, potentially outweighing the costs of additional EEG examination. We also conjectured that use of the most predictive EEG features selected from a wide variety of possible candidates—both linear and nonlinear—would increase the predictive power of the model.

Methods
In this prognostic study, we developed and validated a model that predicted treatment outcome from multivariate EEG data following the recommendations for the Transparent Reporting of a Multivariable Prediction Model for Individual Prognosis or Diagnosis (TRIPOD) reporting guideline.31 All the participants of the study provided written informed consent according to the ethics approval issued by the ethics review board at each of the participating sites.

Data Acquisition and Preprocessing
Participants
We used EEG data from the CAN-BIND-1 study.30 All participants were between 18 and 60 years of age and met the Diagnostic and Statistical Manual of Mental Disorders (Fourth Edition) requirements for MDD and a current major depressive episode. The researchers that performed the machine learning analysis received only deidentified data. Clinical practitioners who conducted behavioral patient evaluations had access to patients’ personal details.

We analyzed resting-state recordings from 122 patients with MDD at baseline (before the treatment started) and 115 of the same patients 2 weeks after escitalopram treatment initiation. A patient was categorized as a responder if the Montgomery-Åsberg Depression Rating Scale (MADRS) score decreased by least 50% in the first 8 weeks of the treatment and as a nonresponder if the score decrease was less than 50% (more details are given in the eMethods in the Supplement).

Intersite Data Harmonization and Preprocessing
Because CAN-BIND-1 data were recorded at multiple sites, they were harmonized (converted into a common site-independent format) and then preprocessed to remove some common sources of noise, such as 60-Hz power line interference. Data harmonization and preprocessing are described in more detail in the eMethods in the Supplement.

Feature Computation and Ranking
Feature Sources
Throughout the study, we compared 4 different sources of features that can be used to predict treatment outcome. The sources differed in the timing of the features used for the prediction: (1) baseline source comprised features derived from the data collected at baseline, (2) week 2 source included features derived from data collected 2 weeks after the start of treatment, (3) early change source denoted change in features from baseline to week 2, and (4) combined source combined features from baseline and early change.

Feature Definitions
We evaluated a diverse variety of potentially informative EEG features. In addition to traditional electrode-level frequency analysis, we considered power spectral features in the source domain,26,32 spatiotemporal complexity,33,34 and global brain network dynamics35 previously found to have predictive value for antidepressant response. The power spectral features used the following definitions of the frequency bands: delta (1-3.5 Hz), theta (4-8 Hz), low alpha (8.5-10 Hz), high alpha (10.5-12 Hz), low beta (12.5-18 Hz), middle beta (18.5-21 Hz), and high beta (21.5-30 Hz).

Four classes of features were used in the study. The first class was electrode-level spectral features (power within a given frequency band at each electrode) and lateralization of power for symmetrically located pairs of electrodes. The second class was source-level spectral features, which are estimates of power within a given frequency band for several locations within the brain obtained using the eLORETA source reconstruction algorithm.36 The third class was multiscale-entropy-based features, which are entropy estimates for individual electrodes as well as entropy asymmetry indexes for symmetrically located electrode pairs computed over 70 different timescales using a temporal coarse-graining process.33,34 The fourth class was microstate-based features, which are features derived from decomposition of EEG signals into microstates using established microstate segmentation procedures.35,37 More details on the feature definitions are given in the eMethods in the Supplement.

Feature Ranking
The feature definitions described result in a large feature set that contains thousands of variables. To construct a practical predictor of the treatment outcome, feature selection was performed to identify a small subset of the most informative features to be used with the final classifier.

Identifying the optimal feature set for machine learning is, in general, an unsolved problem.38,39 Machine learning literature suggests a number of different approaches, such as wrapper or filter methods, each with its own advantages and drawbacks. In this study, we adopted a filter-based approach to remove uninformative features, among other reasons, because filter methods are less prone to overfitting and easy to compute.40

We used a filtering method based on an unpaired 2-tailed t test (described in detail in the eMethods in the Supplement) to assign each feature a score of 0 to 100, with more votes indicating the features that are more robustly predictive of the treatment outcome. Feature selection involved selecting only the features that had a number of votes above the specified vote threshold T.

Classifier Construction and Performance Estimation
After a small subset of features has been selected by applying a given threshold to the features’ rankings, a classifier from the selected features can be constructed. For the current study, we used radial basis function (RBF) kernel-based support vector machines (SVMs) for classification. This choice was motivated by the SVMs’ maturity and popularity in machine learning research in general and the success of the machines in the field of neuropsychiatry in particular.41

For each of the 4 feature sources (baseline, week 2, early change, and combined) and several different vote thresholds T ∈ {50, 60, 70, 80, 90}, we trained an RBF SVM classifier to achieve maximum balanced accuracy (mean of sensitivity and specificity) and estimated its performance using cross-validation. Classifier construction and performance estimation are described in more detail the eMethods in the Supplement.

Assessment of Generalizability Across Sites
One important property of a machine learning model for predicting treatment outcome is the ability to generalize to the data obtained from a clinical site that was not involved in the training of the model. We assessed our approach’s capacity for such generalization by using the leave-one-site-out cross-validation procedure adapted from the literature.42 For each of the 4 participating sites, we performed the following computations. First, we partitioned all the data into the testing set that contained data from the given site and the training set that contained data from the 3 remaining sites. Second, we performed the same procedure as previously described (computing feature rankings, selecting the features with rankings above a certain threshold, and constructing the resulting RBF SVM classifier) using the training set only. We used T = 60 for the vote threshold because this value seemed to provide a good balance between the model’s complexity and performance. Third, we assessed the classifier’s performance using the testing set. This procedure yielded 4 different accuracy estimates (1 per each site).

Statistical Analysis
Our study supplants classic statistical analysis by estimating the ability of SVMs to predict treatment outcome from the EEG data. The SVMs’ ability to differentiate between responders and nonresponders from the EEG data (estimated by cross-validation as described above) served as a statistical measure of difference between the 2 populations. The analysis was performed in MATLAB software (MathWorks) using the LIBSVM toolbox.43

Results
Participants
In the current study, we analyzed EEG data recorded before initiation of treatment from 122 participants (mean [SD] age, 36.3 [12.7] years; 76 [62.3%] female) (Table 1). The mean (SD) MADRS score for the 122 participants whose data were included in the analysis was 30.1 (5.8). In addition, for a subset of 115 of the 122 participants (mean [SD] age, 36.2 [12.4] years; 72 [62.6%] female), we analyzed EEG data recorded 2 weeks after the treatment started.

Table 1.  Demographic and Clinical Data for Study Participants
Clinical or Demographic Variable	EEG Recording Site	All (N = 122)	All Responders at Week 8 (n = 55)	All Nonresponders at Week 8 (n = 67)	
UBC (n = 52)	TGH (n = 45)	QNS (n = 18) 	CAM (n = 7)	
Age, mean (SD), y	35.4 (11.5)	35.7 (12.6)	42.7 (14.0)	30.4 (12.1)	36.3 (12.7)	36.0 (12.7)	36.6 (12.6)	
Sex, No.								
 Male	19	18	9	0	46	19	27	
 Female	33	27	9	7	76	36	40	
MADRS score, mean (SD)								
 Baseline	28.5 (5.8)	32.3 (5.6)	30.0 (4.6)	28.0 (4.8)	30.1 (5.8)	29.5 (5.8)	30.5 (5.8)	
 Week 2	21.9 (7.3)	25.1 (10.1)	23.1 (5.2)	21.1 (3.7)	23.2 (8.5)	20.1 (8.4)	25.8 (7.8)	
 Week 8	14.6 (9.2)	19.1 (12.0)	18.1 (9.9)	15.7 (5.6)	16.8 (10.5)	7.9 (5.0)	24.2 (7.7)	
Decrease in MADRS score, mean (SD)								
 Baseline to week 8	13.9 (9.2)	13.2 (11.8)	11.9 (9.9)	12.3 (4.1)	13.2 (10.2)	21.7 (6.7)	6.3 (6.8)	
 Baseline to week 8 compared with baseline, %	48.7 (32.7)	41.1 (3.8)	39.2 (34.9)	44.5 (15.7)	44.3 (32.6)	73.3 (16.0)	20.4 (21.6)	
Responders as assessed at week 8, No. (%)	24 (46.2)	21 (46.7)	7 (38.9)	3 (42.9)	55 (45.1)	NA	NA	
Nonresponders as assessed at week 8, No. (%)	28 (53.8)	24 (53.3)	11 (61.1)	4 (57.1)	67 (54.9)	NA	NA	
Abbreviations: CAM, Centre for Addiction and Mental Health; EEG, electroencephalography; MADRS, Montgomery-Åsberg Depression Rating Scale; NA, not applicable; QNS, Queens University; TGH, Toronto General Hospital; UBC, University of British Columbia.

Feature Computation and Ranking
Of all the different feature classes considered in this study, the most clearly structured pattern of informative features was exhibited by multiscale entropy. Figure 1 reveals several prominent elements of this pattern. There was a tight cluster of predictive features occurring around timescale 17. The features exhibited frontoparietal distribution over the electrode map and appeared mostly unchanged between the baseline and week 2 measurements, resulting in absence of any predictive early change features at this scale. Another prominent pattern was the cluster of predictive features at lower timescales (eg, around timescale 2). This more posteriorly distributed pattern was absent in the baseline measurement but emerged in the week 2 recording. This difference between baseline and week 2 was also reflected in the prominent cluster of predictive early change features appearing at lower timescales.

Figure 1.  Number of Votes for Multiscale Entropy Features
The figure shows rankings for only 3 of 4 feature sources: baseline (A), week 2 (B), and early change (C). Combined feature source was the union of baseline and early change sources; therefore, computing the rankings for the combined features yielded results that were similar to the results for the baseline and early change sources. For that reason, feature rankings for combined feature source are not shown. The matrices in the top row display rankings for all the features; the topographic plots (left ear is left, nose is up) in the bottom row show distribution over the scalp of the rankings for the features corresponding to multiscale entropy scales 2 and 17 (marked by vertical green lines in the top row plots).

Patterns that were less clearly structured were observed for spectral power features. As Figure 2 shows, the predictive features preferentially appeared in the high alpha and middle beta bands in the baseline and week 2 data and in the theta and low beta in the early change features. The asymmetry of multiscale entropy and power also provided a significant number of predictive features; however, these features were less clearly structured (eFigure 1 and eFigure 2 in the Supplement).

Figure 2.  Number of Votes for Spectral Power Features
The figure shows rankings for only 3 of 4 feature sources: baseline (A), week 2 (B), and early change (C). Combined feature source was the union of baseline and early change sources; therefore, computing the rankings for the combined features yielded results that were similar to the results for the baseline and early change sources. For that reason, feature rankings for combined feature source are not shown. The matrices in the top row display rankings for all the features; the topographic plots (left ear is left, nose is up) in the bottom row show distribution over the scalp of the rankings for the features corresponding to some chosen frequency bands.

Current source density analysis revealed that high-alpha-band power in anterior cingulate cortex was the most prominent predictive feature shared by all the feature sources. In addition, high-alpha-band power in rostral anterior cingulate cortex appeared in baseline and week 2 data and high-beta-band at week 2 only (eFigure 3 in the Supplement). Microstate features did not exhibit any meaningful predictive capacity; the largest number of votes attained by any of the microstates’ features was 9.

Classifier Construction and Performance Estimation
The prediction accuracy of SVMs for different feature sources and vote thresholds is summarized in Table 2. Increasing the number of features (by lowering the threshold) resulted in higher estimates of the model’s accuracy, with the early change feature source exhibiting an exception. The threshold of 60 votes provided a good trade-off between model complexity and performance; thus, we used this value for the rest of the analysis in this study. The eTable in the Supplement describes the classification performance for this threshold in more detail, including specificity and sensitivity values.

Table 2.  Number of Features and Prediction Accuracy for Different Vote Thresholds and Feature Sources
Vote Threshold 	Balanced Accuracy (No. of Features for a Particular Feature Source), % (No.)a	
Baseline	Week 2	Early Change	Combinedb	
≥50	78.6 (54)	79.7 (75)	68.4 (149)	83.3 (185)	
≥60	79.2 (34)	74.3 (50)	68.4 (106)	82.4 (127)	
≥70	77.3 (17)	71.4 (28)	74.2 (73)	76.9 (82)	
≥80	73.6 (9)	72.8 (14)	77.1 (50)	72.5 (52)	
≥90	68.6 (4)	68.8 (5)	70.7 (20)	72.7 (21)	
a Balanced accuracy is defined as the mean of sensitivity and specificity.

b Because the combined feature source was the union of baseline and early change feature sources, the feature count for the combined source was similar to the sum of the counts for baseline and early change sources. The count was similar rather than equal owing to the noise introduced into the feature ranking procedure by randomly choosing the 80% of the data to which the 2-tailed, unpaired t test was applied at each of the 100 iterations (see the Feature Ranking subsection of the Methods section).

The balanced accuracy of the classifier, as estimated by cross-validation, varied from 68.4% for early change feature source to 82.4% for combined feature source. Baseline-only data allowed prediction with an estimated balanced accuracy of 79.2% (sensitivity, 67.3%; specificity, 91.0%), whereas addition of week 2 data increased the accuracy to 82.4% (sensitivity, 79.2%; specificity, 85.5%). When computing sensitivity and specificity, we considered responder status to be a positive outcome and nonresponder to be a negative one.

Assessment of Generalizability Across Sites
The results of the cross-site generalizability assessment are summarized in Table 3. The classification accuracy measured by the leave-one-site-out procedure was, in general, similar to that measured by 10-fold cross-validation on the complete data sample. However, the early change feature source again deviated from the general pattern by yielding inferior performance on the complete data sample.

Table 3.  Cross-site Generalizability of the Treatment Outcome Prediction
Feature Source	Balanced Prediction Accuracy Testing on Data From a Single Sitea,b	Balanced Prediction Accuracya,c	
UBC	TGH	QNS	CAM	
Accuracy, %	Individuals, No.	Accuracy, %	Individuals, No.	Accuracy, %	Individuals, No.	Accuracy, %	Individuals, No.	Accuracy, %	Individuals, No.	
Baseline	62.0	52	71.0	45	82.7	18	74.9	7	79.2	122	
Week 2	74.5	51	74.7	40	79.2	18	72.0	6	74.3	115	
Early change	69.9	85.0	77.4	78.6	68.4	
Combined	71.3	94.6	83.1	77.4	82.4	
Abbreviations: CAM, Centre for Addiction and Mental Health; QNS, Queens University; TGH, Toronto General Hospital; UBC, University of British Columbia.

a Balanced prediction accuracy is defined as the mean of sensitivity and specificity.

b Training was performed on data from the remaining sites.

c Training and testing were performed on the data from all 4 sites using 10-fold cross-validation.

Discussion
In this study, we demonstrated feasibility of predicting an outcome of escitalopram treatment using resting-state EEG. Of note, the prediction was that of the treatment outcome and not of the patient’s response to escitalopram. Without a properly randomized clinical trial, it is impossible to definitely attribute predicted differences in treatment outcomes to differences in individual patients’ responses to escitalopram in our particular experimental setup. However, more generally, there is a wide consensus44,45,46 regarding the assumption that variability in patients’ responses to escitalopram at least partially explains the variability of treatment outcomes. Together with this assumption, our results suggest that the predictive performance attained by our model is likely to at least partially involve prediction of the patient’s response to escitalopram. Of note, our study was not designed as an exhaustive optimization effort to achieve maximum possible classification accuracy. Such an effort would require a search over a larger space of candidate models (including models other than RBF kernel-based SVMs) and would demand larger data sets.

As hypothesized, combining baseline neural dynamics with early changes in neural dynamics (change after 2 weeks of treatment) resulted in the most accurate prediction. Results from leave-one-site-out cross-validation also demonstrated that the large-scale analysis of data pooled across multiple sites did not have a significant effect on classifier performance. This finding is important because it indicates the method’s robustness to variability stemming from differences in instrumentation and operation procedures across different clinical sites, making it more attractive for clinical translation.

A number of features identified through the feature selection process in this study have been previously reported to predict antidepressant response in patients with MDD. These features include parietal alpha,19,20,47 anterior cingulate cortex activity,48,49,50 and frontal theta.18,21 Our study also identified additional features that have not been previously reported, such as asymmetry in complexity of neural activity between hemispheres. This discovery of new EEG features that predict treatment outcome was a result of systematic evaluation of a large number of candidate measures using a relatively large data sample.

Machine learning studies using resting-state EEG measures for antidepressant response prediction are scarce. In the study by Khodayari-Rostamabad et al,51 resting-state EEG measures were used with a mixture of factor analysis classifier to predict antidepressant response. An accuracy of 87.9% was reported (sensitivity, 94.9%; specificity, 80.9%). Accuracy was also high (85%-92%) in the study by Rabinoff et al,15 which used spectral EEG features with classification and regression tree analysis. The study combined trials for 2 antidepressants (fluoxetine and venlafaxine) to predict response in 51 patients with unipolar depression. When interpreting the accuracy of the prediction models reported by different studies and especially comparing the accuracy across studies, a number of caveats should be considered. The most important one is that the reported accuracy numbers are usually estimated from data that are not strictly independent from the data used to fit the model parameters. Essentially this means that the estimates might be biased upward as a result of overfitting. Although a number of techniques are usually used to reduce this bias, such techniques do not necessarily eliminate it completely.52,53 The severity of the bias depends on many factors, such as sample size, number of free parameters in the model, and the bias-control techniques used. As a result, the bias is difficult to estimate and might vary greatly from study to study, making a direct comparison of reported accuracies misleading. Another important factor to consider when comparing results of different studies is the limitation on the maximal achievable accuracy that results from the noise in the target variable. The definition of response to treatment is typically grounded by a behavioral assessment summarized in a numerical variable (MADRS score in our study). However, this variable is inherently noisy; that is, the behavioral assessment of the same patient conducted twice yields somewhat different values.54 Consequently, it is impossible to predict such a variable (and, by extension, other variables derived from it, such as responder or nonresponder classification) with 100% accuracy. The upper bound on achievable accuracy depends on the amount of noise in the target variable, which might vary from study to study; the prediction accuracy reported by the study should be judged relative to that bound and not relative to the bound of 100%, which makes an unrealistic assumption of zero noise in the target labels.

To assess the practical relevance of the above argument, we computed an estimate of the target noise–induced bound for our sample (eMethods in the Supplement). The resulting estimate was 86.7%, indicating that the phenomenon was nonnegligible. Of importance, when computing that value, we made a number of arbitrary assumptions (such as modeling the MADRS noise with a normally distributed random variable); therefore, the result should be treated as a general estimate of the possible size of the effect rather than a measure of the effect in our particular study.

Limitations
This study has limitations. Because this was an open-label study that lacked a control group, it was incapable of probing any causal relationships between the variables. Although we used a number of measures to control the overfitting, such as cross-validation and feature selection techniques, our performance estimate is not perfectly unbiased. Although our study used a larger data sample than most previous works, it was still limited, precluding model validation with a strictly independent data set. To obtain an unbiased estimate of our model’s predictive performance, future studies should validate it against an independent data set that was not used for model construction. This may be in part achieved through the next CAN-BIND validation study that aims to replicate the entire CAN-BIND-1 study in an independent cohort of patients. In addition, prediction models reported in this study have yet to be proven to be generalizable to other antidepressants. Model evaluation should be performed independently with several other types of treatment to evaluate the generalizability of our prediction models. This evaluation may also provide insight into whether the features identified in this study were specific to escitalopram treatment or whether they can be used with other pharmacologic agents. Performance may also be improved with the addition of clinical or behavioral variables, genetic measures, and other imaging-based measures (eg, functional magnetic resonance imaging and diffusion tensor imaging).

Conclusions
This study provided a proof-of-concept pipeline for predicting changes in depression severity after the start of escitalopram treatment. Developed into a proper clinical application, such a pipeline may provide a valuable treatment planning tool. For large data sets that include several groups of patients, each receiving a different treatment option (pharmacologic and nonpharmacologic antidepressants), an approach similar to the one taken by this study may be useful in developing a model that can match each patient to the most effective treatment. The feasibility of such an approach will in part depend on the collection and sharing of large-scale, clinically reliable data sets, such as CAN-BIND. These investigations would contribute to the development of a clinical decision-making tool for data-driven, personalized optimization of antidepressant treatment selection for patients.

Supplement. eMethods. Supplementary Methods

eFigure 1. Rankings of MSE Asymmetry Features

eFigure 2. Rankings of Electrode-Level Spectral Asymmetry Features

eFigure 3. Rankings of Source-Level Spectral Features

eTable. Characteristics of Classifiers Constructed From Features With ≥60 Votes

eReferences

Click here for additional data file.
==== Refs
References
1 Trivedi MH , Rush AJ , Wisniewski SR , ; STAR*D Study Team  
Evaluation of outcomes with citalopram for depression using measurement-based care in STAR*D: implications for clinical practice . Am J Psychiatry . 2006 ;163 (1 ):-. doi:10.1176/appi.ajp.163.1.28 
16390886 
2 Rush AJ , Trivedi MH , Wisniewski SR ,  
Acute and longer-term outcomes in depressed outpatients requiring one or several treatment steps: a STAR*D report . Am J Psychiatry . 2006 ;163 (11 ):1905 -1917 . doi:10.1176/ajp.2006.163.11.1905 
17074942 
3 Arroll B , Macgillivray S , Ogston S ,  
Efficacy and tolerability of tricyclic antidepressants and SSRIs compared with placebo for treatment of depression in primary care: a meta-analysis . Ann Fam Med . 2005 ;3 (5 ):449 -456 . doi:10.1370/afm.349 
16189062 
4 Winokur G  
All roads lead to depression: clinically homogeneous, etiologically heterogeneous . J Affect Disord . 1997 ;45 (1-2 ):97 -108 . doi:10.1016/S0165-0327(97)00063-3 
9268779 
5 Chekroud AM , Zotti RJ , Shehzad Z ,  
Cross-trial prediction of treatment outcome in depression: a machine learning approach . Lancet Psychiatry . 2016 ;3 (3 ):243 -250 . doi:10.1016/S2215-0366(15)00471-X 
26803397 
6 Nunez P , Srinivasan R   Electroencephalogram. Scholarpedia
2007 ;2(2):1348. 
7 Iosifescu DV  
Electroencephalography-derived biomarkers of antidepressant response . Harv Rev Psychiatry . 2011 ;19 (3 ):144 -154 . doi:10.3109/10673229.2011.586549 
21631160 
8 Kemp AH , Gordon E , Rush AJ , Williams LM  
Improving the prediction of treatment response in depression: integration of clinical, cognitive, psychophysiological, neuroimaging, and genetic measures . CNS Spectr . 2008 ;13 (12 ):1066 -1086 . doi:10.1017/S1092852900017120 
19179943 
9 Hunter AM , Cook IA , Leuchter AF  
The promise of the quantitative electroencephalogram as a predictor of antidepressant treatment outcomes in major depressive disorder . Psychiatr Clin North Am . 2007 ;30 (1 ):105 -124 . doi:10.1016/j.psc.2006.12.002 
17362807 
10 Olbrich S , Arns M  
EEG biomarkers in major depressive disorder: discriminative power and prediction of treatment response . Int Rev Psychiatry . 2013 ;25 (5 ):604 -618 . doi:10.3109/09540261.2013.816269 
24151805 
11 Baskaran A , Milev R , McIntyre RS  
The neurobiology of the EEG biomarker as a predictor of treatment response in depression . Neuropharmacology . 2012 ;63 (4 ):507 -513 . doi:10.1016/j.neuropharm.2012.04.021 
22569197 
12 Ulrich G , Renfordt E , Frick K  
The topographical distribution of alpha-activity in the resting EEG of endogenous-depressive in-patients with and without clinical response to pharmacotherapy . Pharmacopsychiatry . 1986 ;19 (04 ):272 -273 . doi:10.1055/s-2007-1017230 

13 Ulrich G , Renfordt E , Frick K  
Electroencephalographic dynamics of vigilance and drug-response in endogenous depression: a comparison of patients treated with amitriptyline or pirlindole . Pharmacopsychiatry . 1986 ;19 :270 -271 . doi:10.1055/s-2007-1017229 

14 Leuchter AF , Cook IA , Uijtdehaage SH ,  
Brain structure and function and the outcomes of treatment for depression . J Clin Psychiatry . 1997 ;58 (suppl 16 ):22 -31 .9430506 
15 Rabinoff M , Kitchen CM , Cook IA , Leuchter AF  
Evaluation of quantitative EEG by classification and regression trees to characterize responders to antidepressant and placebo treatment . Open Med Inform J . 2011 ;5 (1 ):1 -8 . doi:10.2174/1874431101105010001 
21603560 
16 Bares M , Brunovsky M , Kopecek M ,  
Early reduction in prefrontal theta QEEG cordance value predicts response to venlafaxine treatment in patients with resistant depressive disorder . Eur Psychiatry . 2008 ;23 (5 ):350 -355 . doi:10.1016/j.eurpsy.2008.03.001 
18450430 
17 Cook IA , Leuchter AF , Morgan ML , Stubbeman W , Siegman B , Abrams M  
Changes in prefrontal activity characterize clinical response in SSRI nonresponders: a pilot study . J Psychiatr Res . 2005 ;39 (5 ):461 -466 . doi:10.1016/j.jpsychires.2004.12.002 
15992554 
18 Knott VJ , Telner JI , Lapierre YD , Browne M , Horn ER  
Quantitative EEG in the prediction of antidepressant response to imipramine . J Affect Disord . 1996 ;39 (3 ):175 -184 . doi:10.1016/0165-0327(96)00003-1 
8856421 
19 Bruder GE , Sedoruk JP , Stewart JW , McGrath PJ , Quitkin FM , Tenke CE  
Electroencephalographic alpha measures predict therapeutic response to a selective serotonin reuptake inhibitor antidepressant: pre- and post-treatment findings . Biol Psychiatry . 2008 ;63 (12 ):1171 -1177 . doi:10.1016/j.biopsych.2007.10.009 
18061147 
20 Ulrich G , Renfordt E , Zeller G , Frick K  
Interrelation between changes in the EEG and psychopathology under pharmacotherapy for endogenous depression: a contribution to the predictor question . Pharmacopsychiatry . 1984 ;17 (6 ):178 -183 . doi:10.1055/s-2007-1017433 
6514780 
21 Iosifescu DV , Greenwald S , Devlin P ,  
Frontal EEG predictors of treatment outcome in major depressive disorder . Eur Neuropsychopharmacol . 2009 ;19 (11 ):772 -777 . doi:10.1016/j.euroneuro.2009.06.001 
19574030 
22 Iosifescu DV , Nierenberg AA , Mischoulon D ,  
An open study of triiodothyronine augmentation of selective serotonin reuptake inhibitors in treatment-resistant major depressive disorder . J Clin Psychiatry . 2005 ;66 (8 ):1038 -1042 . doi:10.4088/JCP.v66n0812 
16086620 
23 Knott V , Mahoney C , Kennedy S , Evans K  
Pre-treatment EEG and its relationship to depression severity and paroxetine treatment outcome . Pharmacopsychiatry . 2000 ;33 (6 ):201 -205 . doi:10.1055/s-2000-8356 
11147926 
24 Bruder GE , Stewart JW , Tenke CE ,  
Electroencephalographic and perceptual asymmetry differences between responders and nonresponders to an SSRI antidepressant . Biol Psychiatry . 2001 ;49 (5 ):416 -425 . doi:10.1016/S0006-3223(00)01016-7 
11274653 
25 Korb AS , Hunter AM , Cook IA , Leuchter AF  
Rostral anterior cingulate cortex theta current density and response to antidepressants and placebo in major depression . Clin Neurophysiol . 2009 ;120 (7 ):1313 -1319 . doi:10.1016/j.clinph.2009.05.008 
19539524 
26 Pizzagalli D , Pascual-Marqui RD , Nitschke JB ,  
Anterior cingulate activity as a predictor of degree of treatment response in major depression: evidence from brain electrical tomography analysis . Am J Psychiatry . 2001 ;158 (3 ):405 -415 . doi:10.1176/appi.ajp.158.3.405 
11229981 
27 Méndez MA , Zuluaga P , Hornero R ,  
Complexity analysis of spontaneous brain activity: effects of depression and antidepressant treatment . J Psychopharmacol . 2012 ;26 (5 ):636 -643 . doi:10.1177/0269881111408966 
21708836 
28 Jaworska N , Wang H , Smith DM , Blier P , Knott V , Protzner AB  
Pre-treatment EEG signal variability is associated with treatment success in depression . Neuroimage Clin . 2017 ;17 :368 -377 . doi:10.1016/j.nicl.2017.10.035 
29159049 
29 Thomasson N , Pezard L , Allilaire J-F , Renault B , Martinerie J  
Nonlinear EEG changes associated with clinical improvement in depressed patients . Nonlinear Dyn Psychol Life Sci . 2000 ;4 (3 ):203 -218 . doi:10.1023/A:1009580427443 

30 Kennedy SH , Lam RW , Rotzinger S , ; CAN-BIND Investigator Team  
Symptomatic and functional outcomes and early prediction of response to escitalopram monotherapy and sequential adjunctive aripiprazole therapy in patients with major depressive disorder: a CAN-BIND-1 report . J Clin Psychiatry . 2019 ;80 (2 ):18m12202. doi:10.4088/JCP.18m12202 
30840787 
31 Collins GS , Reitsma JB , Altman DG , Moons KGM  
Transparent Reporting of a multivariable prediction model for Individual Prognosis or Diagnosis (TRIPOD): the TRIPOD statement . Ann Intern Med . 2015 ;162 (1 ):55 -63 . doi:10.7326/M14-0697 
25560714 
32 Pizzagalli DA  
Frontocingulate dysfunction in depression: toward biomarkers of treatment response . Neuropsychopharmacology . 2011 ;36 (1 ):183 -206 . doi:10.1038/npp.2010.166 
20861828 
33 Costa M , Goldberger AL , Peng C-K  
Multiscale entropy analysis of biological signals . Phys Rev E Stat Nonlin Soft Matter Phys . 2005 ;71 (2, pt 1 ):021906. doi:10.1103/PhysRevE.71.021906 
15783351 
34 Farzan F , Atluri S , Mei Y ,  
Brain temporal complexity in explaining the therapeutic and cognitive effects of seizure therapy . Brain . 2017 ;140 (4 ):1011 -1025 . doi:10.1093/brain/awx030 
28335039 
35 Pascual-Marqui RD , Michel CM , Lehmann D  
Segmentation of brain electrical activity into microstates: model estimation and validation . IEEE Trans Biomed Eng . 1995 ;42 (7 ):658 -665 . doi:10.1109/10.391164 
7622149 
36 Pascual-Marqui RD , Lehmann D , Koenig T ,  
Low resolution brain electromagnetic tomography (LORETA) functional imaging in acute, neuroleptic-naive, first-episode, productive schizophrenia . Psychiatry Res . 1999 ;90 (3 ):169 -179 . doi:10.1016/S0925-4927(99)00013-X 
10466736 
37 Lehmann D , Ozaki H , Pal I  
EEG alpha map series: brain micro-states by space-oriented adaptive segmentation . Electroencephalogr Clin Neurophysiol . 1987 ;67 (3 ):271 -288 . doi:10.1016/0013-4694(87)90025-3 
2441961 
38 Guyon I , Elisseeff A  
An introduction to variable and feature selection . J Mach Learn Res . 2003 ;3 :1157 -1182 .
39 Blum AL , Langley P  
Selection of relevant features and examples in machine learning . Artif Intell . 1997 ;97 (1 ):245 -271 . doi:10.1016/S0004-3702(97)00063-5 

40 Saeys Y , Inza I , Larrañaga P  
A review of feature selection techniques in bioinformatics . Bioinformatics . 2007 ;23 (19 ):2507 -2517 . doi:10.1093/bioinformatics/btm344 
17720704 
41 Orrù G , Pettersson-Yeo W , Marquand AF , Sartori G , Mechelli A  
Using support vector machine to identify imaging biomarkers of neurological and psychiatric disease: a critical review . Neurosci Biobehav Rev . 2012 ;36 (4 ):1140 -1152 . doi:10.1016/j.neubiorev.2012.01.004 
22305994 
42 Rozycki M , Satterthwaite TD , Koutsouleris N ,  
Multisite machine learning analysis provides a robust structural imaging signature of schizophrenia detectable across diverse patient populations and within individuals . Schizophr Bull . 2018 ;44 (5 ):1035 -1044 . doi:10.1093/schbul/sbx137 
29186619 
43 Chang C-C , Lin C-J  
LIBSVM: a library for support vector machines . ACM Trans Intell Syst Technol . 2011 ;2 (3 ):1 -27 . doi:10.1145/1961189.1961199 
44 Kornstein SG , Bose A , Li D , Saikali KG , Gandhi C  
Escitalopram maintenance treatment for prevention of recurrent depression: a randomized, placebo-controlled trial . J Clin Psychiatry . 2006 ;67 (11 ):1767 -1775 . doi:10.4088/JCP.v67n1115 17196058 
45 Gorman JM , Korotzer A , Su G  
Efficacy comparison of escitalopram and citalopram in the treatment of major depressive disorder: pooled analysis of placebo-controlled trials . CNS Spectr . 2002 ;7 (4 )(suppl 1):40 -44 . doi:10.1017/S1092852900028595 15131492 
46 Burke WJ , Gergel I , Bose A  
Fixed-dose trial of the single isomer SSRI escitalopram in depressed outpatients . J Clin Psychiatry . 2002 ;63 (4 ):331 -336 . doi:10.4088/JCP.v63n0410 12000207 
47 Tenke CE , Kayser J , Manna CG ,  
Current source density measures of EEG alpha predict antidepressant treatment response . Biol Psychiatry . 2011 ;70 (4 ):388 -394 . doi:10.1016/j.biopsych.2011.02.016 
21507383 
48 Mayberg HS , Brannan SK , Mahurin RK ,  
Cingulate function in depression: a potential predictor of treatment response . Neuroreport . 1997 ;8 (4 ):1057 -1061 . doi:10.1097/00001756-199703030-00048 
9141092 
49 Brody AL , Saxena S , Silverman DH ,  
Brain metabolic changes in major depressive disorder from pre- to post-treatment with paroxetine . Psychiatry Res . 1999 ;91 (3 ):127 -139 . doi:10.1016/S0925-4927(99)00034-7 
10641577 
50 Saxena S , Brody AL , Ho ML , Zohrabi N , Maidment KM , Baxter LR Jr 
Differential brain metabolic predictors of response to paroxetine in obsessive-compulsive disorder versus major depression . Am J Psychiatry . 2003 ;160 (3 ):522 -532 . doi:10.1176/appi.ajp.160.3.522 
12611834 
51 Khodayari-Rostamabad A , Reilly JP , Hasey GM , de Bruin H , Maccrimmon DJ  
A machine learning approach using EEG data to predict response to SSRI treatment for major depressive disorder . Clin Neurophysiol . 2013 ;124 (10 ):1975 -1985 . doi:10.1016/j.clinph.2013.04.010 
23684127 
52 Reunanen J  
Overfitting in making comparisons between variable selection methods . J Mach Learn Res . 2003 ;3 :1371 -1382 .
53 Varma S , Simon R  
Bias in error estimation when using cross-validation for model selection . BMC Bioinformatics . 2006 ;7 (1 ):91 . doi:10.1186/1471-2105-7-91 
16504092 
54 Williams JBW , Kobak KA  
Development and reliability of a structured interview guide for the Montgomery Asberg Depression Rating Scale (SIGMA) . Br J Psychiatry . 2008 ;192 (1 ):52 -58 . doi:10.1192/bjp.bp.106.032532 
18174510

