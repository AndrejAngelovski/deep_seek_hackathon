
==== Front
Nat CommunNat CommunNature Communications2041-1723Nature Publishing Group UK London 1065310.1038/s41467-019-10653-8ArticleSpatial suppression promotes rapid figure-ground segmentation of moving objects Tadin Duje dtadin@ur.rochester.edu 12http://orcid.org/0000-0003-1473-4876Park Woon Ju 13http://orcid.org/0000-0002-4725-381XDieter Kevin C. 1Melnick Michael D. 1Lappin Joseph S. 4http://orcid.org/0000-0001-8697-6239Blake Randolph 41 0000 0004 1936 9174grid.16416.34Department of Brain & Cognitive Sciences; Center for Visual Science, University of Rochester, Rochester, NY 14627 USA 2 0000 0004 1936 9166grid.412750.5Departments of Ophthalmology and Neuroscience, University of Rochester Medical Center, Rochester, NY 14642 USA 3 0000000122986657grid.34477.33Department of Psychology, University of Washington, Seattle, WA 98195 USA 4 0000 0001 2264 7217grid.152326.1Department of Psychology, Vanderbilt University, Nashville, TN 37240 USA 2 7 2019 2 7 2019 2019 10 273211 8 2018 21 5 2019 © The Author(s) 2019Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/.Segregation of objects from their backgrounds is a fundamental visual function and one that is particularly effective when objects are in motion. Theoretically, suppressive center-surround mechanisms are well suited for accomplishing motion segregation. This longstanding hypothesis, however, has received limited empirical support. We report converging correlational and causal evidence that spatial suppression of background motion signals is critical for rapid segmentation of moving objects. Motion segregation ability is strongly predicted by both individual and stimulus-driven variations in spatial suppression strength. Moreover, aging-related superiority in perceiving background motion is associated with profound impairments in motion segregation. This segregation deficit is alleviated via perceptual learning, but only when motion segregation training also causes decreased sensitivity to background motion. We argue that perceptual insensitivity to large moving stimuli effectively implements background subtraction, which, in turn, enhances the visibility of moving objects and accounts for the observed link between spatial suppression and motion segregation.

The visual system excels at segregating moving objects from their backgrounds, a key visual function hypothesized to be driven by suppressive centre-surround mechanisms. Here, the authors show that spatial suppression of background motion signals is critical for rapid segmentation of moving objects.

Subject terms
InhibitionMotion detectionObject visionHuman behaviourhttps://doi.org/10.13039/100000053U.S. Department of Health & Human Services | NIH | National Eye Institute (NEI)P30 EY001319T32 EY007125T32 EY007135Tadin Duje issue-copyright-statement© The Author(s) 2019
==== Body
Introduction
Segregation of objects from their backgrounds is one of vision’s most important tasks1. This essential step in visual processing, termed figure-ground segmentation, has fascinated neuroscientists and psychologists since the early days of Gestalt psychology. Visual motion is an especially rich source of information for rapid, effective object segregation1–5. A stealthy animal cloaked by camouflage immediately loses its invisibility once it begins moving, just as does a friend you’re trying to spot, waving her arms amongst a bustling crowd at the arrival terminal of an airport. While seemingly effortless, visual segregation of moving objects invokes a challenging problem that is ubiquitous across sensory and cognitive domains: balancing competing demands between processes that discriminate and those that integrate and generalize6–11. Figure-ground segmentation of moving objects, by definition, requires highlighting of local variations in velocity signals. This, however, is in conflict with integrative processes necessitated by local motion signals that are often noisy and/or ambiguous. Achieving an appropriate and adaptive balance between these two competing demands is a key requirement for efficient segregation of moving objects6,12.

How does our visual system accomplish this critical task of segregating objects in motion? A longstanding hypothesis postulates a key role of antagonistic center-surround mechanisms13. Neurons with such properties are found in motion selective brain regions, most prominently in cortical area MT, a key area for motion processing14. A typical center-surround neuron responds strongly when its receptive field center is stimulated with motion in its preferred direction. However, when the spatial extent of stimulation is enlarged to include the receptive field surround, the neuron’s response is suppressed14,15. Theoretical work shows that this sensitivity to small moving stimuli paired with insensitivity to wide-field, uniform motions is well suited to support segmentation of moving figures from their backgrounds13,16–18. However, direct behavioral evidence for this link is lacking, and even indirect neurophysiological evidence is limited12,19–21. In fact, motion segregation could be accomplished by specialized processes not involving center-surround mechanisms22, with center-surround mechanisms playing a role in other visual processes, including redundancy reduction, input normalization, estimation of optic flow, heading direction, 3D shape-from-motion, and detection of edge discontinuities23–30. In sum, whether motion segregation ability indeed depends on suppressive center-surround mechanisms is an open empirical question.

To address this question, we exploited behavioral correlates of surround suppression12, focusing on strong suppressive effects that are prominent in direction discriminations of brief moving stimuli. As the size of such stimuli increases, observers experience progressively increasing difficulty at perceiving visual motion31. This behavioral phenomenon, termed spatial suppression (to differentiate it from neural surround suppression mechanisms), is thought to reflect surround suppression mechanisms within cortical area MT32–35. A defining property of behavioral spatial suppression is that it adapts to stimulus characteristics; spatial suppression is strong for motion stimuli that are highly visible and weak for those that are either noisy or low in contrast31. This adaptability of spatial suppression parallels theoretical constraints associated with competing demands between segregation and integration of moving signals6. Functional roles of spatial suppression, however, remain unclear and, indeed, at face value, it appears to be detrimental to our ability to perceive visual motion. Here, we test the hypothesis that mechanisms of spatial suppression directly enable rapid segregation of moving objects by suppressing motion signals belonging to the background. We propose that spatial suppression, in essence, functions equivalently to background subtraction algorithms used in computer vision—algorithms that are particularly effective when the background can be reliably identified as is the case with moving backgrounds17,36–39. Within this framework, in other words, large, uniform moving stimuli are treated as backgrounds owing to spatial suppression. This is consistent with classic observations by Rubin and others40,41 that smaller and larger stimuli are more likely to be perceived as figures and backgrounds, respectively.

The results provide converging correlational and causal evidence for the hypothesis that spatial suppression of background motion signals is critical for rapid segmentation of moving objects. We first show that stimulus conditions associated with strong spatial suppression (high contrast and fast speed) also support efficient motion segregation. Moreover, individuals that exhibit strong spatial suppression also excel at motion segregation. This correlational relationship holds for both neurotypical younger adults and for older adults who show age-related weakening of spatial suppression42. Finally, we show that age-related weakening of spatial suppression42 can be reversed as a result of motion segregation training. Taken together, these results provide strong converging evidence for a functional linkage between spatial suppression and motion segregation.

Results
Overview of the results
The results are organized into four sections. The first two sections provide indirect, correlational evidence for a link between spatial suppression and motion segregation. First, by manipulating stimulus characteristics, we show that humans excel at motion segregation under stimulus conditions associated with strong spatial suppression (Exp. 1 and 2). Here, segregation of moving objects from a moving background is remarkably effective, matching and even surpassing detection of moving objects seen against static backgrounds. Next (Exp. 3), by using an individual differences approach, we show that individual variations in spatial suppression strength correlate with observers’ ability to segregate moving objects. Motivated by weakening of spatial suppression in senescence42 we also tested older adults and found that age-related improvements in the relative visibility of large, background motions were associated with pronounced deficits in motion segregation.

The third section tests a prediction derived from correlational experiments in the first two sections: if human motion segregation ability is largely derived from spatial suppression mechanisms, then an intervention that improves motion segregation should also cause corresponding changes in spatial suppression (Exp. 4). Results confirmed this prediction by showing that improvements in motion segregation produced by perceptual learning are accompanied by a corresponding strengthening of spatial suppression. The fourth section describes a model that aims to gain insights into what mechanistic changes might underlie the observed change in spatial suppression. Depending on the reader’s preferences, the results can be either read in its entirety (as gradually building toward more conclusive experiments) or a reader can skip to the third section (“Causal linking of motion segregation and spatial suppression”) treating the first two sections similar to Supplementary materials.

Covariation of motion segregation and spatial suppression
We start by testing a straightforward prediction. If spatial suppression underlies visual motion segregation, then stimulus conditions that strengthen spatial suppression should aid motion segregation and vice versa (Exp. 1). In other words, a motion-defined object should be more visible when its background motion is less visible. To test this hypothesis, we asked observers to (a) identify a motion-defined object imbedded in a large moving background pattern (motion segregation task; Fig. 1a), and (b) identify motion direction of the background motion presented on its own (motion discrimination task; Fig. 1b). Both tasks were done across a range of contrasts. As expected31, motion discriminations of the large background motion considerably worsened with increasing contrast (Fig. 1c), a result consistent with spatial suppression at high contrasts (note that because of a blurred spatial envelope (Fig. 1a, b) increasing contrast also results in modest increases in the effective stimulus size, which also strengthens spatial suppression31). On the other hand, motion segregation gradually improved with increasing contrast (Fig. 1c), exhibiting a strong negative correlation with decreases in the visibility of the background motion (Fig. 1c, d; group result: Pearson r = −0.977, median correlation across observers: −0.983). Notably, at the maximum contrast tested, thresholds for simply perceiving background motion direction were over 7 times higher than thresholds for segregating moving objects on the same size background.Fig. 1 Motion segregation is effective when background motion is less discriminable. a In the motion segregation task, observers identified the tilt of an oval motion-defined object presented on a moving background. The object could be either tilted left (as shown) or tilted right. Block arrows and the object outline are shown for illustration purposes only. Scale bar is 1°. b In the motion discrimination task, the background motion from panel A was presented in isolation, and observers were simply asked to identify its motion direction (which could be either upward or downward). Scale bar is 1°. c Group data showing the opposite effects of stimulus contrast on motion discriminations and motion segregation. d Data for two individual observers. All error bars are s.e.m.



Next, we further examined the effectiveness of motion segregation. Here, we contrasted motion segregation—the ability to segment moving objects on moving backgrounds—with detection of moving objects on static backgrounds, an ostensibly much simpler task (Exp. 2). The observers were asked to identify the location of a moving object, which could appear in one of four different positions (Fig. 2a). The key manipulation was the nature of the background: it was either stationary or moving. At high contrast, observers identified an object’s location more quickly when the background was also moving (Fig. 2b, F1,5 = 72.27, P < 10−3, η2 = 0.935). The advantage of the moving background, however, weakened both at slow speeds (Fig. 2b; interaction: F4,20 = 4.57, P = 0.009, η2 = 0.478) and at low contrast (Fig. 2c, F1,5 = 0.063, P = 0.81, η2 = 0.012). This pattern of results is consistent with speed- and contrast-dependency of spatial suppression; suppression weakens both at low contrast and at slow speeds31,43. Thus, it appears that the visual system excels at motion segregation under conditions that promote insensitivity to background motion – a result consistent with human vision subtracting background motion to accomplish motion segregation.Fig. 2 Motion segregation on moving and static backgrounds. a Observers identified the location of a moving target which could occur in one of four possible locations (shown with dotted circles for illustration purposes only). The target background was either moving (as illustrated) or stationary. Scale bar is 2°. b Effects of speed on task performance for moving and static backgrounds at high contrast. c Same as (b), but at low contrast. d Same data as in (b), but with speed expressed as relative to the background. Error bars are s.e.m.



How effective is this putative background subtraction? To answer that question, we expressed the results in Fig. 2b as a function of the relative speed between the object and the background (i.e., fully correcting for the larger object-background displacements in the moving background condition). Plotted in that way, results (Fig. 2d) show that the presence of the moving background has no negative effect on motion segregation. In fact, we only found evidence for a trend for better motion segregation performance with moving backgrounds (F1,5 = 6.51, P = .051, η2 = 0.566). In other words, motion segregation with moving backgrounds can function at least as efficiently as detection of single moving object on a static background.

To summarize results thus far, we show that the visual system exhibits remarkable effectiveness at differentiating figural regions from their background based on motion under stimulus conditions that also promote strong spatial suppression. In such cases, segregation of moving objects can be several times more efficient than the perception of background motion per se. In the following experiments, we aim to determine whether perceptual insensitivity to background motion, in fact, causes increased visibility of object motion.

Explaining individual differences in motion segregation
Key insights into visual mechanisms can be derived from individual differences44–46. In context of the proposed functional link between spatial suppression and motion segregation, the hypothesis is that, for both young and older adults, spatial suppression strength should predict their ability to segregate moving objects (Exp. 3). We included older adults because senescence is associated with atypically weak spatial suppression42, raising a question of whether this atypicality is also associated with impairments in motion segregation.

To answer this question, we used four different tasks. The first two tasks (Fig. 3a) involved motion direction discriminations (upward vs. downward) of either a small (Fig. 3a, left) or a large moving stimulus (Fig. 3a, right). By testing how much performance deteriorates with increasing stimulus size, we were able to assess spatial suppression strength. The third task assessed motion segregation ability (as in Exp. 1), with observers asked to identify the tilt of a motion-defined object (Fig. 3b, left). Finally, to estimate the visibility of the target object motion on its own, we measured observers’ ability to discriminate the target object motion when shown without the moving background (Fig. 3b, right).Fig. 3 Age-related changes in spatial suppression and motion segregation. In separate blocks, observers discriminated motion directions (up vs. down) of small and large stimuli (a), and that of an oval object (b, right). In the motion segregation task (b, left), observers identified the orientation of a motion-defined object (left tilt vs. right tilt). Block arrows and the object outline are shown for illustration purposes only. Scale bar is 1°. (c) The effect of stimulus size on motion direction discriminations in young and older adults. Suppression index is defined as log10(large size threshold) – log10(small size threshold). (d) Motion segregation and motion discrimination of an oval shape in young and older adults. Motion segregation efficiency is defined as log10(figure-motion threshold) – log10(motion segregation threshold). All error bars are s.e.m.



Starting with consideration of motion discrimination (Fig. 3a), we found that both young and older observers exhibited increased thresholds for perceiving direction of motion with increasing size (Fig. 3c left, F1,36 = 223, P < 10−8, η2 = 0.861), a result indicating spatial suppression. Consistent with prior studies42,47, older adults were less affected by the increasing stimulus size (Fig. 3c left, F1,36 = 25, P = 10−5, η2 = 0.405). To quantify suppression strength, we computed the “suppression index” for each participant—a measure indexing one’s insensitivity to motion direction of large stimuli relative to the person’s ability to perceive motion of small stimuli42,48. The suppression index was considerably weaker in older adults (Fig. 3c right, t36 = 4.97, P = 10−5, Cohen’s d = 1.61).

Turning to motion segregation (Fig. 3b), young adults were able to perceive motion-defined objects with ease; their motion segregation thresholds were actually better than their ability to discriminate target object motion when shown without its moving background (Fig. 3d left, t36 = 2.69, P = 0.01, Cohen’s d = 0.76). Notably, however, older adults exhibited highly impaired motion segregation compared to younger adults (Fig. 3d left, t36 = 5.8, P = 10−6, Cohen’s d = 1.84). We can then estimate “motion segregation efficiency” by indexing motion segregation thresholds relative to the observers’ ability to discriminate motion of the target object motion when shown in isolation. Note that this index accounts for older observers’ decreased ability to perceive motion of the target object motion in isolation. Even with this correction, older adults’ motion segregation efficiency was lower than that of young observers (Fig. 3d right, t36 = 2.12, P = 0.041, Cohen’s d = 0.69). In sum, we found weaker spatial suppression and impaired motion segregation in older adults. The key question is whether these two processes are functionally related. We consider this question next, first with a correlational approach and then, in the subsequent section, with a causal approach.

With one telling exception, correlations among four experimental conditions (Fig. 3a, b) were strongly positive (0.55 < r < 0.90; all P < 10−4). This simply indicates that observers who performed well on one motion perception task tended to perform well on other motion tasks. The notable exception was a lack of significant relationship between motion segregation thresholds and thresholds for discriminating large background motions (r = −0.07; P = 0.67). This result suggests that in addition to general motion sensitivity that should affect both tasks similarly, there is at least one other factor that has an opposite effect. To investigate this possibility, we statistically controlled for the general motion sensitivity by computing correlations between motion segregation and discriminations of both small and large stimuli, while controlling for large and small stimulus thresholds, respectively. These partial correlations revealed that the link between motion perception and motion segregation strongly depended on stimulus size. Good motion segregation performance was associated with low thresholds for small stimuli (Fig. 4a; r = 0.78, P = 10−8) but also with inability to perceive large, background-like motions (Fig. 4b; r = −0.68, P = 10−5). The same pattern of results was observed in a complementary multiple regression analysis (R2 = 0.62, F2,35 = 28.2, P = 10−7), where thresholds for small moving stimuli had a significant positive contribution (B = 1.43, t35 = 7.48, P = 10−8), while large stimulus thresholds had a significant negative contribution (B = −0.77, t35 = −5.35, P = 10−5) to motion segregation performance. These results support the hypothesis that inability to perceive large moving stimuli at brief durations may underlie motion segregation ability. Indeed, thresholds for discriminating large moving stimuli were correlated with motion segregation efficiency, such that observers who were slower (i.e., needed longer stimulus durations) at perceiving large moving stimuli had better motion segregation efficiency (Fig. 4c; r = 0.69, P = 10−6). Similarly, suppression strength predicted motion segregation efficiency (Fig. 4d; r = 0.68, P = 10−6). The same pattern of results was found when we separately considered older and younger observers (Fig. 3c, d, dashed lines). In sum, we find strong correlational evidence for a link between spatial suppression and motion segregation.Fig. 4 The relationship between motion segregation and spatial suppression. a The relationship between standardized residuals for motion segregation and small stimulus tasks after regressing thresholds for the large stimulus from both. In both (a) and (b), higher values indicate worse performance. b The relationship between standardized residuals for motion segregation and large stimulus tasks after regressing thresholds for the small stimulus from both. Motion segregation efficiency is predicted by both c poor motion discriminations of large stimuli and d strong spatial suppression. Here, higher values indicate better motion segregation efficiency. Dashed lines are linear fits to young and older adult data. Solid lines are linear fits to the pooled data



Causal linking of motion segregation and spatial suppression
The first two sections show that spatial suppression correlates with motion segregation, both within and between observers. If these correlational links indeed reflect a functional link between motion segregation and mechanisms underlying spatial suppression, then the following prediction should hold: causing improvements in motion segregation should also come with concomitant changes in spatial suppression. To test this prediction (Exp. 4), we utilized perceptual learning to produce motion segregation improvements, hypothesizing that these improvements will result in the strengthening of spatial suppression (i.e., worse perception of large background-like motions). This approach is similar to prior studies that have exploited perceptual learning to forge causal links49,50.

We focused on older adults who, because of abnormally weak spatial suppression42,47 and poor motion segregation (Fig. 3c, d), have more room for improvements. In contrast, remarkably efficient motion segregation in young adults (Figs. 1–3) should limit or even preclude further training-dependent improvements (we confirmed this in our pilot explorations). Additionally, by focusing on older adults, we were able to determine whether perceptual training can at least partially alleviate age-related deficits in motion segregation (Fig. 3d).

During pre-training sessions, we measured size-dependency of motion discrimination thresholds for both horizontal and vertical motions at low (7%) and at high (99%) contrast. We included low contrast motions to test whether changes induced by motion segregation training are specific to suppressive processes, processes that are restricted to higher contrasts31,51 or simply result in more general motion perception improvements. The pre-training results for older adults (Fig. 5a) revealed spatial summation at low contrast and relatively weak or non-existent spatial suppression at high contrast, replicating earlier findings42. These data were fit with a simple descriptive model to characterize the strengths of summation and suppression47 (Equation 1, see “Methods” section). For comparison, we performed the same measurements in young adults (Fig. 5b). At high contrast, in addition to generally lower thresholds for young adults, the two groups differed in suppression strength, as indicated by a higher suppression slope (k2) in young adults (0.50 vs. 0.17, F1,7 = 26, P = 0.001, η2 = 0.785), replicating group differences in spatial suppression shown in Fig. 3. For both groups, there was neither a main effect of motion direction nor an interaction (all P > 0.11). At low contrast, consistent with prior work42, both groups had similarly low suppression (suppression slope: 0.067 vs. 0.096, F1,7 = 0, P = 1), with older adults exhibiting a pronounced elevation in thresholds. These data also help rule out size-dependent differences in attention as causing the observed age-related changes in motion perception. In this alternative explanation, differences in motion discriminations (Fig. 3c) and poor motion segregation (Fig. 3d) could be attributed to older adults being better at attending to large compared to small moving stimuli. However, in that case, we would expect similar results at low and at high contrast.Fig. 5 Effects of size and contrast on spatial summation and surround suppression in older adults. a Pre-training data for older adults. The results revealed spatial summation at low contrast and weak spatial suppression at high contrast, with no differences between horizontal and vertical motions. Data were fit with the model described in the “Methods” section. b Data for young adults shown for comparison purposes. All error bars are s.e.m.



Next, older adults underwent 16 sessions of perceptual training on a motion segregation task (as shown in the left side of Fig. 3b, but either with horizontal or vertical motions). By limiting training to one direction of motion, we were able to test the hypothesis, derived from evidence that perceptual learning for motion is directionally selective52,53, that changes in spatial suppression will be specific to that trained direction. Resultant thresholds were fit with an exponential function, whose slope provides an index of the magnitude of improvement, i.e., the degree of learning. The slope was negative (Fig. 6a; −0.054 ± 0.02 s.e.m.), indicating that, on average, motion segregation thresholds decreased over time. Different observers, however, exhibited varying amounts of learning, ranging from no learning to a ~25% improvement in motion segregation (abscissa in Fig. 6c). Later in this paper, we will return to these individual differences.Fig. 6 Perceptual learning of motion segregation affects spatial suppression. a Motion segregation performance as a function of the training session. Data were fit with an exponential function. Error bars are s.e.m. b Comparison of pre- and post-training motion direction discriminations at high contrast. Black lines are descriptive model fits to the post-training data (see “Methods” section), with the solid line indicating the trained motion direction. Gray lines are fits to the pre-training data. For clarity, pre-training thresholds are omitted and can be seen in Fig. 5a. Error bars are s.e.m. c The relationship between the amount of perceptual learning and the resultant change in spatial suppression strength for the trained motion direction. Error bars are 95% CI, revealing significant learning in 3 observers. The empty circle shows the average overall observers, with s.e.m as error bars. d Same as (b), except only showing data for observers who exhibited significant perceptual learning. For comparison, data for young adults is replotted from Fig. 5b (averaged over motion direction). Note that the y-axis is larger than in (b) to accommodate young adult data. e Same as (b), but for low contrast stimuli



A comparison of pre and post-training direction discriminations (Fig. 6b, gray vs. black lines) reveals that motion segregation training affected observers’ ability to perceive high contrast moving stimuli. Namely, spatial suppression strength for the trained motion directions increased after training, as evident by a relative increase in thresholds for large, high contrast motions (Fig. 6b, i.e., more pronounced upward bend for larger stimulus sizes but only for the trained motion direction). Analyzing results from individual observers, we found significant suppression slope increases in 3/5 observers for the trained motion direction (all P < 0.046; no changes for the untrained motion direction, all P > 0.21; see “Methods” section for bootstrap analysis details). Crucially, whether an observer showed a change in suppression strength was predicted by the amount of perceptual learning during the training phase; individual learning slopes strongly correlated with post-training increases in suppression strength (Fig. 6c; r = 0.97, P = 0.007). For the observers who showed significant perceptual learning, training-induced changes in spatial suppression were substantial (Fig. 6d). For the largest stimulus size, post-training thresholds were almost twice as high for the trained as the untrained motion directions, with the suppression slope more similar to young adults (Fig. 6d; 0.37 vs. 0.50; although thresholds for older adults remained atypically elevated). Post-training suppression slopes for observers who exhibited statistically significant learning were significantly higher than both their pre-training, trained-direction suppression slopes (t2 = 8.1, P = 0.015, Cohen’s d = 1.37) and post-training, untrained-direction suppression slopes (t2 = 6.9, P = 0.02, Cohen’s d = 1.27).

Notably, post-training changes were restricted to large stimulus sizes. We found no changes in observers’ ability to see small moving stimuli even though those stimuli were similar in size to the moving shape discriminated during training (gray bars in Fig. 6b, d). This size-specificity provides further evidence that reduced sensitivity to background motion is what drives improvements in motion segregation. Turning to low contrast data, we found very little effect of motion segregation training (Fig. 6e). We observed no evidence for spatial suppression either before or after training, with 19/20 95% CI around suppression slope (k2) including 0 (5 observers × 2 motion directions, both pre and post-training). Evidently, motion segregation training has no significant effect on motion discriminations at low contrast (Fig. 6e) and small stimulus size (Fig. 6b, d)—stimulus conditions that are unaffected by spatial suppression31. Moreover, the observation that training did not affect the ability to perceive small moving stimuli of any contrast (while improving motion segregation) further helps to rule out possible confounding effects of attention. Namely, it rules out the possibility that the observed age-related deficits were due to older adults having trouble attending to small moving stimuli. However, it is worth noting that small stimulus thresholds remain abnormally elevated for older adults, and this aspect of our results might be due, at least in part, to older adults’ reduced ability to focus spatial attention on small stimuli.

In sum, we found that perceptual training of motion segregation can alleviate age-related impairments in segmenting moving objects from moving backgrounds. Of note, this perceptual learning caused increased thresholds for perception of large, background-like motion but no changes in the sensitivity to small, object-like motions, highlighting the crucial role of background insensitivity in motion segregation.

A mechanistic model of spatial suppression
In the previous section, data were fit with a descriptive model. We chose that model as it is both very simple, with only three free parameters, and has been shown to closely capture spatial suppression and summation in both young and older adults47. However, while that model is appropriate to detect changes in behavioral spatial suppression, it is agnostic about mechanisms underlying spatial suppression. To gain insights into what changes might underlie the observed changes in spatial suppression, we also fit the data with a mechanistic model54. The model captures divisive interactions between responses of excitatory center and inhibitory surround regions, with responses varying with both stimulus contrast and size54. See Methods for implementation details. This model can capture spatial suppression and summation, as well as account for perceptual differences in special populations, such as older adults54 and children with autism55. Motivated by previous work54,55, we focused on estimating excitatory and inhibitory spatial pooling sizes (α, β) and response gain parameters (Ae, Ai), investigating how these parameters change as a function of motion segregation training. Because of the mechanistic nature of the model, we fit low and high contrast data together with the same model. We fit the model to each observer individually as well as to the observers who showed significant perceptual learning of motion segregation.

The mechanistic model provided a good fit to the data (Tables 1−3: all R2 > 0.931, χ2 < 1.27, P > 0.99995). When compared to younger adults (Table 1), older adults exhibited weaker excitatory and inhibitory gains, as well as broader spatial properties that, relative to young adults, were less biased toward inhibitory spatial pooling (i.e., smaller β/α). This pattern of differences is consistent with prior results for higher spatial frequency stimuli54. Considering the effects of training (Tables 2 and 3), modeling results provided statistically significant evidence indicating that motion segregation training leads to an increase in the relative size of the inhibitory spatial pooling (β/α). This was the case when comparing post-training to pre-training models (Table 2) and when comparing untrained and trained motion directions at post-training (Table 3; Fig. 7). For the latter comparison, we also observed an increase in the inhibitory spatial pooling (Table 3). Considering model fits for individual observers, β/α significantly increased for two observers that exhibited the strongest learning (the rightmost points in Fig. 6c), both when comparing pre- and post-training (Ps < 0.047 see “Methods” section for bootstrap analysis details) and when comparing trained and untrained motion directions (Ps < 0.004).Table 1 Model parameters, comparing young and older adults

		
A
e
	
A
i
	
α
	
β
	β/α	
Young adults	Estimates	204.2	28.6	0.57	0.76	1.34	
95% CI	[184.2, 219.3]	[26.4, 30.9]	[0.49, 0.65]	[0.67, 0.87]	[1.32, 1.37]	
Older adults	Estimates	122.6	18.2	0.75	0.88	1.18	
95% CI	[98.4, 147.1]	[15.0, 22.5]	[0.58, 0.97]	[0.66, 1.15]	[1.13, 1.25]	
P-values	<0.001	<0.001	0.026	0.19	<0.001	
Table 2 Model parameters, comparing pre-training vs. post-training for the trained motion direction

		
A
e
	
A
i
	
α
	
β
	β/α	
Pre-training	Estimates	109.5	18.7	0.80	0.96	1.21	
95% CI	[78.8, 147.9]	[11.4, 28.1]	[0.62, 1.09]	[0.71, 1.30]	[1.15, 1.28]	
Post-training	Estimates	117.3	21.8	0.83	1.06	1.28	
95% CI	[87.9, 138.5]	[15.1, 27.1]	[0.74, 0.97]	[0.92, 1.22]	[1.26, 1.34]	
P-values	0.34	0.26	0.39	0.22	0.020	
Table 3 Model parameters, comparing post-training results for untrained and trained motion directions

		
A
e
	
A
i
	
α
	
β
	β/α	
Untrained	Estimates	113.6	17.0	0.77	0.87	1.13	
95% CI	[79.2, 139.2]	[12.9, 20.1]	[0.69, 0.97]	[0.75, 1.03]	[1.07, 1.25]	
Trained	Estimates	117.3	21.8	0.83	1.06	1.28	
95% CI	[87.9, 138.5]	[15.1, 27.1]	[0.74, 0.97]	[0.92, 1.22]	[1.26, 1.34]	
P-values	0.39	0.11	0.27	0.039	<0.001	
Fig. 7 Mechanistic model fits. Low and high contrast data are shown for observers that exhibited significant perceptual learning, contrasting the trained and the untrained motion direction. Lines are mechanistic model fits as described in the main text and “Methods” section. All error bars are s.e.m.



Discussion
The defining perceptual consequence of spatial suppression is insensitivity to supra-threshold background-like motions. This effect is widely replicated12 and strong: duration thresholds for motion discriminations of large stimuli can be a factor of two (Fig. 2a) or more31 times higher than those for perceiving small moving objects. Here, we show that this seemingly maladaptive loss of sensitivity, in fact, is associated with the promotion of an important visual function: motion segregation. Both stimulus-dependent and individual variations in spatial suppression strength predict observers’ ability to segregate moving objects. Moreover, perceptual learning of motion segregation caused strengthening of spatial suppression. These behavioral findings support theoretical work13,16,17 that argues for functional involvement of surround suppression in motion segregation. Neurophysiological studies also postulated that motion segregation is a functional role of surround suppression15,56—a hypothesis receiving some support19. Using psychophysical spatial suppression as a behavioral correlate of neural surround suppression mechanisms32–35, we provide the first direct behavioral evidence for this link.

How does spatial suppression facilitate motion segregation? Consider a motion segregation situation involving a small moving object appearing within a background of motion. Because of spatial suppression, the visual sensitivity to background motion will be considerably worse than the visibility of the object’s motion. This is particularly true for very brief exposures for which large background motion is imperceptible yet the motion of a small object is readily visible57. That is also evident in the present results (Figs 1, 3), where stimulus durations needed for motion segregation are between 1/3rd to 1/7th of durations needed to perceive large background motions. Through this insensitivity to background motion, the visual system effectively accomplishes background subtraction and, as a result, increases visual saliency of object motion16. From a computational standpoint, this is an efficient strategy because motion segregation is achieved by suppressing irrelevant information, rather than enhancing relevant figure information, reducing the overall responsiveness of the system46. Consistent with this idea, motion segregation learning only affected the sensitivity to large motions, having no effect on the discriminability of small moving stimuli (Fig. 6b, d). Moreover, the object detection experiment (Fig. 2) showed that vision can fully account for the moving background under conditions that support spatial suppression. This concept of background subtraction is found in a number of domains, including in the retina where it functions to eliminate uniform image motion due to small eye movements58. Our ability to estimate motion of objects during self-motion also appears to depend on a mechanism that globally subtracts optic flow signals caused by self-motion59. In computer vision, background subtraction is used to segment foreground objects, a strategy that is particularly effective when there is a common background motion17,36–39. Furthermore, background subtraction can be used to enhance odor discrimination60, suggesting that it may be a general computational strategy used across different modalities.

The key result of our study is the firm establishment of a link between behavioral spatial suppression, a seemingly maladaptive visual phenomenon, with an important functional role: visual motion segregation. In addition, we also applied a model54,55 to gain insights into what mechanistic changes in surround suppression might occur together with improvements in motion segregation. The model showed that, as a result of motion segregation training, the size of the suppressive spatial pooling becomes larger relative to the integrative (i.e., excitatory) spatial pooling. Such a mechanism would make responses to large stimuli weaker, plausibly leading to stronger behavioral spatial suppression. Notably, the previous work54 indicates that aging is associated with abnormal spatial pooling of motion that favors spatial integration of motion signals. Our study suggests that motion segregation training may modify this age-related abnormality. These results, while providing clues into potential underlying mechanisms of spatial suppression, should be interpreted with caution. As with all mechanistic models, the one presented here is constrained by assumptions made about underlying mechanisms—a question that is still under debate for surround suppression in motion34,35,61. Note, however, that this limitation does not affect the demonstrated link between spatial suppression and motion segregation (Fig. 1–6), as both of these characteristics of motion perception are operationalized on a behavioral level.

We argue that many of the relevant motion segregation processes occur on relatively brief time scales4, likely driven by evolutionary pressure to rapidly segregate moving objects. Our results show that a 16 ms stimulus exposure is sufficient to segregate a motion-defined object (Fig. 2b)—a perceptual ability that we link with mechanisms underlying spatial suppression. While spatial suppression effects have been found over a range of time scales31,57,62–65, marked suppression of large moving stimuli is found only for brief presentations31,57. This poor perceptual sensitivity to large moving stimuli when presented briefly is consistent with a strong bias of MT responses toward representing object rather than background motions at brief durations32. While surround suppressed MT neurons exhibit good directional selectivity for small brief stimuli, wide-field MT neurons have poor directional selectivity for brief stimuli of any size. In other words, neurons that are well suited to represent background motion do not do so for brief stimuli. Importantly, this study32 shows that the earliest directionally selective responses in area MT will be those representing motion of small stimuli, effectively segregating those responses from background motion responses. Whether this temporal segregation of responses is explicitly used as a motion segregation cue is an open question.

Thinking broadly, our findings also raise the question of possible negative consequences of suppressing large moving stimuli, since such motions are undoubtedly useful for other visual functions. However, we previously showed that despite its dramatic effects on visibility of large background motions, spatial suppression has little effect on second-order motion66, motion adaptation67 and ocular following reflexes (OFR)68. This specificity of spatial suppression to perception of first-order motion, we argue, is adaptive. While insensitivity to background motion can improve segregation of moving objects, some motion processes, such as OFR, require high sensitivity to large moving stimuli.

By including older adults in our study, we were able to exploit the additional variability in spatial suppression strength to explore its role in motion segregation. The results revealed that previously reported better-than-normal motion sensitivity to large moving stimuli42 comes at a cost of impaired motion segregation. Here, we speculate that in the aging visual system, the benefits of rapid motion segregation are outweighed by the need for enhanced spatial integration of motion signals, signals that might be atypically noisy at old age. In other words, the demands of vision at old age shift the discrimination/integration balance toward enhanced integration69. Moreover, these results predict that other populations that exhibit abnormally weak spatial suppression (schizophrenia48, major depression70) should also exhibit similar deficits in motion segregation. The observed trade-off between integration and segregation is not unique to motion segregation, but is ubiquitous in visual processing6,71,72, other sensory modalities7,8,11 as well as cognitive function9,10. In our study, we show that conditions promoting spatial sensitivity and integration, such as low contrast, are associated with poor segmentation, and vice versa (Fig. 1). For older adults, this balance can be changed as a result of motion segregation training (Fig. 6). While it may seem counterintuitive that perceptual learning of one motion task results in worsening motion perception on another task, this result is entirely consistent with the functional link between spatial suppression and motion segregation. This link appears to be adaptive, where computationally useful suppressive mechanisms are only utilized when motion signals are sufficiently strong. For slow, low contrast and noisy motions, integrative mechanisms dominate31,43.

In summary, we report behavioral evidence for both correlational and causal links between motion segregation and mechanisms underlying spatial suppression. We conclude that perceptual insensitivity to large, background-like moving stimuli effectively implements background subtraction, in turn enhancing the relative visibility of moving objects.

Methods
General methods
All procedures complied with guidelines set by institutional review boards at Vanderbilt University and University of Rochester. All participants gave written informed consent. Stimuli were created in MATLAB and Psychophysics Toolbox. All experiments measured duration thresholds31,35,42,46,47,51,57,70,73–75, estimating the minimum stimulus duration required for threshold-level performance. Duration thresholds were estimated by interleaved QUEST staircases converging to 82% correct76. Feedback was provided for each trial.

Covariation of motion segregation and spatial suppression
In Experiment 1, stimuli were shown on a linearized monitor (1024 × 768 resolution, 120 Hz). Viewing was binocular at 83 cm (yielding 1.5 × 1.5 arcmin per pixel). Ambient and background illuminations were 4.8 cd m−2 and 60.5 cd m−2. The stimuli were moving random-texture patterns consisting of light and dark elements (each 3 × 3 arcmin) presented in a 2D raised cosine envelope (Fig. 1a, b). From frame to frame of the animation, half of the pixels shifted in one direction (6.2° s−1) while the remaining pixels were randomly regenerated (50% correlation). 50% correlation was used to slightly increase task difficulty and, thus, avoid possible floor effects. These conditions produced vivid motion perception at suprathreshold exposure durations. The stimulus size was fixed and relatively large (radius = 5.3°). To allow presentation of brief motion stimuli, stimulus contrast was ramped on and off with a temporal Gaussian envelope (duration is defined as the 2σ of the temporal Gaussian). For each condition, four young adult observers (two females and two males; three naïve observers; age range: 19–25) ran four pairs of interleaved staircases, with the first pair discarded as practice.

The motion discrimination and segregations tasks were conducted at 6 contrast levels each (9–92%). This yielded 12 conditions whose order was randomized. In the motion discrimination task, observers identified motion direction of a random-texture pattern that moved either upward or downward (Fig. 1a). In the motion segregation task, observers discriminated between two motion-defined shapes (Fig. 1b, 45° rightward tilted ellipse vs. 45° leftward tilted ellipse). The texture elements within the elliptic region moved either upward or downward (direction randomly chosen on each trial), while the texture elements outside the elliptic region moved in the opposite direction. Long and short axes of the ellipse were 2.28° and 1.14°, respectively. Note that the single frames from the motion and figure-ground discriminations tasks are indistinguishable (i.e., both are featureless random-texture patterns as shown in Fig. 1a, b).

In Experiment 2, stimuli were presented on a natively linear DLP projector (DepthQ WXGA 360, 1280 × 720 resolution) at 360 Hz with each pixel subtending 2 arcmin of visual angle (146 cm viewing distance). Ambient and background illuminations were 1.8 cd/m2 and 113.7 cd/m2. The same random-texture patterns with light and dark elements each subtending 8’ × 8’ were used as in the other experiments, but they were low-pass filtered (Fig. 2a; cutoff frequency, 1.12 cycles/degree) to eliminate motion blur cues to the object location. Observers’ task was to segregate the motion-defined object from its background and report its location (Fig. 2a). The object could appear in one of four quadrants at 2.25° eccentricity, and the background could either move in the opposite direction from the object, or was stationary. The size of the background and the objects were 12° and 0.75° in radius, respectively. Two contrast levels were used: 99% for the high contrast, and 3% for the low contrast condition. Duration thresholds were measured across five different speed levels (1°, 2°, 4°, 8°, and 16° −1), with one exception being the exclusion of 1°/s stimuli at low contrast (as such stimuli were difficult to see at any duration). Stimulus duration was defined as full-width at half-height of the temporal contrast envelope, which was a hybrid-Gaussian33. Observers completed four blocks (each with two interleaved QUEST staircases per speed level) for both moving and stationary background conditions. The first block was considered as practice and discarded from analysis. Six naïve young adult observers participated in the experiment (five female, one male; age range: 19–28). One observer had difficulty with 3% contrast stimuli, so this observer did the low contrast task at 3.5%. The data with and without this subject were qualitatively the same.

Explaining individual differences in motion segregation
In Experiment 3, stimuli were shown on a linearized high-speed PROCALIX monitor (Totoku, Irving, TX, 21 in, 800 × 600 resolution, 200 Hz). 200 Hz frame rate ensured that our measurements were not affected by frame-sampling limitations64, allowing us to use fully coherent motion. Viewing was binocular at 114 cm. Ambient and background illuminations were 0.15 and 41.5 cd m−2. Stimulus duration was defined in the same manner as in Experiment 2. All stimuli were composed of random-texture patterns that consisted of light and dark elements (each 4.5’ × 4.5’, Fig. 1). To produce motion, texture elements uniformly shifted in position on each frame (i.e., 100% coherence), yielding speed of 5° s−1. Stimuli were shown in stationary raised cosine spatial envelopes, whose radii defined stimulus size.

21 young (mean age = 22.5, std. = 4.18, age range = 18–35) and 21 older adults (mean age 67.7, std. = 5.88, age range: 60–84; 13 female, 8 male) participated. Older adults underwent basic cognitive screening (Modified Telephone Interview for Cognitive Status score over 30; absence of diagnosis of Alzheimer’s disease, no reported neuropsychological deficits, recent severe medical conditions (e.g., stroke) and severe sensory or motor loss). Four types of moving stimuli were used (Fig. 3a, b), all presented at 99% peak stimulus contrast. In two of the tasks (Fig. 3a), observers discriminated motion direction (up vs. down) of small (r = 0.75°) and large (r = 5°) moving stimuli. The small stimulus size was chosen to be near optimal, while the large stimulus was sufficiently large to yield strong spatial suppression51. To estimate motion segregation ability, observers identified the orientation of a motion-defined shape (Fig. 3b, left; 45° left vs. 45° right tilt, randomly chosen) embedded in a large moving background (r = 5°). Long and short radii of the elliptical shape were 0.7° and 0.35°. The pixels within the elliptical figure moved either up or down (randomly chosen), while the pixels outside the elliptical region (i.e., background) moved in the opposite direction. Finally, observers conducted a figure-motion discrimination task. Here, the above-described motion segregation stimulus was used but without background motion. The observers’ task was to simply identify its motion direction. Shape orientation was chosen randomly for each block of trials, remaining constant for its duration. Note that all motion discrimination tasks involved discriminating between up and down motions. This was done to avoid response the possible confusion in the motion segregation task (which involved right vs. left tilt decisions).

For each of the four conditions, observers completed four pairs of interleaved staircases conducted in four sessions of trials. Within each session, the order of four conditions was randomized, each tested in a separate block. Before each block, a screen displaying the task instructions and an exaggerated stimulus example was shown. Overall, this procedure yielded four pairs of thresholds for each condition. The first pair was used as task practice and to set the starting points for subsequent staircases. Next, the lowest and the highest results were eliminated, and the remaining thresholds were averaged. We routinely use this exclusion of extreme values when working with subjects that are inexperienced with psychophysics46,75,77. For the present data sets (Figs. 3 and 4), removing extreme values improved the average split-half reliability from 0.87 to 0.95 (just looking at older observers, the reliability was 0.94). Data for 1 young and 3 older adults were excluded because data variability (defined as standard deviation, SD, of threshold measurements for individual conditions) was 3 SD higher than the average variability.

Causal linking of motion segregation and spatial suppression
Experiment 4 included three parts: pre-training measures, motion segregation training, and post-training measures. The equipment and most stimulus parameters were same as in Experiment 3. Observers were older adults (n = 5; mean age = 68.2, std. = 4.92, age range = 64–76; two females, three males). For both pre- and post-training measures, we characterized size-dependency of motion direction discriminations for two contrasts (7% and 99%). At high contrast, stimulus sizes were r = 0.43°, 0.75°, 1.33°, 2.33°, 4°, and 7°. At low contrast, the smallest size was omitted because of its poor visibility. These measurements were done for both horizontal (left vs. right) and vertical (up vs. down) motion direction discriminations, tested in two consecutive counterbalanced sessions. Each session consisted of 11 randomized blocks of trials, each consisting of one size-contrast combination. In each block, two thresholds were estimated. This entire sequence was repeated on four separate days, yielding a total of 8 thresholds per condition. The first day was taken as practice.

During motion segregation training, each observer completed 16 perceptual training sessions conducted on separate days (taking 4–5 weeks). In each session, observers completed 10–12 blocks of motion segregation, with two interleaved QUEST staircases per block. Motion segregation task was as described above, except that figure and background motions were either both horizontal or both vertical. This was pseudo-randomly assigned for each observer (3 vertical, 2 horizontal), remaining constant throughout the training.

To describe size-dependency of motion perception, we used a simple descriptive model that has been shown to closely capture size and contrast-dependency of duration thresholds for both young and older adults47. Namely, we fit the pre- and post-training results with: 1 f(x)=p1xk1+p2xk2,withk1fixedat-2. where x is the stimulus size, p1 and p2 set the height of the descending (i.e., summation) and ascending (i.e., suppression) portions of the curve, while the k1 and k2 parameters determine the descending and ascending slopes. Parameter k1 was set to −2, to incorporate linear temporal summation47. We confirmed this assumption by separately fitting k1 as a free parameter, which resulted with the average fitted value across all conditions of −1.99. For our purposes, the key parameter is the suppression slope (k2). Change in k2 (namely smaller k2) closely describes age-related changes in spatial suppression47.

A mechanistic model of spatial suppression
Data from the perceptual training experiment (Experiment 4) were fitted with a mechanistic model that captures size- and contrast-dependent interactions between the receptive field center and surround54. Namely, the model includes an excitatory center (E) and an inhibitory surround (I): 2 E(w)=1-e-wα22,  3 I(w)=1-e-wβ22, where w is stimulus size (in degrees), while α and β are size constants for the center and the surround spatial pooling, respectively. Both the center and surround responses depend non-linearly on stimulus contrast, as determined by the Naka-Rushton function: 4 Ke(c)=Aecnecne+c50ene,  5 Ki(c)=Aicnicni+c50ini, where c is stimulus contrast, while excitatory and inhibitory regions are captured by parameters determining response gain (Ae, Ai), semi-saturation point (c50e, c50i) and slope (ne, ni), respectively. The overall response is determined by the ratio of the responses in the center and surround (i.e., inhibition is divisive): 6 R(w,c)=Ke(c)⋅E(w)1+Ki(c)⋅I(w), which is then converted to thresholds: 7 T=CriterionR0+R. 

Criterion and R0 scale the model responses to perceptual thresholds, and were fixed to 20 and 6, respectively, following the previous work54.

Both at pre-training and at post-training, we estimated spatial pooling size (α, β) and response gain parameters (Ae, Ai) (the key parameters of interest), while fixing other parameters (c50e, c50i, ne, ni were fixed to 0.2, 0.2, 3, and 5, respectively). Changing values of fixed parameters (i.e., slopes and semi-saturation constants) had minimal effects on the model fits (largely because the fitted data consisted of only low and high contrasts). The model was fitted using the least squares procedure.

Statistics
For most analysis, conventional statistical tests were used (ANOVA, t-test and Pearson correlation). All tests were two-tailed. For models, non-parametric bootstrap was used to obtain 95% confidence intervals (CI) and associated statistical significance for the descriptive model. Specifically, for each observer, individual thresholds (for the condition of interest) were sampled with replacement (9999 and 1000 bootstrap samples for the descriptive and the mechanistic model, respectively), and the model fitted to each set of samples. The 95% confidence intervals and p-values were extracted from the resampled distributions. We compiled difference distributions (pre-training vs. post-training, untrained vs. trained directions (post-training), or younger vs. older (pre-training), depending on the analysis) for each model parameter. p-values were determined by the proportion of samples that “crossed” zero.

Reporting summary
Further information on research design is available in the Nature Research Reporting Summary linked to this article.

Supplementary information

Transparent Peer Review File

 
Reporting Summary

 


Peer review information:
Nature Communications thanks Robbe Goris and other anonymous reviewer(s) for their contribution to the peer review of this work. Peer reviewer reports are available.

Publisher’s note: Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.

Supplementary information
Supplementary Information accompanies this paper at 10.1038/s41467-019-10653-8.

Acknowledgements
This work was supported by a NIH NEI grant R01 EY019295 to D.T and awards NEI P30 EY001319, T32 EY007125 and T32 EY007135-19.

Author contributions
Conceptualization: D.T., W.J.P., J.S.L. and R.B.; Methodology: D.T. and W.J.P.; Software: D.T. and W.J.P.; Formal analysis: D.T. and W.J.P.; Investigation: D.T., W.J.P., K.C.D. and M.D.M.; Writing—Original draft: D.T.; Writing—Review & Editing: D.T., W.J.P., K.C.D., M.D.M., J.S.L. and R.B.; Funding acquisition: D.T.

Data availability
The data sets generated during and/or analyzed during the current study (Figs. 1–7) are available from the corresponding author on request.

Code availability
Modeling computer code (MATLAB) is also available on request.

Competing interests
The authors declare no competing interests.
==== Refs
References
1. Regan, D. Human perception of objects (Sinauer Press, Sunderland, MA, 2000).
2. Helmholtz, H. V. Handbook of physiological optics. 3rd edn, (Dover, 1910/1962).
3. Lettvin JY  Maturana HR  McCulloch WS  Pitts WH   What the frog’s eye tells the frog’s brain Proc. IRE 1959 47 1940 1951 10.1109/JRPROC.1959.287207 
4. Park, W. J. & Tadin, D. in The Stevens’ Handbook of Experimental Psychology and Cognitive Neuroscience: Sensation, Perception & Attention (ed J. Serences) 415–488 (Wiley, 2018).
5. Zahar, Y., Lev-Ari, T., Wagner, H. & Gutfreund, Y. Behavioral evidence and neural correlates of perceptual grouping by motion in the barn owl. J. Neurosci.38, 6653–6664 (2018).
6. Braddick O   Segmentation versus integration in visual motion processing Trends Neurosci. 1993 16 263 268 10.1016/0166-2236(93)90179-P 7689769 
7. Chu MW  Li WL  Komiyama T   Balancing the robustness and efficiency of odor representations during learning Neuron 2016 92 174 186 10.1016/j.neuron.2016.09.004 27667005 
8. Ollerenshaw DR  Zheng HJV  Millard DC  Wang Q  Stanley GB   The adaptive trade-off between detection and discrimination in cortical representations and behavior Neuron 2014 81 1152 1164 10.1016/j.neuron.2014.01.025 24607233 
9. Roach NW  McGraw PV  Whitaker DJ  Heron J   Generalization of prior information for rapid Bayesian time estimation Proc. Natl Acad. Sci. USA 2017 114 412 417 10.1073/pnas.1610706114 28007982 
10. Sims CR   Efficient coding explains the universal law of generalization in human perception Science 2018 360 652 656 10.1126/science.aaq1118 29748284 
11. Tian LY  Brainard MS   Discrete Circuits Support Generalized versus Context-Specific Vocal Learning in the Songbird Neuron 2017 96 1168 1177 e1165 10.1016/j.neuron.2017.10.019 29154128 
12. Tadin D   Suppressive mechanisms in visual motion processing: From perception to intelligence Vis. Res 2015 115 58 70 10.1016/j.visres.2015.08.005 26299386 
13. Nakayama K  Loomis JM   Optical velocity patterns, velocity-sensitive neurons, and space perception - hypothesis Perception 1974 3 63 80 10.1068/p030063 4444922 
14. Born RT  Bradley DC   Structure and function of visual area MT Annu. Rev. Neurosci. 2005 28 157 189 10.1146/annurev.neuro.26.041002.131052 16022593 
15. Allman J  Miezin F  McGuinness E   Direction- and velocity-specific responses from beyond the classical receptive field in the middle temporal visual area (MT) Perception 1985 14 105 126 10.1068/p140105 4069941 
16. Gao, D., Mahadevan, V. & Vasconcelos, N. On the plausibility of the discriminant center-surround hypothesis for visual saliency. J. Vis.8, 13.1–18 (2008).
17. Petkov N  Subramanian E   Motion detection, noise reduction, texture suppression, and contour enhancement by spatiotemporal Gabor filters with surround inhibition Biol. Cyber. 2007 97 423 439 10.1007/s00422-007-0182-0 
18. Sachtler WL  Zaidi Q   Visual processing of motion boundaries Vis. Res 1995 35 807 826 10.1016/0042-6989(94)00160-N 7740772 
19. Born RT  Groh JM  Zhao R  Lukasewycz SJ   Segregation of object and background motion in visual area MT: effects of microstimulation on eye movements Neuron 2000 26 725 734 10.1016/S0896-6273(00)81208-8 10896167 
20. Bradley DC  Andersen RA   Center-surround antagonism based on disparity in primate area MT J. Neurosci. 1998 18 7552 7565 10.1523/JNEUROSCI.18-18-07552.1998 9736673 
21. Hu J    Visual motion processing in Macaque V2 Cell Rep. 2018 25 157 167 e155 10.1016/j.celrep.2018.09.014 30282025 
22. Marcar VL  Raiguel SE  Xiao D  Orban GA   Processing of kinetically defined boundaries in areas V1 and V2 of the macaque monkey J. Neurophysiol. 2000 84 2786 2798 10.1152/jn.2000.84.6.2786 11110809 
23. Buracas GT  Albright TD   Contribution of area MT to perception of three-dimensional shape: a computational study Vis. Res 1996 36 869 887 10.1016/0042-6989(95)00192-1 8736221 
24. Carandini M  Heeger DJ   Normalization as a canonical neural computation Nat. Rev. Neurosci. 2012 13 51 62 10.1038/nrn3136 
25. Schwartz O  Simoncelli EP   Natural signal statistics and sensory gain control Nat. Neurosci. 2001 4 819 825 10.1038/90526 11477428 
26. Sillito AM  Grieve KL  Jones HE  Cudeiro J  Davis J   Visual cortical mechanisms detecting focal orientation discontinuities Nature 1995 378 492 496 10.1038/378492a0 7477405 
27. Vinje WE  Gallant JL   Sparse coding and decorrelation in primary visual cortex during natural vision Science 2000 287 1273 1276 10.1126/science.287.5456.1273 10678835 
28. Xiao DK  Raiguel S  Marcar V  Koenderink J  Orban GA   Spatial heterogeneity of inhibitory surrounds in the middle temporal visual area Proc. Natl Acad. Sci. USA 1995 92 11303 11306 10.1073/pnas.92.24.11303 7479984 
29. Cui Y  Liu LD  Khawaja FA  Pack CC  Butts DA   Diverse suppressive influences in area MT and selectivity to complex motion features J. Neurosci. 2013 33 16715 16728 10.1523/JNEUROSCI.0203-13.2013 24133273 
30. Royden CS   Computing heading in the presence of moving objects: a model that uses motion-opponent operators Vis. Res 2002 42 3043 3058 10.1016/S0042-6989(02)00394-2 12480074 
31. Tadin D  Lappin JS  Gilroy LA  Blake R   Perceptual consequences of centre-surround antagonism in visual motion processing Nature 2003 424 312 315 10.1038/nature01800 12867982 
32. Churan J  Khawaja FA  Tsui JMG  Pack CC   Brief motion stimuli preferentially activate surround-suppressed neurons in macaque visual area MT Curr. Biol. 2008 18 R1051 R1052 10.1016/j.cub.2008.10.003 19036331 
33. Tadin D  Silvanto J  Pascual-Leone A  Battelli L   Improved motion perception and impaired spatial suppression following disruption of cortical area MT/V5 J. Neurosci. 2011 31 1279 1283 10.1523/JNEUROSCI.4121-10.2011 21273412 
34. Liu, L. D., Haefner, R. M. & Pack, C. C. A neural basis for the spatial suppression of visual motion perception. Elife5, 10.7554/eLife.16167 (2016).
35. Schallmo, M. P. et al. Suppression and facilitation of human neural responses. Elife7, 10.7554/eLife.30334 (2018).
36. Huang SS  Fu LC  Hsiao PY   Region-level motion-based background modeling and subtraction using MRFs IEEE T Image Process 2007 16 1446 1456 10.1109/TIP.2007.894246 
37. Ross MG  Kaelbling LP   Segmentation according to natural examples: learning static segmentation from motion segmentation IEEE T Pattern. Anal. 2009 31 661 676 10.1109/TPAMI.2008.109 
38. Elgammal A   Background subtraction: Theory and practice Synth. Lect. Comput. Vis. 2014 5 1 83 10.2200/S00613ED1V01Y201411COV006 
39. Sobral A  Vacavant A   A comprehensive review of background subtraction algorithms evaluated with synthetic and real videos Comput. Vis. Image Under. 2014 122 4 21 10.1016/j.cviu.2013.12.005 
40. Kunnapas TM   Experiments on figural dominance J. Exp. Psychol. 1957 53 31 39 10.1037/h0042462 13398539 
41. Oyama T   Figure-ground dominance as a function of sector angle, brightness, hue, and orientation J. Exp. Psychol. 1960 60 299 305 10.1037/h0041175 13731822 
42. Betts LR  Taylor CP  Sekuler AB  Bennett PJ   Aging reduces center-surround antagonism in visual motion processing Neuron 2005 45 361 366 10.1016/j.neuron.2004.12.041 15694323 
43. Lappin JS  Tadin D  Nyquist JB  Corn AL   Spatial and temporal limits of motion perception across variations in speed, eccentricity, and low vision J. Vis. 2009 9 30 31 14 
44. Wilmer JB  Nakayama K   Two distinct visual motion mechanisms for smooth pursuit: evidence from individual differences Neuron 2007 54 987 1000 10.1016/j.neuron.2007.06.007 17582337 
45. Wilmer J   How to use individual differences to isolate functional organization, biology, and utility of visual perception; with illustrative proposals for stereopsis Spat. Vis. 2008 21 561 579 10.1163/156856808786451408 19017483 
46. Melnick MD  Harrison BR  Park S  Bennetto L  Tadin D   A strong interactive link between sensory discriminations and intelligence Curr. Biol. 2013 23 1013 1017 10.1016/j.cub.2013.04.053 23707433 
47. Betts LR  Sekuler AB  Bennett PJ   Spatial characteristics of center-surround antagonism in younger and older adults J. Vis. 2009 9 25 21 15 
48. Tadin D    Weakened center-surround interactions in visual motion processing in schizophrenia J. Neurosci. 2006 26 11403 11412 10.1523/JNEUROSCI.2592-06.2006 17079669 
49. Shibata K  Watanabe T  Sasaki Y  Kawato M   Perceptual learning incepted by decoded fMRI neurofeedback without stimulus presentation Science 2011 334 1413 1415 10.1126/science.1212003 22158821 
50. Sotiropoulos G  Seitz AR  Series P   Perceptual learning in visual hyperacuity: A reweighting model Vis. Res 2011 51 585 599 10.1016/j.visres.2011.02.004 21316384 
51. Tadin D  Lappin JS   Optimal size for perceiving motion decreases with contrast Vis. Res 2005 45 2059 2064 10.1016/j.visres.2005.01.029 15845238 
52. Ball K  Sekuler R   Direction-specific improvement in motion discrimination Vis. Res 1987 27 953 965 10.1016/0042-6989(87)90011-3 3660656 
53. Zhang, R. & Tadin, D. Disentangling locus of perceptual learning in the visual hierarchy of motion processing. Sci Rep7, 10.1038/s41598-018-37892-x (2018).
54. Betts LR  Sekuler AB  Bennett PJ   Spatial characteristics of motion-sensitive mechanisms change with age and stimulus spatial frequency Vis. Res 2012 53 1 14 10.1016/j.visres.2011.11.004 22100817 
55. Schauder KB  Park WJ  Tadin D  Bennetto L   Larger receptive field size as a mechanism underlying atypical motion perception in autism spectrum disorder Clin. Psychol. Sci. 2017 5 827 842 10.1177/2167702617707733 28989818 
56. Born RT  Tootell RB   Segregation of global and local motion processing in primate middle temporal visual area Nature 1992 357 497 499 10.1038/357497a0 1608448 
57. Glasser, D. M. & Tadin, D. Low-level mechanisms do not explain paradoxical motion percepts. J. Vis.10, 20.1–9 (2010).
58. Olveczky BP  Baccus SA  Meister M   Segregation of object and background motion in the retina Nature 2003 423 401 408 10.1038/nature01652 12754524 
59. Warren PA  Rushton SK   Optic flow processing for the assessment of object movement during ego movement Curr. Biol. 2009 19 1555 1560 10.1016/j.cub.2009.07.057 19699091 
60. Sturgill JF  Isaacson JS   Somatostatin cells regulate sensory response fidelity via subtractive inhibition in olfactory cortex Nat. Neurosci. 2015 18 531 535 10.1038/nn.3971 25751531 
61. Liu LD  Miller KD  Pack CC   A Unifying Motif for Spatial and Directional Surround Suppression J. Neurosci. 2018 38 989 999 10.1523/JNEUROSCI.2386-17.2017 29229704 
62. Neri P  Levi D   Surround motion silences signals from same-direction motion J. Neurophysiol. 2009 102 2594 2602 10.1152/jn.00489.2009 19726727 
63. Paffen CLE  Tadin D  Pas SFT  Blake R  Verstraten FAJ   Adaptive center-surround interactions in human vision revealed during binocular rivalry Vis. Res 2006 46 599 604 10.1016/j.visres.2005.05.013 16005041 
64. Tadin D  Lappin JS  Blake R   Fine temporal properties of center-surround interactions in motion revealed by reverse correlation J. Neurosci. 2006 26 2614 2622 10.1523/JNEUROSCI.4253-05.2006 16525040 
65. Tadin, D., Paffen, C. L. E., Blake, R. & Lappin, J. S. Contextual modulations of center-surround interactions in motion revealed with the motion aftereffect. J. Vis. 8, 9.1–11 (2008).
66. Glasser, D. M. & Tadin, D. Increasing stimulus size impairs first-but not second-order motion perception. J. Vis.11, pii: 22 (2011).
67. Glasser DM  Tsui JMG  Pack CC  Tadin D   Perceptual and neural consequences of rapid motion adaptation Proc Natl Acad. Sci. USA 2011 108 E1080 E1088 10.1073/pnas.1101141108 21709221 
68. Glasser DM  Tadin D   Modularity in the motion system: independent oculomotor and perceptual processing of brief moving stimuli J. Vis. 2014 14 28 10.1167/14.3.28 
69. Tadin D  Blake R   Motion perception getting better with age? Neuron 2005 45 325 327 10.1016/j.neuron.2005.01.017 15694315 
70. Golomb JD    Enhanced visual motion perception in major depressive disorder J. Neurosci. 2009 29 9072 9077 10.1523/JNEUROSCI.1003-09.2009 19605644 
71. Huang X  Albright TD  Stoner GR   Adaptive surround modulation in cortical area MT Neuron 2007 53 761 770 10.1016/j.neuron.2007.01.032 17329214 
72. Pack CC  Hunter JN  Born RT   Contrast dependence of suppressive influences in cortical area MT of alert macaque J. Neurophysiol. 2005 93 1809 1815 10.1152/jn.00629.2004 15483068 
73. Arranz-Paraiso S  Serrano-Pedraza I   Testing the link between visual suppression and intelligence PLoS One 2018 13 e0200151 10.1371/journal.pone.0200151 29979774 
74. Murray SO    Sex differences in visual motion processing Curr. Biol. 2018 28 2794 2799 10.1016/j.cub.2018.06.014 30122530 
75. Troche SJ  Thomas P  Tadin D  Rammsayer TH   On the relationship between spatial suppression, speed of information processing, and psychometric intelligence Intelligence 2018 67 11 18 10.1016/j.intell.2017.12.002 
76. Watson AB  Pelli DG   QUEST: a Bayesian adaptive psychometric method Percept. Psychophys. 1983 33 113 120 10.3758/BF03202828 6844102 
77. Foss-Feig JH  Tadin D  Schauder KB  Cascio CJ   A substantial and unexpected enhancement of motion perception in autism J. Neurosci. 2013 33 8243 8249 10.1523/JNEUROSCI.1608-12.2013 23658163

