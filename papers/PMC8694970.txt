
==== Front
J Healthc Eng
J Healthc Eng
JHE
Journal of Healthcare Engineering
2040-2295
2040-2309
Hindawi

10.1155/2021/9725762
Research Article
EEG Analysis with Wavelet Transform under Music Perception Stimulation
https://orcid.org/0000-0002-3016-0334
Xue Jing likaiyue@stumail.hbu.edu.cn

Xi'an University of Posts & Telecommunications, Shaanxi 710000, China
Academic Editor: Balakrishnan Nagaraj

2021
15 12 2021
2021 97257626 10 2021
29 10 2021
8 11 2021
Copyright © 2021 Jing Xue.
2021
https://creativecommons.org/licenses/by/4.0/ This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.
In order to improve the classification accuracy and reliability of emotional state assessment and provide support and help for music therapy, this paper proposes an EEG analysis method based on wavelet transform under the stimulation of music perception. Using the data from the multichannel standard emotion database (DEAP), α, ß, and θ rhythms are extracted in frontal (F3 and F4), temporal (T7 and T8), and central (C3 and C4) channels with wavelet transform. EMD is performed on the extracted EEG rhythm to obtain intrinsic mode function (IMF) components, and then, the average energy and amplitude difference eigenvalues of IMF components of EEG rhythm waves are further extracted, that is, each rhythm wave contains three average energy characteristics and two amplitude difference eigenvalues so as to fully extract EEG feature information. Finally, emotional state evaluation is realized based on a support vector machine classifier. The results show that the correct rate between no emotion, positive emotion, and negative emotion can reach more than 90%. Among the pairwise classification problems among the four emotions selected, the classification accuracy obtained by this EEG feature extraction method is higher than that obtained by general feature extraction methods, which can reach about 70%. Changes in EEG α wave power were closely correlated with the polarity and intensity of emotion; α wave power varied significantly between “happiness and fear,” “pleasure and fear,” and “fear and sadness.” It has a good application prospect in both psychological and physiological research of emotional perception and practical application.
==== Body
pmc1. Introduction

Music therapy is an emerging discipline integrating music, medicine, psychology, and other fields. It has made some research achievements in the psychological rehabilitation treatment of prenatal education, children's autism, Alzheimer's disease, and other diseases As an important part of social cognition, emotional perception is very important in the process of biological evolution and social interaction in real life [1]. Most neuroscience studies on human emotions use static visual images as stimuli to induce emotions, but in real life, people's emotions can obviously be triggered by many different stimuli. Neuroscience has found that music is also an effective tool for studying emotions [2]. Music has the following advantages: Music can trigger emotional reactions with considerable intensity. These emotions can usually be induced consistently among different subjects. Music not only can arouse unpleasant emotions but also can arouse happy emotions. However, it is difficult to arouse happy emotions through static images [3]. With the development of science and technology and the application of computers, many comprehensive signals are processed by digital signals, which make people's daily working methods reformed. Digital signal processing is generally divided into two categories: steady-state using Fourier analysis and unsteady state (sudden change) using wavelet analysis [4, 5]. Changes in EEG (electroencephalogram) power spectrum are closely related to the polarity and intensity of musical mood; α wave power is inversely correlated with brain activity, that is, greater α power represents less brain activity, smaller α power represents more brain activity, and α band power can more to changes in brain behavior than other bands. However, as a new field, the overall EEG research on musical emotion perception is still in the groping stage, looking forward to more and more systematic and detailed research. EEG examination has a significant role in the diagnosis of neurological disease, disease monitoring, and efficacy observation. Abnormal bioelectricity can be found through brain waves, and brain lesions can be detected.

EEG signals can comprehensively reflect the physiological and psychological state of the human body, and it is an effective evaluation method to analyze the emotional state in combination with the changes of EEG signals and then evaluate the effect of music therapy [6]. The activity degree of a certain rhythm wave caused by different emotions is different, so the original signal is decomposed and reconstructed by wavelet transform to obtain the basic rhythm wave. Extracting EEG features of rhythmic waves will be able to better analyze the changes of music emotional EEG [7]. Khaleghi et al. have proposed several linear and nonlinear biomarkers from EEG signals to diagnose ADHD. However, it is still controversial to determine which type of analysis provides us with the best characteristics and biomarkers for diagnosing ADHD. In this study, several kinds of features extracted from EEG for diagnosing ADHD are evaluated and compared. In this study, five types of features are extracted from EEG, including morphology, time, frequency, time-frequency, and nonlinear features. The receiver operates the feature (ROC) curve and the evidence k nearest neighbor (EKNN) classifier to determine the efficacy of each feature class in ADHD diagnosis. Statistical analysis showed that 13.15, 13.68, 14.47, 14.03, and 34.73% of the extracted features were significant in morphology, time, frequency, time frequency, and nonlinear domain (P < 0.05). The maximum AUC values of five categories such as morphological, temporal, frequency, time frequency, and nonlinear feature are 0.870, 0.796, 0.824, 0.806, and 0.899 [8]. Wavelet packet decomposition reconstruction of affective EEG signals and the ß rhythm was used for affective state recognition. The degree of some rhythm wave activity caused by different emotions is different. Therefore, by using the wavelet transform to obtain the basic rhythm wave, the extraction of the EEG features of the rhythm waves will better analyze the changes in the musical mood EEG.

Based on this study, this paper presents an EEG analysis method based on wavelet transformation under music sensing stimulation. The EEG states under different musical stimuli were used as the analysis objects. The frequency band (α, ß, and θ) waves were reconstructed by using the wavelet transform decomposition. Adaptive features based on the EMD make full use of the extracted time-domain waveform features of the rhythmic wave signal (local maximum, minimal, over zero, and mean line). The α wave, ß wave, and θ wave rhythms are decomposed into series of IMF components. Features such as the mean energy and amplitude difference of the IMF were further extracted. Match detection of EEG with various wavelet groups takes the wavelet coefficient and has the minimum variance value. Based on the support vector machine (SVM) classifier for affective state assessment, it then provides help and support for music therapy.

2. Research Methods

2.1. Algorithm Flow Chart

The general flow of this algorithm is shown in Figure 1.

2.2. EMD  Algorithm

EMD is an algorithm for decomposing nonlinear and nonstationary sequence signals based on its own time scale, which is self-adaptive and does not need to set a basis function. The purpose of EMD is to obtain a limited series of IMF components, and the frequency of each IMF component is gradually reduced with the increase of scale, which is helpful to highlight the local part of each component of EEG Features. The EMD principle is as follows, assuming that the original signal is x (t):Step 1: find out all local maxima and minima of x(t) signal.

Step 2: perform curve fitting on all local maximum points in step 1 to form an upper envelope m1(t); all minimum points are fitted into the lower envelope m2(t).

Step 3: find the mean curve u(t) of the upper and lower envelopes, as shown in the following formula:(1) ut=12m1t+m2t.

Step 4: separate the envelope mean curve u(t) from the original signal x(t) to obtain a residual function h1(t), as shown in the formula:(2) h1t=xt−ut.

If the residual function h1(t) are satisfied with the following two conditions of the IMF component, such as (1) the difference between the number of zero crossings and the number of extreme points in the whole signal segment is 1 at most, that is, there can be neither a minimum value greater than zero nor a maximum point less than zero in IMF and (2) the upper and lower envelopes of the signal are locally symmetric about the time axis [9]. The residual function h1(t) is the first IMF component; otherwise, h1(t) repeats steps 1–4 as a new original signal and cycle k times until the obtained residual function meets the two conditions of the IMF component. At this time, as the first IMF component, the residual function is written as follows:(3) s1t=h1kt.

This cycle cannot be infinite, and Huang finally gives a component stopping condition similar to the Cauchy convergence criterion, as shown in the following formula:(4) SD=∑t=0Thk−1t−hkt2∑t=0Thk−12t.

When SD is generally 0.1–0.3, the iteration stops, and the screening process ends.

Step 5: put the IMF component s1(t) separated from the original signal x(t); a residual signal c1(t) is obtained, as shown in the following formula:(5) c1t=xt−s1t.

Step 6: the residual signal is added. c1(t) repeats steps 1–5 as a new original signal and cycle n times until the final residual function is obtained. When cn(t) runs as a monotone function or constant, the EMD decomposition process ends, which can be easily obtained from the above formula, as shown in the following formula:(6) xt=∑i=1nsit+cnt.

According to EMD decomposition, the frequency of IMF components in each order is different, and the later the IMF components are separated, the lower the frequency is. Therefore, according to the influence of music on the frequency of EEG rhythm waves, the corresponding features can be extracted from each IMF component.

2.3. Feature Extraction

Studies have shown that the EEG characteristics of music-induced emotions are mainly reflected in three rhythm waves: α, ß, and θ. When people are excited, the amplitude of ß rhythm increases, while when people are sad, α rhythm decreases and θ rhythm increases, that is, θ rhythm is directly proportional to inhibitory emotion, while ß rhythm is directly proportional to stimulating emotion, which is more obvious in the frontal and temporal lobes. Therefore, in this study, F3 and F4 in the frontal region, T7 and T8 in the temporal region, and C3 and C4 in the central region were selected. DEAP database uses a “potency-arousal” two-dimensional emotion model. The emotion model divides emotions into positive and negative poles according to valence. Positive emotions at the positive pole usually bring pleasant feelings, while negative emotions at the negative pole usually produce unpleasant feelings. At the same time, according to arousal, we can distinguish the intensity of emotions. The greater the arousal, the stronger the emotion [9, 10]. Negative emotions generally include sadness, fear, anger, anxiety, pain, and hatred, while positive emotions include happiness, satisfaction, interest, pride, gratitude, and love. In this paper, four common basic emotions are selected, including positive emotions such as happy and exciting and negative emotions such as sad and terrible. No emotion chooses quiet baseline EEG signals [11]. Because 7,680 data points in 60 s are relatively large and MATLAB runs slowly, 1,024 data points are intercepted for analysis. Firstly, 5 kinds of emotional EEG signals of 32 subjects were decomposed and reconstructed into θ wave, α wave, and ß wave by wavelet transform. Taking F4 data in a happy state as an example, its channel reconstruction wave is shown in Figure 2.

The reconstructed three rhythmic waves are decomposed by EMD to obtain IMF components, and the F4 channel data in a happy emotional state can obtain seven IMF components by EMD. Then, the Fourier transform is used to transform into frequency domain, and the frequency spectrum of IMF of each order is obtained.

The frequencies of IMF components obtained by EMD are different, and the higher the order of IMF, the lower its frequency. If all IMF component-related features are extracted, the dimension of the feature vector will be very high. These feature quantities will contain a lot of feature values that have little correlation with music EEG features, which will lead to a decrease in the accuracy of emotion recognition. The frequency of the EEG rhythm wave studied in this paper is 4–30 Hz, so the first three IMF components are intercepted as shown in Figure 3, and these IMF components contain almost 90% of the energy of the signal. The first three IMF components are taken for feature extraction.

As the amplitude of the three rhythmic waves of EEG will change when music intervenes, the amplitude difference of adjacent IMF components is extracted as an eigenvalue, as shown in the following formula:(7) Hij=1n∑t=1nsit−sjt,

where si(t) is the i-th IMF component, sj(t) is the j-th IMF component, n is the number of IMF component data points, and Hij Is the amplitude difference between the i-th IMF and the j-th IMF component. The frequency difference of each IMF component is large, that is, there is an energy difference, so the average energy of each IMF component is taken as an eigenvalue, as shown in the following formula:(8) Εl=1n∑t=1nslt2,

where sl is the l-th IMF component and n is the IMF component data points. El is the average energy characteristic of the l-th IMF component. To sum up, a subject in each channel of each type of music in this paper has three kinds of rhythm waves, and each rhythm wave contains three average energy eigenvalues and two amplitude difference eigenvalues, so each subject has 15 eigenvalues.

2.4. Lib SVM Classifier

The goal of the SVM classifier is to produce a model based on training data that can be used to predict the target value of test data given only attributes. In this paper, the SVM classification model is selected as C-support vector classification (C-SVC). The basic principle of the C-SVC classification model algorithm: set a given training set as follows: T={(Xi, yi)|Xi ∈ Rn, yi ∈ {−1,1},  i=1,…, k}, look for the function h(k), and use the decision function y=f(X)=sgn(h(x)) to deduce the output y value corresponding to the input vector x. The specific steps are as follows:Step 1: select the appropriate kernel function K(Xi, Xj) and the penalty parameter c. The optimization problem is constructed and solved as shown in the following formulas:(9) minα12∑i=1k∑j=1kyiyjαiαjKXi,Xj−∑j=1kαj,

(10) s.t. ∑i=1kyiαi=0,0≤αi≤C, i=1,…,k.

Get the optimal solution: α∗=(α1∗,…,αk∗)T.

Step 2: choose α∗ a component of 0 < αj∗ < C and calculate from it: b∗=yj − ∑i=0kyiαi∗K(Xi, Xj).

Step 3: construct a decision function, as shown in the following formula:(11) fX=sgn∑i=1kyiαi∗KXi,X+b∗.

In this paper, the Gaussian radial basis function (RBF) is chosen as the kernel function, and its expression is: K(Xi, Xj)=exp(−‖Xi − Xj‖/2σ2), where σ is the width parameter.

2.5. Wavelet Transform

2.5.1. Selection of Wavelet Bases

The wavelet base treatment analysis and the EEG wavelet coefficient and variance values were calculated. The wavelet bases for multiresolution analysis in continuous wavelet transform include coif system wavelet, rbio wavelet, haar wavelet, db wavelet, wavelet, dmey wavelet, sym wavelet, bior wavelet, and so on, which are the group of wavelet bases that obtained the largest wavelet coefficient and small variance. When the wavelet signal was extracted using wavelet transform, the selection of wavelet base was optimized first.

2.5.2. Multiresolution Analysis

If the six-layer decomposition is performed, the sub-band components of each component correspond roughly one-to-one to low δ and high δ, θ, α, β, and γ in the EEG brain waves. After adopting the six-layer decomposition, the one-to-one corresponding frequency band has a clear physical meaning. Therefore, the original signal f (t) of EEG was decomposed by six layers, and using the wavelet transform, the wavelet base selection was optimized first. The paper uses the adaptive wavelet base method, matching detection, EEG, and various wavelet bases and takes the wavelet coefficient with the minimum variance value. Therefore, there may be multiple different wavelet bases for the EEG to be analyzed. After multiresolution analysis, obtained coefficients were calculated and classified by SVM.

3. Results

3.1. No Emotion, Positive Emotion, and Negative Emotion

3.1.1. Distinguish between No Emotion and Positive Emotion

Neuroscientific research on human emotions mostly uses static visual images as stimuli to induce emotions, and real-life human emotions can obviously be triggered by many different stimulus sources. As shown in Table 1, when no emotional state and positive emotions are identified, the average energy and amplitude difference of ß waves are higher than the single α waves. Moreover, although the optimal accuracy is 100%, the accuracy of the test set is reduced compared with the single ß rhythm, indicating that the characteristics of ß rhythm waves in EEG signals are related to the positive emotions induced by music and is much better than the classification of mixed waves.

3.1.2. Distinguish between No Emotion and Negative Emotion

As shown in Table 2, it can be seen that when distinguishing between no emotion and negative emotion, alone α wave performs better than using θ wave alone. The results show that the accuracy of the two kinds of wave mixing features is higher than that of using only one wave, which indicates that the negative emotions induced by music are related to both α waves and θ waves, but the correlation between θ waves and negative emotions is higher than that of α waves.

3.1.3. Distinguish between Positive Emotions and Negative Emotions

As shown in Table 3, it can be seen that the accuracy of feature classification between positive emotions and negative emotions is not high, which is similar to that obtained by extracting approximate entropy and wavelet entropy features, mostly in the range of 60–70%. However, the classification accuracy of the features between positive and negative emotions is higher, mostly in 70–80%. Therefore, it is better to use the extracted features of the IMF component of the EEG rhythm wave for classification.

In 1985, Cole and Ray studied the relationship between the high- and low-frequency bands of ß rhythm and emotion processing, respectively. The results showed that positive emotion and negative emotion caused different brain activities in the high- and low-frequency bands of ß rhythm [12–14]. This study focuses on only one EEG rhythm. After that, Kabuto and Yuan Quan began to study the relationship between the frequency domain characteristics of EEG basic rhythm and music. By analyzing the EEG signal in the happy and relaxed mood induced by music, it was found that the energy of θ rhythm wave increased, while the energy of α wave decreased obviously [15]. These studies only analyze the relationship between emotion and EEG from a certain rhythm of EEG or only select EEG signals in a certain emotional state as the research object, which lacks universality. In this paper, we choose three kinds of EEG rhythm waves that have a great correlation with emotion and analyze the changes of rhythm waves in the two states of positive emotion and negative emotion and get better classification results, which further expands the research between emotion and EEG [16, 17].

The application field of automatic identification of EEG is not only in the clinical medical diagnosis of epilepsy, encephalitis, Parkinson's disease, Alzheimer's disease, Wilson, brain tumor, epilepsy, arrhythmia, and other diseases but also in the adjuvant treatment of mental trauma, will depression, and so on. When the characteristic waveform is detected, the corresponding intervention treatment can be carried out, and the detection and treatment are automatically intelligent. This paper combines wavelet analysis and empirical mode decomposition to realize the feature extraction of music intervention EEG. The α, β, and θ wave rhythms of EEG were extracted, and according to the characteristics of EEG stimulated by music, 15 characteristic quantities such as amplitude difference of adjacent IMF components and average energy of the first three IMF components were extracted [18]. Pairwise classification of four emotions was solved to some extent. The classification accuracy obtained by this EEG feature extraction method is higher than that obtained by general feature extraction methods and can reach about 70%. However, although the recognition rate of pairwise classification of four emotions has been improved, it cannot achieve the effect of complete separation. For example, the classification effect of sad emotion and terrible emotion is still very low. Therefore, the recognition effectiveness of this feature extraction method between similar emotions needs to be improved [19, 20].

4. Conclusion

As an effective emotional inducement source, music has a good application prospect in both psychological and physiological research of emotional perception and practical application. The application field of automatic identification of EEG is not only in the clinical medical diagnosis of epilepsy, encephalitis, Parkinson's disease, Alzheimer's disease, Wilson, brain tumor, epilepsy, arrhythmia, and other diseases but also in the adjuvant treatment of mental trauma, will depression, and so on. When the characteristic waveform is detected, the corresponding intervention treatment can be carried out, and the detection and treatment are automatically intelligent. Especially in recent years, the clinical development of music therapy and brain computer interface in brain neuroscience is very fast, which makes the study of the relationship between music, emotion, and EEG appear more valuable. If the music is arranged according to the law of the emotional response to different music in the EEG rhythm and used for clinical music therapy, its application value is self-evident.

Data Availability

The data used to support the findings of this study are available from the corresponding author upon request.

Conflicts of Interest

The author declares that there are no conflicts of interest.

Figure 1 Algorithm flow chart.

Figure 2 Three rhythmic waves of reconstructed EEG.

Figure 3 IMF component spectrogram with determined order.

Table 1 Classification of no emotion and positive emotion.

Band	Optimal accuracy rate (%)	Accuracy of test set (%)	
α wave (N-H)	93.75	84.38	
α wave (N-E)	96.88	81.25	
β wave (N-H)	93.75	90.63	
β wave (N-E)	100.00	100.00	
α wave + ß wave (N-H)	100.00	87.50	
α wave + ß wave (N-E)	100.00	84.38	

Table 2 Classification of no emotion and negative emotion.

Band	Optimal accuracy rate (%)	Accuracy of test set (%)	
α wave (N-S)	96.75	93.75	
α wave (N-t)	93.88	87.50	
θ wave (N-S)	100.00	93.75	
θ wave (N-t)	100.00	100.00	
α wave + θ wave (N-S)	100.00	96.88	
α wave + θ wave (N-t)	100.00	100.00	

Table 3 Pairwise classification between four emotions.

Classify	Approximate entropy + wavelet entropy accuracy (%)	Average energy + amplitude difference (this algorithm) accuracy (%)	
H-E	65.63	68.75	
H-S	68.75	81.25	
E-S	50.00	75.00	
H-T	59.38	71.88	
E-T	59.38	78.13	
S-T	53.13	65.63
==== Refs
1 Shalini M. Paul S. Classification of depression patients and normal subjects based on electroencephalogram (eeg) signal using alpha power and theta asymmetry Journal of Medical Systems 2019 44 1 p. 28
2 Shan X. Yang E.-H. Zhou J. Chang V. W. C. Neural-signal electroencephalogram (eeg) methods to improve human-building interaction under different indoor air quality Energy and Buildings 2019 197 188 195 10.1016/j.enbuild.2019.05.055 2-s2.0-85066254019
3 Yassin A. El-Salem K. Khassawneh B. Y. Diagnostic value of electrocardiogram during routine electroencephalogram Seizure 2021 89 2021 19 23 10.1016/j.seizure.2021.04.016 33971558
4 Rongrong Y. Tian T. Bao T. [recognition method of single trial motor imagery electroencephalogram signal based on sparse common spatial pattern and Fisher discriminant analysis] Sheng wu yi xue gong cheng xue za zhi = Journal of biomedical engineering = Shengwu yixue gongchengxue zazhi 2019 36 6 911 915 31875363
5 Kaliraman B. Duhan M. A new hybrid approach for feature extraction and selection of electroencephalogram signals in case of person recognition Journal of Reliable Intelligent Environments 2021 7 3 241 251 10.1007/s40860-021-00148-z
6 Feng Zhang R. Zhong S. Alteration in sleep architecture and electroencephalogram as an early sign of alzheimer’s disease preceding the disease pathology and cognitive decline Alzheimer’s and Dementia: The Journal of the Alzheimer’s Association 2019 15 4 590 597
7 Chatterjee S. Detection of focal electroencephalogram signals using higher‐order moments in EMD‐TKEO domain Healthcare Technology Letters 2019 6 3 64 69 10.1049/htl.2018.5036 2-s2.0-85068218934 31341630
8 Khaleghi A. Birgani P. M. Fooladi M. F. Mohammadi M. R. Applicable features of electroencephalogram for adhd diagnosis Research on Biomedical Engineering 2020 36 1 1 11 10.1007/s42600-019-00036-9
9 Kanoga S. Kanemura A. Asoh H. Multi-scale dictionary learning for ocular artifact reduction from single-channel electroencephalograms Neurocomputing 2019 347 28 240 250 10.1016/j.neucom.2019.02.060 2-s2.0-85065070044
10 Bhardwaj H. Sakalle A. Bhardwaj A. Tiwari A. Classification of electroencephalogram signal for the detection of epilepsy using innovative genetic programming Expert Systems 2019 36 1 e12338.1 e12338.14 10.1111/exsy.12338 2-s2.0-85053448954
11 Bose R. Pratiher S. Chatterjee S. Detection of epileptic seizure employing a novel set of features extracted from multifractal spectrum of electroencephalogram signals IET Signal Processing 2019 13 2 157 164 10.1049/iet-spr.2018.5258 2-s2.0-85065089508
12 Zhang Y. Geyfman A. Coffman B. Gill K. Ferrarelli F. Distinct alterations in resting-state electroencephalogram during eyes closed and eyes open and between morning and evening are present in first-episode psychosis patients Schizophrenia Research 2021 228 1 36 42 10.1016/j.schres.2020.12.014 33434730
13 Ngo C. Q. Chai R. Nguyen T. V. Jones T. W. Nguyen H. T. Electroencephalogram spectral moments for the detection of nocturnal hypoglycemia IEEE Journal of Biomedical and Health Informatics 2020 24 5 1237 1245 10.1109/jbhi.2019.2931782 31369389
14 Xiaoyu Z. Minpeng X. Xiaolin X. Long C. Gu X. Ming D. [A review of researches on electroencephalogram decoding algorithms in brain-computer interface] Sheng wu yi xue gong cheng xue za zhi = Journal of biomedical engineering = Shengwu yixue gongchengxue zazhi 2019 36 5 856 861 31631636
15 Juanjuan J. Yan Z. Sheng C. A novel detection tool for mild cognitive impairment patients based on eye movement and electroencephalogram Journal of Alzheimer’s Disease: JAD 2019 72 2 389 399 31594231
16 Roy P. P. Kumar P. Chang V. A hybrid classifier combination for home automation using eeg signals Neural Computing & Applications 2020 32 20 1 13 10.1007/s00521-020-04804-y
17 Shah A. A. Chowdhry B. S. Memon T. D. Kalwar I. H. Ware J. A. Real time identification of railway track surface faults using canny edge detector and 2d discrete wavelet transform Annals of Emerging Technologies in Computing 2020 4 2 53 60 10.33166/aetic.2020.02.005
18 Li P. Yuan H. Wang Y. Chen X. Pumping unit fault analysis method based on wavelet transform time-frequency diagram and cnn International Core Journal of Engineering 2020 6 1 182 188
19 Zhang Q. Li H. Li H. Li M. Ding L. Feature extraction of face image based on lbp and 2-d gabor wavelet transform Mathematical Biosciences and Engineering 2020 17 2 1578 1592 10.3934/mbe.2020082
20 Rabi J. Balusamy T. Raj Jawahar R. Analysis of vibration signal responses on pre induced tunnel defects in friction stir welding using wavelet transform and empirical mode decomposition Defence Technology 2019 15 6 885 896 10.1016/j.dt.2019.05.014 2-s2.0-85066314093

