
==== Front
Comput Intell Neurosci
Comput Intell Neurosci
cin
Computational Intelligence and Neuroscience
1687-5265
1687-5273
Hindawi

10.1155/2022/4430742
Research Article
Application of Multiprocessing Technology of Motion Video Image Based on Sensor Technology in Track and Field Sports
https://orcid.org/0000-0002-6581-4414
Xu Shaofeng
https://orcid.org/0000-0003-3718-1661
Chen Junmeng chenjm11@st.btbu.edu.cn

Sangmyung University, Seoul 03016, Republic of Korea
Academic Editor: Qiangyi Li

2022
11 2 2022
2022 44307428 12 2021
4 1 2022
15 1 2022
Copyright © 2022 Shaofeng Xu and Junmeng Chen.
2022
https://creativecommons.org/licenses/by/4.0/ This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.
To improve the accuracy of track and field sports feature recognition, this paper combines sensor technology to improve the motion video image multiprocessing technology and gives the basic principles of image registration. Moreover, this paper chooses a model based on projection transformation. When using a high-speed linear CCD, only the image information on the finish line is collected. Unlike the previous high-speed area CCD cameras that can capture runway information, linear CCDs are used to collect only the image information on the finish line, and the data is collected and processed through sensor technology. The research shows that the application effect of the motion video image multiprocessing technology based on sensor technology in track and field sports proposed in this paper has good practical effects.

Sangmyung University
==== Body
pmc1. Introduction

Images are objective and true image data obtained from the real world through various observation and measurement systems and various observation and measurement methods. It can be directly received by the human eye and generates a signal in the human brain to make the human visually perceive the actual information. After scientific research, it has been confirmed that about 80% of the information obtained by humans comes from the human visual system, which means that about three-quarters of the information obtained by people is in the form of images [1]. This is the most basic qualitative for the word image. Images can convey a lot of information and are not susceptible to interference from other factors. In addition, it can be expressed in the most true, direct, and objective manner, and the received information can be processed twice at the fastest speed through the widely used multimedia information technology nowadays. On this basis, we discover the relevant information about the athletes we need in training, so as to ensure that coaches and the researchers responsible for monitoring and investigating the athletes' training situation can obtain the most direct, intuitive, and highly referential training information of athletes and can also use this as a basis to guide athletes on how to train in the follow-up process [2]. Therefore, the related technology of image processing has been welcomed and favored by coaches and athletes for a long time. This method can play a very huge role in the process of researching sports [3].

Video images are obtained by people using various tools to observe the objective world in different forms and methods. It can directly or indirectly act on the human eyes and produce visual perception entities, that is, static pictures or dynamics observed by the human eyes. Video. Scientific research and statistics show that about 75% of the information that humans obtain from the outside world comes from the visual system, which is obtained from images. After the two-dimensional or three-dimensional analysis of the sports technology video image, the image or data information of the athlete's technical performance is obtained, and then, the technical training level is evaluated through scientific analysis and evaluation. All of this is based on the video image. Image processing technology can most intuitively monitor and evaluate athletes' technical movements, and it can also stimulate athletes' interest in learning and improving sports technology the most. At the same time, the sports technology video is carried out under the condition of no interference to the athletes. It directly obtains the real technical data of the athletes at the competition and training site, which can best meet the requirements of sports training and the real situation of the competition. Therefore, video image processing technology is one of the most effective scientific research methods and has a wide range of application prospects.

This article combines sensor technology to improve the multiprocessing technology of sports video images, researches the process of track, and field sports and builds an intelligent track and field analysis system, which provides a reference for the subsequent improvement of the effect of track and field sports.

2. Related Work

The development of modern multimedia technology has enabled computers to intensively manage and process the media that disseminate information, such as text, graphics, sound, and images, so that modern educational technology with computers as the core has become a key experimental field for school teaching reform in the new era. Physical education is an important part of school education and school physical education. Teaching methods and methods should also be continuously enriched and developed, and its reform is imperative [4]. The characteristic of multimedia teaching is that it is suitable for expressing visualized or simple logical thinking teaching content based on concrete images. Using multimedia computers to integrate text, graphics, images, and videos can present more information to students in a short period of time, which cannot be accomplished by traditional teaching methods in the same time period [5]. There are many media in physical education. The use of media is sufficient, complete, diverse, and efficient, which is conducive to improving the quality of teaching and is conducive to the learning and mastery of sports movements [6].

Multimedia technology is the result of the comprehensive development of related technologies, such as microelectronics, computer technology, and communication technology. Therefore, it is a highly comprehensive high-tech. With the development and improvement of multimedia technology itself, its concept is also constantly developing, the meaning it covers is also constantly extending, and its related fields are constantly expanding [7].

After the 1990s, with the development of computer technology, the continuous upgrading of hardware and software, the continuous improvement of multimedia technology, the continuous improvement of the support capacity of the PC system platform, the continuous improvement of compression and decompression technology and coding technology, and the development of network technology, it solves the storage, transmission, and performance of multimedia information [8]. The multimedia system has the ability to comprehensively process sound, graphics, and text, especially the problem of processing full-motion video information and interactive video applications. Video images are obtained by people using various tools to observe the objective world in different forms and methods. It can directly or indirectly act on the human eye and produce visual perception entities, that is, static pictures or dynamics observed by human eyes. The video [9]. After the two-dimensional or three-dimensional analysis of the sports technology video image, the image or data information of the athlete's technical performance is obtained, and then, the technical training level is evaluated through scientific analysis and evaluation, all of which are based on the video image [10]. From the perspective of the development of video image acquisition and processing methods, it has experienced from early film photography to infrared spot and AV signal video recording and then digital DV signals that are widely used at present. From the perspective of the development of image acquisition speed, it has experienced low-speed video and normal-speed video to high-speed video; from analog signal to digital signal, from low-resolution video to the development of high-precision images, from two-dimensional measurement analysis to three-dimensional measurement analysis; in the display after the picture is collected, from black and white images to color images; in terms of technical feedback, through field video collection, laboratory video collection, analysis, and post-exercise Feedback, up to the current on-site video collection, on-site video technology analysis and processing, on-site rapid feedback, feedback time is greatly shortened [11]; in the way of video feedback, from single person single video technical data feedback, to multi-person and multi-video comparison Feedback, video overlay feedback, etc.; in terms of obtaining motion parameters, it has also experienced the development from complex to simple, from long-term feedback to rapid feedback on the sports scene, from complex technical processing to simple technical rapid processing. All of this is closely connected with the rapid development of modern science and technology, especially computer technology [12]. Scientific research and statistics show that about 75% of the information that humans obtain from the outside world comes from the visual system, which is also obtained from images [13]. After the two-dimensional or three-dimensional analysis of the sports technology video image, the image or data information of the athlete's technical performance is obtained, and then, the technical training level is evaluated through scientific analysis and evaluation, all of which are based on the video image [14]. Image processing technology can most intuitively monitor and evaluate athletes' technical movements, and it can also stimulate athletes' interest in learning and improving sports technology the most. At the same time, the sports technology video is carried out under the condition of no interference to the athletes. It directly obtains the real technical data of the athletes at the competition and training site, which can best meet the requirements of sports training and the real situation of the competition. Therefore, video image processing technology is one of the most effective scientific research methods and has a wide range of application prospects [15].

3. Multiprocessing Technology of Track and Field Video Image

The geometric transformation model of track and field sports images uses the matrix form in the mathematical model to express the change relationship between two track and field sports images, such as translation, rotation, and zoom transformation. In fact, the mathematical model is used to express the geometric transformation model of the track and field sports image, which is convenient for the simulation and simulation of the algorithm. Before the two track and field sports images are fused, the corresponding coordinate points of the same objects in the two track and field sports images need to be found. When shooting, the two track and field sports images to be registered may be affected by the experimental environment. There are some changes. Different mathematical models should be selected for different situations to describe the geometric transformations of the track and field sports images. Some common transformations are translation, rotation, affine, projection and so on. Among them, the first two are simple transformations, which are uniformly divided into rigid body transformations.

The rigid body transformation can only represent the translation and rotation transformation between the coordinates of two track and field sports images. Formula (1) represents the mathematical expression of rigid body transformation [16].(1) x′y′1=cosθ−sinθm2sinθcosθm5001xy1.

Rigid body transformation is the simplest transformation among the three transformations, and there are only three degrees of freedom. m2, m5 represents the horizontal offset and vertical offset between two track and field sports images. 0 represents the rotation angle between two athletic images, (x′, y′) is the coordinate after transformation, and (x, y) is the coordinate of the original image.

Affine transformation can not only describe the translation and rotation transformations between the pixels of two track and field sports images but also describe their scaling transformations. Formula (2) expresses the mathematical expression of affine transformation [17].(2) x′y′1=m0m1m2m3m4m5001xy1.

It is not difficult to see that (x′, y′) are the transformed coordinates, and (x, y) are the coordinates in the original image. There are six in the transformation matrix. m0, m1, m3, and m4 represent one of the two track and field sports images. Rotation and zoom between the two, m2 and m5, represent the amount of translation. It can be known from the number of unknowns that at least three pairs of corresponding feature points are needed to obtain the transformation matrix.

The projection transformation is closer to actual life. The shapes of the two track and field sports images before and after the transformation are basically unchanged, but the original parallel line segments no longer remain parallel. After repeated experimental verification, this paper found that the effect of projection transformation is significantly better than that of other transformations. Therefore, this paper adopts the projection transformation, and there are eight degrees of freedom in the projection transformation. According to the values of these eight degrees of freedom, people can accurately know what transformations have occurred in the two track and field sports images. The models and principles of these three transformations have been introduced previously. Next, this paper combines the projection transformation selected in this paper and the coordinates mapped in real shooting to do a detailed introduction. Figure 1 shows the coordinates mapped during the actual shooting.

As shown in Figure 1, where P (X, Y, Z) is any point in the natural scene, C1 and C2 are two different imaging sensors with translation and rotation transformations. P1, P2 is the imaging coordinates of the unified scenic spot Р taken by the two different imaging sensors, respectively, marked as x1=(X1, Y1, k1)T, x2=(X2, Y2, k2)T, so formula (3) can be derived [18].(3) x1=V1R1T1P,x2=V2R2T2P.

Among them, Ti, Vi, Ri(i=1,2), respectively, represent the translation, scaling, and rotation matrix of the imaging coordinate system of the acquisition device relative to the world coordinate system. Formula (4) shows the relationship between x1 and x2:(4) x2=V2R2T2T1−1R1−1V1−1x1.

M=V2R2T2T1−1R1−1V1−1, and there is x2=Mx1, where M is a 3 × 3 matrix, which is generally written as follows:(5) x2=X2Y2k1=m0m1m2m3m4m5m6m71XYk,

(6) X2=m0X1+m1Y1+m2m6X1+m7Y1+1,

(7) Y2=m3X1+m4Y1+m5m6X1+m7Y1+1.

The previously mentioned formula shows that if the coordinates of a point in the actual scene captured and imaged by two different sensors are x1 and x2, a 3 × 3 transformation matrix can be used to express the transformation relationship between two track and field sports images. According to the transformation matrix, people can calculate the specific values of translation, rotation, and scaling between two track and field sports images. The projection transformation model has 8 degrees of freedom mi (i = 0, 1, 2,…, 7), where k is the scaling parameter. The perspective transformation is that the original parallel line segments no longer remain parallel, but the original straight-line segments are still straightline segments.

The detection of feature points is to detect the feature points of the differential Gaussian pyramid of track and field sports images of different scales. The so-called feature points are points that do not change under the changes of translation, rotation, and scaling, that is, the scale invariance factor. In fact, the difference pyramid is used to refine the track and field motion image and then detect the feature points. The differential Gaussian pyramid of track and field sports images is defined as [19](8) Dx,y,kσ=Gx,y,kσ−Gx,y,σ⊗Ix,y,Gx,y,kσ=12πσ2e−x2+y2/2σ2.

Among them, D(x, y, kσ) represents the differential Gaussian pyramid of the track and field sports image with a scale of 0 under the coefficient k, D(x, y, σ) represents the Gaussian pyramid of the scale of G(x, y, kσ), 1(x, y) represents the original track and field sports image, and ⊗ represents the convolution between them. σ is the scale factor, G(x, y, kσ) represents the Gaussian function of scale, and (x, y) is the coordinate of the point on the track and field sports image. In order to find the characteristic points on the difference pyramid, take any point on the track and field sports image of the difference pyramid as the center point in the 3 × 3 window, and then take the 3 × 3 window of the upper and lower layers of the difference pyramid corresponding to this layer. Whether the value of the center point is greater than the value of 26 points in its neighboring or corresponding points in the upper and lower windows is compared. If it is, then, the point is regarded as the maximum point, that is, the feature point of interest; otherwise, it is not, and the feature point detected on the track and field sports image is obtained.

The matching method of sift in Lowe is mainly based on Euclidean distance. However, the threshold value selected each time is different, and the specific threshold value is determined mainly based on repeated experiments. The matching of two descriptors D1 and D2 is when the distance between only two descriptors is T times (threshold) not greater than the distance between D1 and other descriptors, it is considered as a corresponding matching point as follows:(9) dD1,D2×1.5<dD1,others.

The Chinese meaning of surf is fast and robust. After the sift algorithm was researched, later generations found that although the sift algorithm is very stable, it runs very slowly. The Sift algorithm uses a differential Gaussian pyramid, while the surf algorithm uses an approximation of the determinant of the Hessian matrix. Formula (10) represents a Hessian matrix with point x at scale σ.(10) Hx,σ=Lxxx,σLxyx,σLxyx,σLyyx,σ.

Among them, Lxx(x, σ) represents the convolution of the function value of the second-order Gaussian differential ∂2/∂x2g(σ) with the track and field moving image I at point x. Lxy(x, σ) represents the convolution of the function value of the second-order Gaussian differential ∂2/∂x  ∂yg(σ) with the track and field moving image I at point x. Lyy(x, σ) represents the convolution of the function value of the Gaussian second-order differential ∂2/∂y2g(σ) with the track and field moving image I at the point x.

People can use the corresponding template to convert the result of the convolution into the form of a box filter, as shown in Figure 2:

If a Gaussian second-order differential function with a standard deviation of 1.2 is used for filtering, a 9 × 9 template is selected to convolve and detect track and field moving images. Formula (12) represents the simplified formula for the determinant value of the Hessian matrix:(11) DetHapprox=DxxDyy−0.9Dxy2.

From Figure 3, we can see the difference between the pyramid constructed with the sift algorithm and the pyramid constructed with the surf algorithm [20]. That is, when the sift algorithm is used to construct the pyramid, the size of the track and field sports image is continuously changed after sampling, but the size of the template is fixed. However, when the surf algorithm is used to construct the pyramid, the size of the track and field motion image is unchanged, but the size of the filter is constantly changing, thus constructing an integral function on the original track and field motion image and speeding up the running speed of the surf algorithm.

In the surf algorithm, the horizontal and vertical eigenvalues of the Harr wavelet in the neighborhood of the feature point are counted. The range of the neighborhood is to rotate at a certain angular interval in a sector with an arc center angle of 60 degrees in the circle of. Then, the sum of the eigenvalues of the Harr wavelet in the sector are, respectively, counted, and the main direction of the characteristic point is determined according to the largest statistical value. Then, according to the obtained main direction, draw a square that is consistent with the direction near the feature point. The square is divided into 4 × 4 small areas, a total of 16 areas, and the eigenvalues of the Harr wavelet of 25 pixels in each small area are calculated. The characteristic value includes the cumulative value of the horizontal direction, the cumulative value of the vertical direction, the cumulative value of the absolute value of the horizontal characteristic value, and the cumulative value of the absolute value of the vertical characteristic value. The schematic of the process is shown in Figure 4:

In this way, the cumulative value of four directions in 16 regions is formed, a total of 64-dimensional vectors, and the sift algorithm has a total of 128-dimensional vectors, so the amount of calculation is reduced by half, which greatly accelerates the matching speed of the algorithm. For the fusion of two cameras that use different fields of view (FOV) and resolution, the first thing that needs to be realized is the transformation relationship between all the track and field sports images involved. Therefore, it is necessary to spatially remap each track and field sports image to a common coordinate. This can be achieved by a simple registration method. The geometric registration formulates several key assumptions. First, the two cameras are assumed to be concentrated at the same point. Therefore, the center of each track and field sports image should match spatially before any registration. Second, it assumes that when the two cameras are synchronized, the frames that produce the same scene are related to time. Finally, it is assumed that the slight difference in the actual camera position between the scenes viewed by the two cameras at a certain distance is negligible [21].

The final hypothesis can be obtained from Figure 5. Two planes appear in this picture, the length of Wc represents the sensor plane and the length of Ws represents the scene plane. The distance S is related to the offset of the two cameras installed. The scene at the sensor level is quantized into N discrete pixels, and the width of each pixel is described as follows:(12) Pixel Widt=WcN.

Therefore, the plane of the scene is also quantized into N, and the following describes the discrete part of the pixel width:(13) Scene Widt=WsN=2d  tanγ.

In order for a significant difference in the two frames of the two offset cameras to appear, there must be at least 1 SceneWidth. Therefore, as long as the value of S is less than one pixel shift, there is no difference in the distance between the two cameras in the final track and field sports image.(14) S<d  tanγN.

The distance d is solved by the rearrangement (15) algorithm, and the result is(15) d>S×Ntanγ.

Arbitrarily, if S is equivalent to a value close to 10 cm, that is, the camera is installed at a distance of 10 cm, 240 pixels are used, and the field of view is less than 90 degrees, and the minimum distance d can be found. The result of this calculation shows that as long as the two cameras are concentrated to a distance greater than 2.40 meters, no offset can be seen in the two track and field sports images.

In all other track and field sports images, the track and field sports images called “source” are sampled to achieve the same resolution as the benchmark track and field sports images. The first step in this process involves taking a useful part of the base geometry, as shown in Figure 6. Angle 0 is equivalent to half of a specific angle of view. The relationship between the angle and the length of this side is expressed as follows [22]:(16) tanθ=D2Dt.

Since the Dt of the two cameras is the same, this value can be normalized to get the relative length of the track and field sports image, and the result can be expressed by formula (17). Since this formula uses the relative height and width of each frame, each frame can be found:(17) D=2  tanθ.

These distances are used to remove any areas that will not appear in the two frames. In order to achieve this, the relative distance of each track and field sports image must be compared. No matter which frame contains a larger distance, it must be cropped to a frame with a smaller size. Since the resolution of each camera may change, this difference is converted into pixels. This value indicates how many rows or columns must be removed, which is expressed by the following:(18) Num Croppe Npixels1−DMinDMax.

4. Application of Multiprocessing Technology of Motion Video Image Based on Sensor Technology in Track and Field Sports

This research uses high-speed linear CCD to collect only the image information on the finish line. Unlike the previous high-speed area CCD camera that can capture runway information, the linear CCD only collects the image information on the finish line. Next, we need to solve the runway problem. If the track cannot be resolved, the matching of the athlete's performance will be affected to a certain extent. In order to solve this problem, the finish line can be drawn as a white line, and the runway line can be extended to the finish line with a black line, so that the CCD acquisition system can collect the black line information of the runway. Since there is runway information on each frame of image, in this way, the line of the runway appears on the image composed of the linear CCD images of each frame, and the rest of the runways are white, which is easy to distinguish. The schematic diagram of camera placement and runway identification is shown in Figure 7.

This system is composed of upper plastic layer, sensor unit, row lead, column lead, lower plastic layer, sensor acquisition node, field bus unit, digital track module, field bus, computer, and wireless headset. It is characterized by the structure of a flexible array sensor based on a screen printing process, and a plurality of sensor units are placed between the upper plastic layer and the lower plastic layer for protection. The sensor unit is connected by row leads and column leads to form a sensor acquisition node. Moreover, multiple sensor collection nodes are connected with the lower plastic layer and the upper plastic layer, and the field bus unit to form a large-area flexible digital track module as a training platform, which is fixed on the ground. In the large-area flexible digital racetrack module, the row leads of each row of sensor units and the column leads of each sensor unit are connected to the field bus unit. Furthermore, it is connected to the computer through the field bus to complete the transfer of information collection to the computer, and the wireless headset receives the feedback information from the computer through the wireless communication network. The block diagram of the system modules is shown in Figure 8.

According to the system proposed in this paper, a case image of the multiprocessing technology of track and field sports video is obtained, as shown in Figure 9.

Through the multiprocessing technology of the track and field sports video for image processing, the image processing effect is shown in Figure 10.

Based on this analysis, the application effect of this system is evaluated, and the results shown in Table 1 are obtained.

From the previously mentioned research, we can see that the multiprocessing technology of motion video image based on sensor technology proposed in this paper has good practical effects in track and field sports.

5. Conclusion

With the continuous improvement of sports technology and computer performance, the intensity of track and field events is also increasing. During the track and field competition, the accuracy of the athlete's starting movement can enable the athlete to obtain the best speed in the shortest time, which directly affects the competition performance, so it has become the focus of research in the field of sports teaching. In the actual training process, due to the differences in the physical conditions and specific physical abilities of different athletes, some athletes have more wrong starting movements, and their ability to master the correct starting movements is poor. In this state, how to effectively conduct in-depth observation and judgment of athletes' starting movements and use certain effective means to prevent and correct them has become the main problem that needs to be solved urgently in this field, which has attracted the attention of many experts and scholars in this field. Therefore, many good research results have been obtained. This article combines sensor technology to improve the multiple processing technology of sports video images, researches the process of track and field sports, and builds an intelligent track and field analysis system, which provides a reference for the subsequent improvement of the effect of track and field sports.

Acknowledgments

This study was sponsored by Sangmyung University.

Data Availability

The labeled dataset used to support the findings of this study are available from the corresponding author upon request.

Conflicts of Interest

The authors declare no conflicts of interest.

Figure 1 Coordinates mapped during actual shooting.

Figure 2 Box filter.

Figure 3 Sift pyramid and surf pyramid.

Figure 4 Schematic diagram of Harr wavelet characteristics.

Figure 5 Registration specifications.

Figure 6 Geometric registration.

Figure 7 Schematic diagram of camera placement and runway identification.

Figure 8 Block diagram of system modules.

Figure 9 Case images of multiprocessing technology for track and field sports videos. (a) Case image 1. (b) Case image 2.

Figure 10 The processing effect of the motion video image multiprocessing technology. (a) Original image. (b) Grayscale processing. (c) Noise removal. (d) Feature recognition.

Table 1 Application effect of multiprocessing technology of motion video image based on sensor technology in track and field sports.

NO	Effect	NO	Effect	
1	94.16	19	92.58	
2	91.70	20	83.51	
3	90.10	21	86.67	
4	86.47	22	88.12	
5	85.25	23	88.74	
6	86.94	24	91.57	
7	93.57	25	86.19	
8	92.25	26	93.19	
9	94.83	27	94.85	
10	92.51	28	84.16	
11	83.51	29	84.31	
12	90.22	30	86.10	
13	88.03	31	86.67	
14	83.64	32	83.94	
15	83.63	33	86.66	
16	94.98	34	84.46	
17	94.08	35	91.56	
18	90.37	36	85.77
==== Refs
1 Abawajy J. H. Hassan M. M. Federated internet of things and cloud computing pervasive patient health monitoring system IEEE Communications Magazine 2017 55 1 48 53 10.1109/mcom.2017.1600374cm 2-s2.0-85010002074
2 He D. Ye R. Chan S. Guizani M. Xu Y. Privacy in the internet of things for smart healthcare IEEE Communications Magazine 2018 56 4 38 44 10.1109/mcom.2018.1700809 2-s2.0-85045941519
3 Ray P. P. Internet of things for smart agriculture: technologies, practices and future direction Journal of Ambient Intelligence and Smart Environments 2017 9 4 395 420 10.3233/ais-170440 2-s2.0-85015228281
4 Qadri Y. A. Nauman A. Zikria Y. B. Vasilakos A. V. Kim S. W. The future of healthcare internet of things: a survey of emerging technologies IEEE Communications Surveys & Tutorials 2020 22 2 1121 1167 10.1109/comst.2020.2973314
5 Dobkin B. H. A rehabilitation-internet-of-things in the home to augment motor skills and exercise training Neurorehabilitation and Neural Repair 2017 31 3 217 227 10.1177/1545968316680490 2-s2.0-85012920358 27885161
6 Yao J. Ansari N. Caching in energy harvesting aided internet of things: a game-theoretic approach IEEE Internet of Things Journal 2018 6 2 3194 3201
7 Siegel J. E. Kumar S. Sarma S. E. The future internet of things: secure, efficient, and model-based IEEE Internet of Things Journal 2017 5 4 2386 2398
8 Abd-Elmagid M. A. Pappas N. Dhillon H. S. On the role of age of information in the internet of things IEEE Communications Magazine 2019 57 12 72 77 10.1109/mcom.001.1900041
9 Sheth A. Jaimini U. Yip H. Y. How will the internet of things enable augmented personalized health? IEEE Intelligent Systems 2018 33 1 89 97 10.1109/mis.2018.012001556 2-s2.0-85046958146 29887765
10 Joyia G. J. Liaqat R. M. Farooq A. Saad R. Internet of medical things (IOMT): applications, benefits and future challenges in healthcare domain Journal of Communications 2017 12 4 240 247
11 Kshetri N. The evolution of the internet of things industry and market in China: an interplay of institutions, demands and supply Telecommunications Policy 2017 41 1 49 67 10.1016/j.telpol.2016.11.002 2-s2.0-85007242133
12 Siboni S. Sachidananda V. Meidan Y. Security t for internet-of-things devices IEEE Transactions on Reliability 2019 68 1 23 44 10.1109/tr.2018.2864536 2-s2.0-85058125435
13 Ancillao A. Savastano B. Galli M. Albertini G. Three dimensional motion capture applied to violin playing: a study on feasibility and characterization of the motor strategy Computer Methods and Programs in Biomedicine 2017 149 2 19 27 10.1016/j.cmpb.2017.07.005 2-s2.0-85024854541 28802327
14 Komisar V. Novak A. C. Haycock B. A novel method for synchronizing motion capture with other data sources for millisecond-level precision Gait & Posture 2016 51 3 125 131 27756055
15 Fátima S. A Marques A. Rocha N. B. F. Maria J. Carlos C. Johannes S. Kinematic parameters of throwing performance in patients with schizophrenia using a markerless motion capture system Somatosensory Research 2015 32 2 77 86
16 Juan Pablo L. Nelson Arzola P. Kinematic hand analysis using motion capture technology IFMBE proceedings 2015 49 6 257 260
17 Kim M.-K. Kim T. Y. Lyou J. Performance improvement of an AHRS for motion capture Journal of Institute of Control, Robotics and Systems 2015 21 12 1167 1172 10.5302/j.icros.2015.15.0116 2-s2.0-84949788940
18 Zhou Z.-M. Chen Z.-W. A survey of motion capture data earning as high dimensional time series International Journal of Multimedia and Ubiquitous Engineering 2015 10 9 17 30 10.14257/ijmue.2015.10.9.03 2-s2.0-84943225881
19 Khan M. A. Multiresolution coding of motion capture data for real-time multimedia applications[J] Multimedia Tools and Applications 2016 76 15 1 16 10.1007/s11042-016-3944-7 2-s2.0-84988416244
20 Puupponen A. Wainio T. Burger B. Jantunen T. Head movements in Finnish sign language on the basis of motion capture data Sign Language and Linguistics 2015 18 1 41 89 10.1075/sll.18.1.02puu 2-s2.0-84946092459
21 Lee Y. Yoo H. Low-cost 3D motion capture system using passive optical markers and monocular vision Optik International Journal for Light & Electron Optics 2016 130 2 1397 1407
22 Rahman M. M. Analysis of finger movements of a pianist using magnetic motion capture system with six dimensional position sensors Transactions of the Virtual Reality Society of Japan 2017 15 3 243 250

