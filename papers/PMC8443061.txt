
==== Front
PLoS One
PLoS One
plos
PLoS ONE
1932-6203
Public Library of Science San Francisco, CA USA

PONE-D-21-15070
10.1371/journal.pone.0252108
Research Article
Physical Sciences
Mathematics
Operator Theory
Kernel Functions
Physical Sciences
Mathematics
Probability Theory
Probability Distribution
Normal Distribution
Physical Sciences
Mathematics
Probability Theory
Statistical Distributions
Distribution Curves
Medicine and Health Sciences
Medical Conditions
Neurodevelopmental Disorders
Adhd
Biology and Life Sciences
Neuroscience
Developmental Neuroscience
Neurodevelopmental Disorders
Adhd
Medicine and Health Sciences
Neurology
Neurodevelopmental Disorders
Adhd
Medicine and Health Sciences
Mental Health and Psychiatry
Neuropsychiatric Disorders
Adhd
Research and Analysis Methods
Mathematical and Statistical Techniques
Statistical Methods
Forecasting
Physical Sciences
Mathematics
Statistics
Statistical Methods
Forecasting
Biology and Life Sciences
Neuroscience
Brain Mapping
Functional Magnetic Resonance Imaging
Medicine and Health Sciences
Diagnostic Medicine
Diagnostic Radiology
Magnetic Resonance Imaging
Functional Magnetic Resonance Imaging
Research and Analysis Methods
Imaging Techniques
Diagnostic Radiology
Magnetic Resonance Imaging
Functional Magnetic Resonance Imaging
Medicine and Health Sciences
Radiology and Imaging
Diagnostic Radiology
Magnetic Resonance Imaging
Functional Magnetic Resonance Imaging
Research and Analysis Methods
Imaging Techniques
Neuroimaging
Functional Magnetic Resonance Imaging
Biology and Life Sciences
Neuroscience
Neuroimaging
Functional Magnetic Resonance Imaging
Biology and Life Sciences
Psychology
Developmental Psychology
Pervasive Developmental Disorders
Autism Spectrum Disorder
Social Sciences
Psychology
Developmental Psychology
Pervasive Developmental Disorders
Autism Spectrum Disorder
Physical Sciences
Mathematics
Statistics
Statistical Noise
Gaussian Noise
The pitfalls of using Gaussian Process Regression for normative modeling
The pitfalls of using Gaussian Process Regression for normative modeling
https://orcid.org/0000-0001-5876-1740
Xu Bohan Formal analysis Investigation Methodology Writing – original draft 1 2 *
https://orcid.org/0000-0003-2954-6421
Kuplicki Rayus Writing – review & editing 1
Sen Sandip Writing – review & editing 2
https://orcid.org/0000-0002-0825-3606
Paulus Martin P. Writing – review & editing 1 3 4
1 Laureate Institute for Brain Research, Tulsa, OK, United States of America
2 Department of Computer Science, Tandy School of Computer Science, University of Tulsa, Tulsa, OK, United States of America
3 Department of Community Medicine, Oxley College of Health Sciences, University of Tulsa, Tulsa, OK, United States of America
4 Department of Psychiatry, School of Medicine, University of California San Diego, San Diego, CA, United States of America
Chen Chi-Hua Editor
Fuzhou University, CHINA
Competing Interests: The authors have declared that no competing interests exist.

* E-mail: bxu@laureateinstitute.org
2021
15 9 2021
16 9 e02521086 5 2021
27 8 2021
© 2021 Xu et al
2021
Xu et al
https://creativecommons.org/licenses/by/4.0/ This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.

Normative modeling, a group of methods used to quantify an individual’s deviation from some expected trajectory relative to observed variability around that trajectory, has been used to characterize subject heterogeneity. Gaussian Processes Regression includes an estimate of variable uncertainty across the input domain, which at face value makes it an attractive method to normalize the cohort heterogeneity where the deviation between predicted value and true observation is divided by the derived uncertainty directly from Gaussian Processes Regression. However, we show that the uncertainty directly from Gaussian Processes Regression is irrelevant to the cohort heterogeneity in general.

National Institute of General Medical Sciences P20GM121312 https://orcid.org/0000-0002-0825-3606
Paulus Martin P. This research was supported by the Laureate Institute for Brain Research and the National Institute of General Medical Sciences (P20GM121312, MP, RK). Data AvailabilityThe data is generated from a python script, and the python script is available on the Github (https://github.com/nidaye1999/normative-model-GPR).
Data Availability

The data is generated from a python script, and the python script is available on the Github (https://github.com/nidaye1999/normative-model-GPR).
==== Body
pmcIntroduction

In case-control studies, participants are assigned labels and classified into one or more categories based on their similarities or common criteria, with little consideration for the heterogeneity within each cohort. Meanwhile, normative modeling is becoming increasingly popular. In a normative model, each observation is quantified as a normalized deviation with respect to the cohort heterogeneity. The growth chart [1, 2] is an example normative model as shown in Fig 1, where a series of percentile curves (normalized deviation) illustrate the distribution of selected body measurements in children. Another widely-used measure for normalized deviation is the z-score, which is calculated by dividing the difference between an observation and the reference model, i.e., residual, by a standard deviation that represents local heterogeneity and assumes residuals are Gaussian distributed locally.

10.1371/journal.pone.0252108.g001 Fig 1 Weight-for-age boys: Birth to 2 years.

Reprinted from [3] under a CC BY license, with permission from World Health Organization, original copyright (2021). The percentiles show the distribution of weights in boys form birth to 2 years. Black dots: observations; red error bars: epistemic uncertainty; blue curly brackets: aleatoric uncertainty.

The uncertainty sometimes can be classified into two categories: epistemic and aleatoric uncertainties. Epistemic uncertainty is known as systematic uncertainty and is due to things one could in principle know but do not in practice; aleatoric uncertainty is known as statistical uncertainty and is representative of unknowns that differ each time we run the same experiment [4]. Epistemic uncertainty is often introduced by the limited dataset size and can be reduced by adding more observations. On the other hand, aleatoric uncertainty represents a character of heterogeneity in the underlying distribution itself which is unrelated to sample size, so it cannot be reduced by modifying the dataset, and this is the heterogeneity a normative model should measure. As shown in Fig 1, larger number and density of data points (black dots) reduce the epistemic uncertainty (red error bars), while the aleatoric uncertainty (blue curly brackets) is unrelated to the sample size or distribution. The confidence intervals obtained from most statistical tests and advanced machine learning models only capture epistemic uncertainty, while a normative model is designed to capture the aleatoric uncertainty.

Gaussian Process Regression (GPR) has been widely used in many domains. Schulz et al. [5] presented a tutorial on the GPR with the mathematics behind the model as well as several applications to real-life datasets/problems. Tonner et al. [6] developed a GPR based model and testing framework to capture the microbial population growth and shown their proposed approach outperformed primary growth models. Banerjee et al. [7] and Raissi et al. [8] introduced two novel approaches to improve the efficiency of GPR in “big data” problems.

However, some previous research implemented the GPR as a normative modeling approach and utilized the derived prediction variance to model the cohort heterogeneity. Ziegler et al. [9] attempted to build a normative model for diagnosing mild cognitive impairment and Alzheimer’s disease based on the normalized deviation of predicted brain volume from GPR. Marquand et al. [10] used delay discounting as covariates and reward-related brain activity derived from task Functional Magnetic Resonance Imaging (fMRI) as the target variable with GPR and extreme value statistics to identify the participants with Attention-Deficit/Hyperactivity Disorder (ADHD). Wolfers et al. [11] investigated the deviation of brain volume in an ADHD cohort from healthy control group (HC) with respect to age and gender, and they also explored the heterogeneous phenotype of brain volume for schizophrenia and bipolar disorder with GPR [12]. Zabihi et al. [13] studied Autism Spectrum Disorder (ASD) regarding the deviation of cortical thickness via a similar methodology.

In this paper, we introduce some background knowledge related to GPR. We then present a rigorous mathematical derivation and several examples to demonstrate that the variance from GPR cannot be used in a normative model alone. In the last section, we discuss the difficulties and disadvantages of modeling the cohort heterogeneity by modifying original GPR variance, and a misunderstanding existed in previous research.

Materials and methods

Gaussian Process Regression

The relation between the observation and the predictive model usually can be expressed as y=f(x)+ε,(1)

where y is the observation (output), f(⋅) represents the predictive model, x is a vector of independent variables (input) corresponding to the output y, and ε is the noise term which follows a normal distribution ε∼N(0,σnoise2). Gaussian Process Regression (GPR) assumes a zero-mean normal distribution over the predictive model f(·)∼N(0,k(·,·)),(2)

where k(⋅, ⋅) is some covariance (kernel) function. Given the training set input X and testing set input X*, since both of them follow the same distribution, we have f([XX*])∼N(0,[K(X,X)K(X,X*)K(X*,X)K(X*,X*)]).(3)

According to the Eq 1, the observation follows the summation of these two normal distributions [yy*]=f([XX*])+[εε*]∼N(0,[K(X,X)+Σtrain2K(X,X*)K(X*,X)K(X*,X*)+Σtest2]),(4)

where Σtrain2 and Σtest2 are two square diagonal matrices that represent the variance of observation noise in training and testing sets, and all diagonal elements of Σtrain2 and Σtest2 are identical and equal to σnoise2. By the rules of conditional Gaussian distribution, the prediction of testing set y* follows a normal distribution y*∼N(μ*,Σ*2), where μ* and Σ*2 are defined as [14, 15] μ*=K(X*,X)[K(X,X)+Σtrain2]-1y,(5a)Σ*2=K(X*,X*)+Σtest2-K(X*,X)[K(X,X)+Σtrain2]-1K(X,X*).(5b)

Kernel trick

Similar to Support Vector Machines (SVM), the kernel trick can also be implemented with GPR to project the input of data from the original space into a same or higher dimensional feature space via some mapping function z(⋅). Given a pair of inputs (x1,x2), the kernel function calculates the inner product of the coordinates in the feature space, i.e., k(x1,x2) = z(x1)z(x2)T [16, 17]. The kernel trick avoids the expensive computation of calculating the coordinate in the feature space for each input. We use the linear kernel and Radial Basis Function kernel (RBF) as examples to illustrate this advantage.

Linear kernel

The linear kernel is non-stationary and the simplest kernel, which is defined as k(x1,x2)=x1x2T,(6a)z(x)=x,(6b)

where the input is projected into a feature space according to Eq 6b, and the feature space is the original space.

Radial Basis Function kernel

The RBF kernel is a stationary kernel, which is also widely used and defined as [17] k(x1,x2)=e-∥x1-x2∥22l2,(7a)z(x)=[e-∥x∥22l2jl2jj!1jj!n1!⋯nk!x1n1⋯xknk]j=0,⋯,∞,∑i=1kni=j,(7b)

where l is a free scaling parameter. The RBF kernel projects the input from the original space onto an infinite dimensional feature space where the mapping is defined by Eq 7b. It is impossible to exactly compute the coordinates in an infinite dimensional space, while Eq 7a still allows straightforward computation of the inner product for coordinate pairs in that feature space.

Matérn and Rational-Quadratic kernels

Matérn kernel is a generalization of the RBF kernel which is defined as [14] k(x1,x2)=21-νΓ(ν)(2νl∥x1-x2∥)νKν(2νl∥x1-x2∥),(8)

where the parameter ν controls the smoothness of the function, Γ(⋅) refers to the gamma function, and Kν(⋅) represents modified Bessel function. Rational-Quadratic kernel is another kernel based on the RBF kernel, which is given by k(x1,x2)=(1+∥x1-x2∥22αl2)-α,(9)

where α is a scale mixture parameter. The Rational-Quadratic kernel can be considered as an infinite sum of RBF kernels with different length-scales l [18].

Estimated uncertainty for GPR

One benefit of using GPR to build a data-driven model is the predictions are associated with the derived variances as shown in Eq 5. However, we need to emphasize that this variance is only related to the kernel function k(⋅, ⋅) and distribution/coordinate of training set input X, i.e., it cannot be utilized in a normative model approach alone to capture the variance introduced by the conditional distribution Var(y|x).

We better illustrate and verify this statement through simplifying the Eq 5b. Since any kernel function k(⋅, ⋅) can be written as the inner product of a coordinate pair in the feature space by some mapping function z(⋅), we present our derivation in a general format. We define a variable x* which represents a testing input, then Eq 5b can be written as Σ*2(x*)=k(x*,x*)+σtest2-k(x*,X)[K(X,X)+Σtrain2]-1k(X,x*)(10a)=z(x*)z(x*)T+σtest2-z(x*)Z(X)T[Z(X)Z(X)T+Σtrain2]-1Z(X)z(x*)T.(10a)

Applying Singular Value Decomposition (SVD) on ∑train−1Z(X)=U∑VT, Eq 10 is reformulated as (the detailed derivation is presented in S1 Appendix) Σ*2(x*)=z(x*)z(x*)T+σtest2-z(x*)Z(X)T[Z(X)Z(X)T+Σtrain2]-1Z(X)z(x*)T=z(x*)V[I-ΣT(ΣΣT+I)-1Σ]VTz(x*)T︸quadraticterm+σtest2︸constant.(11)

After simplification, the variance is reformulated as Eq 11, which is a summation of a quadratic term for z(x*) and a constant represents the noise, Σ and V are constant matrices where the values are fully depended on training input X, training noise Σtrain, and mapping function z(⋅) or kernel function k(⋅, ⋅).

Modification of uncertainty from GPR

Regarding Eq 11, the variance calculated via Eq 5b is purely depended on kernel function and training data input, thus it is only able to capture the epistemic uncertainty which could be reduced by modifying or adding training data. The derived variance from GPR could be extended to model the heterogeneity Var(y|x) for a normative model by adding an aleatoric variance term into Eq 5b Var(y*|X*)=K(X*,X*)+Σtest2-K(X*,X)[K(X,X)+Σtrain2]-1K(X,X*)︸epistemicuncertainty+Σaleatoric2(X*)︸aleatoricuncertainty,(12)

where ∑aleatoric2(X*) represents the data character of heterogeneity in output at given locations on the input space. This formula, however, is not implemented in any previous research as we know and we will discuss the difficulties and disadvantages in estimating the aleatoric uncertainty later.

Results

We apply the unmodified GPR (Eq 5) on several synthetic datasets where both input x and output y are one dimensional to facilitate visualization. Although the presented results are based on one dimensional input x, they are generalizable to any dimensional input. We illustrate the characteristics of the four kernels mentioned above, but we mainly focus on the linear and RBF kernels. We also present the results of two scenarios with known and unknown noise levels.

Dataset

Four synthetic datasets are generated and plotted in Fig 2, and each of them contains 1000 points with a noise level of σnoise = 0.05. Four other undersampled datasets are plotted in Fig 3, each of which contains 1000 × 5% = 50 points.

10.1371/journal.pone.0252108.g002 Fig 2 Original datasets.

10.1371/journal.pone.0252108.g003 Fig 3 Undersampled datasets.

In Dataset 1, both input X and output y follow a Gaussian distribution N(0,12) and are correlated with a Pearson coefficient of 0.75. Dataset 2 is transformed from Dataset 1, which moves the set of points where x ≥ 0 in Dataset 1 along the line y = x until the maximum input in that set equals 0, and moves the remaining points where x < 0 in Dataset 1 until the minimum input is 0. Dataset 3 has input X and output y uniformly distributed over a half-open interval [−π, π). Output y of Dataset 4 is obtained by multiplying a factor function over output y from Dataset 3, which is defined as f(x) = sin(x)/2 + 1 and x is the corresponding input. We should note that the inputs X of original Datasets 3–4 are exactly same as shown in Fig 2C and 2D, and the inputs X of corresponding undersampled Datasets 3–4 are also identical as shown in Fig 3C and 3D.

GPR with known noise level

Linear kernel

The regression surface of GPR with linear kernel is a hyperplane and the variance is a quadric hypersurface defined by Eq 11 in feature/original spaces, where the hyperplane always passes the origin, the variance is a function only with respect to the coordinate of testing input x* and a unique minimum is located at x* = 0. Figs 4 and 5 present results for GPR with linear kernel on the one dimensional synthetic datasets, where top sub-figures plot the reference models/predictions (red lines) overlapped on the data (blue dots), middle sub-figures show the derived variances (blue curves) across the original input space, and the bottom sub-figures shows the corresponding “z-score” for training set which is computed via Eq 13 if the residual (y − yreference) is mistakenly normalized by standard deviation Σ directly from GPR (Eq 5b). z-score=y-yreferenceΣ(13)

10.1371/journal.pone.0252108.g004 Fig 4 GPR with linear kernel on original datasets.

10.1371/journal.pone.0252108.g005 Fig 5 GPR with linear kernel on undersampled datasets.

The mapping function of linear kernel projects an input to itself (Eq 6b). For one dimensional input, Σ in Eq 11 is an m × 1 matrix, where m is the size of training set. The only non-zero element Σ1,1 equals the only non-zero singular value σ of ∑train−1X, and V is a 1 × 1 identity matrix. Therefore, Eq 11 can be further reduced to Σ*2(x*)=[1-ΣT(ΣΣT+I)-1Σ]x*2+σtest2=(1-σ2σ2+1)x*2+σtest2=x*2σ2+1+σtest2.(14)

As shown in Figs 4 and 5, the variance is a univariate function of coordinate of the testing input x* where the shape is a quadratic curve, and the global minimum is always located at x* = 0 with a value of σtest2=0.052 as Eq 14 formulated. The result of GPR with linear kernel presents a good example which illustrates the derived variance from GPR does not model the conditional variance Var(y|x), thus corresponding z-score cannot be utilized as a normalized deviation in a normative model.

As previously mentioned, the predicted variance for testing set from GPR only depends on the training set input and the kernel function. As the original as well as the undersampled Datasets 3–4 have identical inputs X, the variance curves in Figs 4C, 4D, 5C and 5D are respectively identical.

RBF kernel

Unlike the linear kernel, RBF kernel mapping function (Eq 7b) defines a feature space which is different from the original space. Regarding the original space, the regression surface is no longer a hyperplane and the variance is no more a quadric hypersurface for the RBF kernel, although regression surface is always a hyperplane and variance is always a quadric hypersurface for any kernels in the feature space. Because the mapping function of RBF kernel is very complicated, we only briefly describe the characteristics of the regression surface and variance in the original space. For a test input x*, the prediction is a summation of discounted outputs of all training points where each corresponding discount factor is determined by the Euclidean distance between x* and that training input, and the predicted value converges to 0 if x* is far away from all training inputs. On the other hand, the variance depends only on the density of training inputs at x*, and higher density results in lower variance. Therefore, the variance of GPR with RBF kernel is related of the relative location to the training inputs rather than the absolute location specified by coordinate.

The results for GPR with RBF kernel applied to these synthetic datasets are shown in Figs 6 and 7. We should note that the value of hyper-parameter l in the RBF kernel function (Eq 7a) does not affect the main idea of this paper, thus we used a fixed value of 1.0 instead of utilizing hyper-parameter optimization in this section. As shown in Figs 6 and 7, the variance is unrelated to the conditional variance Var(y|x). Therefore, z-scores based on this model do not represent normalized deviation. However, unlike the quadratic curves whose unique minimum is always located at x = 0 in Figs 4 and 5 for linear kernel, the variance function of GPR with RBF kernel regarding the original input space is related to the distribution of training input X. The denser inputs at the middle of Dataset 1 and two ends of Dataset 2 lead to lower variances at those locations in Fig 6A and 6B, while the uniformly distributed inputs of Datasets 3–4 result in relatively flat curves in and Fig 6C and 6D. According to Eq 7a and given an arbitrary input x*, the RBF kernel function returns a larger value for a point in X that is closer to x*, and k(x*,X) and k(X,x*) have more large elements if x* is close to more points in X. Due to K(X,X)+∑train2 is a symmetric positive definite matrix, both result in the decrease of the value for Eq 10a, i.e., to smaller variance.

10.1371/journal.pone.0252108.g006 Fig 6 GPR with RBF kernel on original datasets.

10.1371/journal.pone.0252108.g007 Fig 7 GPR with RBF kernel on undersampled datasets.

Scales of Y-axis for variance plots are different.

Similar to the result for the linear kernel, the theoretical minimum of variance is σtest2=0.052, and the variance curves are exactly identical in Figs 6C, 6D, 7C and 7D respectively.

Matérn and Rational-Quadratic kernels

The properties of Matérn and Rational-Quadratic kernels are similar to the RBF kernel. Therefore, we only present the results in Figs 8–11 for these two kernels without the detailed analysis. Similar to RBF kernel, the hyper-parameters of Matérn and Rational-Quadratic kernels are also fixed in this section, where ν = 1.5 for Matérn kernel, α = 1.0 for Rational-Quadratic kernel, and l = 1.0 for both kernels. The variance curves shown in Figs 8C, 8D, 9C, 9D, 10C, 10D, 11C and 11D are exactly identical, respectively.

10.1371/journal.pone.0252108.g008 Fig 8 GPR with matérn kernel on original datasets.

Scales of Y-axis for variance plots are different.

10.1371/journal.pone.0252108.g009 Fig 9 GPR with matérn kernel on undersampled datasets.

Scales of Y-axis for variance plots are different.

10.1371/journal.pone.0252108.g010 Fig 10 GPR with Rational-Quadratic kernel on original datasets.

Scales of Y-axis for variance plots are different.

10.1371/journal.pone.0252108.g011 Fig 11 GPR with Rational-Quadratic kernel on undersampled datasets.

Scales of Y-axis for variance plots are different.

GPR with unknown noise level

The noise level can be included as a hyper-parameter when it is unknown. However, the derived variance from GPR still does not model the heterogeneity Var(y|x), although it could be a good approximation in some special cases.

As the basic properties of linear and RBF kernels have been introduced, a hybrid kernel is utilized in the following analysis which is defined as khybrid(·,·)=wlinearklinear(·,·)+wRBFkRBF(·,·)+kwhite(·,·),(15)

where wlinear and wRBF represent adjustable weights on linear and RBF kernels, and kwhite(⋅, ⋅) refers to a white-noise kernel that represents the independently and identically normally-distributed observation noise, i.e., Kwhite(X,X)=∑train2, Kwhite(X*,X*)=∑test2, Kwhite(X,X*) = 0, and Kwhite(X*,X) = 0. Because the Matérn and Rational-Quadratic kernels are both based on the RBF kernel, so we only include the RBF kernel in the hybrid kernel. The Eq 5b can be reformulated as Σ*2=Khybrid(X*,X*)-Khybrid(X*,X)Khybrid(X,X)-1Khybrid(X,X*).(16)

Original Datasets 3–4 in Fig 2C and 2D are prefect for testing whether a model captures the heterogeneity Var(y|x), as the large number of instances and uniformly distributed data over the input space lead to negligible epistemic uncertainty in certain input range, and the true reference model y = 0 is very simple as well. Besides, the results of two more complex datasets with quadratic reference models are presented in the S1 Appendix. In this section, the hyper-parameters are tuned by maximizing the likelihood P(y|X,θ), where θ represents all hyper-parameters in the model. The results are plotted in Fig 12, and the optimized hyper-parameters are listed in Table 1 as well as the overall variances of residual Var(y − yreference).

10.1371/journal.pone.0252108.g012 Fig 12 GPR with hybrid kernel on original datasets 3–4.

Scales of Y-axis for variance plots are different.

10.1371/journal.pone.0252108.t001 Table 1 Optimized hyper-parameters for hybrid kernel on original datasets 3–4.

	w linear	w RBF	l	σnoise2	Var(y−yreference	
Dataset 3	7.29e-8	4.88e-10	2.94e2	3.29	3.29	
Dataset 4	1.35e-7	1.98e-17	1.54e-5	3.64	3.64	

As shown in Fig 12, the GPR accurately estimates the reference models, i.e., yreference ≈ yreference,true. The variance curves are nearly quadratic, since the wlinear is relatively larger than wRBF while wRBF is not exact zero as listed in Table 1. However, the domination of kwhite(⋅, ⋅) over klinear(⋅, ⋅) and kRBF(⋅, ⋅) due to small optimized weights flattens the curves, i.e., the value of the curve is almost constant over the plotted input range in this example. Particularly, the σnoise2 is very close to the overall residual variance Var(y−yreference), and the explanation will be presented later. Therefore, Khybrid(X*,X*)≈∑test2, Khybrid(X,X)≈∑train2, Khybrid(X*,X) ≈ 0 and Khybrid(X,X*) ≈ 0, which result in ∑*2≈∑test2=∑noise2 for Eq 16.

Regarding Eq 1, since the noise is included as a tunable hyper-parameter without any constraints, the optimizer will adjust reference model f(⋅) as well as bias σnoise2 to Var(y−yreference) to maximize the likelihood P(y|X,θ). Even the σnoise refers to the observation noise level in GPR while the optimizer handles it as a variable without considering its meaning in a model.

In Dataset 3, σnoise2 is biased to the overall residual variance Var(y−yreference), and Var(y−yreference) is well matched with the homoskedastic heterogeneity Var(y|x). So the z-scores plotted in Fig 12A show the GPR works as a normative model approach in this special case. However, in Dataset 4, σnoise2 is also biased to the overall residual variance Var(y−yreference), while Var(y−yreference) does not approximate the heteroskedastic heterogeneity Var(y|x). So the z-scores plotted in Fig 12B do not represent a measure of normalized deviation in general.

Discussion

Although GPR could be extended and to model the heterogeneity as presented in this work, it is either: (1) hard to estimate the aleatoric uncertainty accurately when the data are sparse, e.g., at the middle of Dataset 2; or (2) unnecessary to model the conditional variance by Eq 12 when the data are dense, e.g., Datasets 3–4. One approach to estimate σaleatoric2(x*) is using the sliding window technique, but it is hard to choose the window size for each dimension of input. For Scenario 1, even if the optimal window sizes can be obtained, it is hard to accurately estimate σaleatoric2(x*) when the window centered at x* only covers a small number of training data points, e.g., x* is far away from all points in X. If the window centered at x* covers a large number of training data points, e.g., Scenario 2, Var(y|x*) should almost equal σaleatoric2(x*) and epistemic uncertainty is insignificant. Then Var(y|x*) can be simply approximated as a local variance over a space defined by the window. There are more sophisticated algorithms than the naive sliding window technique, e.g., LOcal regrESSion (LOESS) [19, 20] and Generalized Additive Models of Location Shape and Scale (GAMLSS) [21, 22]. However, these methods still need densely distributed data over the input space based on our experience.

Another misunderstanding we found in the literature is interpreting the noise term σnoise2 as aleatoric uncertainty. When the observation noise is considered as a hyper-parameter, it will likely bias the overall residual variance Var(y−yreference). The overall residual variance is a good approximation of homoskedastic aleatoric uncertainty Var(y|x). It is, however, not valid for cases with heteroskedastic residuals, which is the main motivation for using normative modeling. Although the value of the noise term is biased to estimate overall residual variance during the optimization, the mathematical/physical meanings are pre-defined by the model. Moreover, in homoskedastic aleatoric uncertainty cases, further investigation is needed to verify whether K(X*,X*)−K(X*,X)[K(X,X)+∑noise2]−1K(X,X*) will still be a good approximation of epistemic uncertainty with such a biased estimation of observation noise level.

Conclusions

In this paper, we present the mathematical derivation with a general formula to demonstrate that the derived prediction variance from GPR does not model the heterogeneity Var(y|x), which in general is necessary for a normative model. GPR with a linear kernel and an RBF kernel are used as examples to illustrate this statement on one dimensional input datasets. Overall, the derived variance from GPR cannot be utilized in a normative model alone.

Supporting information

S1 Appendix This file contains data/code availability, Eq S1, S1 Fig, and S1 Table.

All datasets are generated from the same Python script, which contains the code for analysis as well; Eq S1 is a detailed derivation for Eq 11; S1 Fig and S1 Table are results for modified Datasets 3-4.

(PDF)

Click here for additional data file.

I would sincerely appreciate my families and friends from Laureate Institute for Brain Research, the University of Tulsa, and Brain Technologies Inc. for helping me through my brain tumor surgery and the subsequent recovery during the revision of this paper. Special appreciation to Kaiping Burrows and Leandra Figueroa-Hall.

We would also like to thank the journal editor and anonymous reviewers for insightful discussions and feedback that have improved our study and manuscript.

10.1371/journal.pone.0252108.r001
Decision Letter 0
Chen Chi-Hua Academic Editor
© 2021 Chi-Hua Chen
2021
Chi-Hua Chen
https://creativecommons.org/licenses/by/4.0/ This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
Submission Version0
7 Jun 2021

PONE-D-21-15070

The pitfalls of using Gaussian Process Regression for normative modeling

PLOS ONE

Dear Dr. Xu,

Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE’s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.

Please submit your revised manuscript by Jul 22 2021 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at plosone@plos.org. When you're ready to submit your revision, log on to https://www.editorialmanager.com/pone/ and select the 'Submissions Needing Revision' folder to locate your manuscript file.

Please include the following items when submitting your revised manuscript:

A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.

A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.

An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.

If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.

If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: http://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols. Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at https://plos.org/protocols?utm_medium=editorial-email&utm_source=authorletters&utm_campaign=protocols.

We look forward to receiving your revised manuscript.

Kind regards,

Chi-Hua Chen, Ph.D.

Academic Editor

PLOS ONE

Journal Requirements:

1) Please review your reference list to ensure that it is complete and correct. If you have cited papers that have been retracted, please include the rationale for doing so in the manuscript text, or remove these references and replace them with relevant current references. Any changes to the reference list should be mentioned in the rebuttal letter that accompanies your revised manuscript. If you need to cite a retracted article, indicate the article’s retracted status in the References list and also include a citation and full reference for the retraction notice.

2) Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. The PLOS ONE style templates can be found at

https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf and

https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf

3)  Thank you for stating the following in the Acknowledgments Section of your manuscript:

[Also, special thanks to Laureate Institute for Brain Research and the University of Tulsa for supporting this research.]

We note that you have provided funding information that is not currently declared in your Funding Statement. However, funding information should not appear in the Acknowledgments section or other areas of your manuscript. We will only publish funding information present in the Funding Statement section of the online submission form.

Please remove any funding-related text from the manuscript and let us know how you would like to update your Funding Statement. Currently, your Funding Statement reads as follows:

 [This research was supported by the Laureate Institute for Brain Research and the

National Institute of General Medical Sciences (P20GM121312, MP, RK)]

Please include your amended statements within your cover letter; we will change the online submission form on your behalf.

4)  We note that Figure 1 in your submission contain copyrighted images. All PLOS content is published under the Creative Commons Attribution License (CC BY 4.0), which means that the manuscript, images, and Supporting Information files will be freely available online, and any third party is permitted to access, download, copy, distribute, and use these materials in any way, even commercially, with proper attribution. For more information, see our copyright guidelines: http://journals.plos.org/plosone/s/licenses-and-copyright.

We require you to either (1) present written permission from the copyright holder to publish these figures specifically under the CC BY 4.0 license, or (2) remove the figures from your submission:

i. You may seek permission from the original copyright holder of Figure(s) [#] to publish the content specifically under the CC BY 4.0 license.

We recommend that you contact the original copyright holder with the Content Permission Form (http://journals.plos.org/plosone/s/file?id=7c09/content-permission-form.pdf) and the following text:

“I request permission for the open-access journal PLOS ONE to publish XXX under the Creative Commons Attribution License (CCAL) CC BY 4.0 (http://creativecommons.org/licenses/by/4.0/). Please be aware that this license allows unrestricted use and distribution, even commercially, by third parties. Please reply and provide explicit written permission to publish XXX under a CC BY license and complete the attached form.”

Please upload the completed Content Permission Form or other proof of granted permissions as an "Other" file with your submission. 

In the figure caption of the copyrighted figure, please include the following text: “Reprinted from [ref] under a CC BY license, with permission from [name of publisher], original copyright [original copyright year].”

ii.    If you are unable to obtain permission from the original copyright holder to publish these figures under the CC BY 4.0 license or if the copyright holder’s requirements are incompatible with the CC BY 4.0 license, please either i) remove the figure or ii) supply a replacement figure that complies with the CC BY 4.0 license. Please check copyright information on all replacement figures and update the figure caption with source information. If applicable, please specify in the figure caption text when a figure is similar but not identical to the original image and is therefore for illustrative purposes only.

[Note: HTML markup is below. Please do not edit.]

Reviewers' comments:

Reviewer's Responses to Questions

Comments to the Author

1. Is the manuscript technically sound, and do the data support the conclusions?

The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented.

Reviewer #1: Yes

**********

2. Has the statistical analysis been performed appropriately and rigorously?

Reviewer #1: Yes

**********

3. Have the authors made all data underlying the findings in their manuscript fully available?

The PLOS Data policy requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.

Reviewer #1: Yes

**********

4. Is the manuscript presented in an intelligible fashion and written in standard English?

PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.

Reviewer #1: Yes

**********

5. Review Comments to the Author

Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)

Reviewer #1: This paper introduced some background knowledge related to GPR and presented a rigorous mathematical derivation and several examples to demonstrate that the variance from GPR cannot be used in a normative model alone. In addition, they discussed the difficulties and disadvantages of modeling the cohort heterogeneity by modifying original GPR variance, and a misunderstanding existed in previous research.

1. In Row 64, “where Σ2 train and Σ2 test are two diagonal matrices that represent the variance of observation noise in training and testing sets, and the diagonal elements equal σ2_noise”. Are all diagonal elements equal σ2_noise?

2. The limited results are not comprehensive enough. The experimental results of other kernel methods should be reported for a fair comparison.

3. The pictures shown in this paper are too vague, I suggest the author redraw them.

**********

6. PLOS authors have the option to publish the peer review history of their article (what does this mean?). If published, this will include your full peer review and any attached files.

If you choose “no”, your identity will remain anonymous but your review may still be made public.

Do you want your identity to be public for this peer review? For information about this choice, including consent withdrawal, please see our Privacy Policy.

Reviewer #1: No

[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]

While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, https://pacev2.apexcovantage.com/. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at figures@plos.org. Please note that Supporting Information files do not need this step.

10.1371/journal.pone.0252108.r002
Author response to Decision Letter 0
Submission Version1
18 Aug 2021

A rebuttal letter is uploaded.

Attachment Submitted filename: Response to Reviewers.pdf

Click here for additional data file.

10.1371/journal.pone.0252108.r003
Decision Letter 1
Chen Chi-Hua Academic Editor
© 2021 Chi-Hua Chen
2021
Chi-Hua Chen
https://creativecommons.org/licenses/by/4.0/ This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
Submission Version1
31 Aug 2021

The pitfalls of using Gaussian Process Regression for normative modeling

PONE-D-21-15070R1

Dear Dr. Xu,

We’re pleased to inform you that your manuscript has been judged scientifically suitable for publication and will be formally accepted for publication once it meets all outstanding technical requirements.

Within one week, you’ll receive an e-mail detailing the required amendments. When these have been addressed, you’ll receive a formal acceptance letter and your manuscript will be scheduled for publication.

An invoice for payment will follow shortly after the formal acceptance. To ensure an efficient process, please log into Editorial Manager at http://www.editorialmanager.com/pone/, click the 'Update My Information' link at the top of the page, and double check that your user information is up-to-date. If you have any billing related questions, please contact our Author Billing department directly at authorbilling@plos.org.

If your institution or institutions have a press office, please notify them about your upcoming paper to help maximize its impact. If they’ll be preparing press materials, please inform our press team as soon as possible -- no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact onepress@plos.org.

Kind regards,

Chi-Hua Chen, Ph.D.

Academic Editor

PLOS ONE

Additional Editor Comments (optional):

Reviewers' comments:

Reviewer's Responses to Questions

Comments to the Author

1. If the authors have adequately addressed your comments raised in a previous round of review and you feel that this manuscript is now acceptable for publication, you may indicate that here to bypass the “Comments to the Author” section, enter your conflict of interest statement in the “Confidential to Editor” section, and submit your "Accept" recommendation.

Reviewer #1: All comments have been addressed

**********

2. Is the manuscript technically sound, and do the data support the conclusions?

The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented.

Reviewer #1: Yes

**********

3. Has the statistical analysis been performed appropriately and rigorously?

Reviewer #1: Yes

**********

4. Have the authors made all data underlying the findings in their manuscript fully available?

The PLOS Data policy requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.

Reviewer #1: Yes

**********

5. Is the manuscript presented in an intelligible fashion and written in standard English?

PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.

Reviewer #1: Yes

**********

6. Review Comments to the Author

Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)

Reviewer #1: By reading the author's reply document, I think that the comments are answered well. I have no further concerns.

**********

7. PLOS authors have the option to publish the peer review history of their article (what does this mean?). If published, this will include your full peer review and any attached files.

If you choose “no”, your identity will remain anonymous but your review may still be made public.

Do you want your identity to be public for this peer review? For information about this choice, including consent withdrawal, please see our Privacy Policy.

Reviewer #1: No

10.1371/journal.pone.0252108.r004
Acceptance letter
Chen Chi-Hua Academic Editor
© 2021 Chi-Hua Chen
2021
Chi-Hua Chen
https://creativecommons.org/licenses/by/4.0/ This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
6 Sep 2021

PONE-D-21-15070R1

The pitfalls of using Gaussian Process Regression for normative modeling

Dear Dr. Xu:

I'm pleased to inform you that your manuscript has been deemed suitable for publication in PLOS ONE. Congratulations! Your manuscript is now with our production department.

If your institution or institutions have a press office, please let them know about your upcoming paper now to help maximize its impact. If they'll be preparing press materials, please inform our press team within the next 48 hours. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information please contact onepress@plos.org.

If we can help with anything else, please email us at plosone@plos.org.

Thank you for submitting your work to PLOS ONE and supporting open access.

Kind regards,

PLOS ONE Editorial Office Staff

on behalf of

Professor Chi-Hua Chen

Academic Editor

PLOS ONE
==== Refs
References

1 Kuczmarski RJ , Ogden CL , Grummer-Strawn LM , Flegal KM , Guo SS , Wei R , et al . CDC growth charts: United States. Advance data from vital and health statistics; 314 . Hyattsville, Maryland: National Center for Health Statistics; 2000.
2 Kuczmarski RJ , Ogden CL , Guo SS , Grummer-Strawn LM , Flegal KM , Mei Z , et al . 2000 CDC growth charts for the United States: methods and development. Vital Health Stat 11(246). Hyattsville, Maryland: National Center for Health Statistics; 2002.
3 World Health Organization. Reproduced from “Weight-for-Age Boys: Birth to 2 years (percentiles)” accessed 6-May-2021; Copyright (2021). Available from: https://cdn.who.int/media/docs/default-source/child-growth/child-growth-standards/indicators/weight-for-age/boys-charts---weight-for-age-birth-to-2-years-(percentiles).pdf.
4 Wikipedia contributors. Uncertainty quantification—Wikipedia, the free encyclopedia; 2021. Available from: https://en.wikipedia.org/w/index.php?title=Uncertainty_quantification&oldid=1015674163.
5 Schulz E , Speekenbrink M , Krause A . A tutorial on Gaussian process regression: modelling, exploring, and exploiting functions. Journal of Mathematical Psychology. 2018;85 :1–16. doi: 10.1016/j.jmp.2018.03.001
6 Tonner PD , Darnell CL , Engelhardt BE , Schmid AK . Detecting differential growth of microbial populations with Gaussian process regression. Genome Research. 2017;27 (2 ):320–333. doi: 10.1101/gr.210286.116 27864351
7 Banerjee A , Dunson DB , Tokdar ST . Efficient Gaussian process regression for large datasets. Biometrika. 2013;100 (1 ):75–89. doi: 10.1093/biomet/ass068 23869109
8 Raissi M , Babaee H , Karniadakis GE . Parametric Gaussian process regression for big data. Computational Mechanics. 2019;64 (2 ):409–416. doi: 10.1007/s00466-019-01711-5
9 Ziegler G , Ridgway GR , Dahnke R , Gaser C , Alzheimer’s Disease Neuroimaging Initiative. Individualized Gaussian process-based prediction and detection of local and global gray matter abnormalities in elderly subjects. NeuroImage. 2014;97 :333–348. doi: 10.1016/j.neuroimage.2014.04.018 24742919
10 Marquand AF , Rezek I , Buitelaar J , Beckmann CF . Understanding heterogeneity in clinical cohorts using normative models: beyond case-control studies. Biological Psychiatry. 2016;80 (7 ):552–561. doi: 10.1016/j.biopsych.2015.12.023 26927419
11 Wolfers T , Beckmann CF , Hoogman M , Buitelaar JK , Franke B , Marquand AF . Individual differences v. the average patient: mapping the heterogeneity in ADHD using normative models. Psychological Medicine. 2020;50 (2 ):314–323. doi: 10.1017/S0033291719000084 30782224
12 Wolfers T , Doan NT , Kaufmann T , Alnæs D , Moberget T , Agartz I , et al . Mapping the heterogeneous phenotype of schizophrenia and bipolar disorder using normative models. JAMA Psychiatry. 2018;75 (11 ):1146–1155. doi: 10.1001/jamapsychiatry.2018.2467 30304337
13 Zabihi M , Oldehinkel M , Wolfers T , Frouin V , Goyard D , Loth E , et al . Dissecting the heterogeneous cortical anatomy of autism spectrum disorder using normative models. Biological Psychiatry: Cognitive Neuroscience and Neuroimaging. 2019;4 (6 ):567–578. doi: 10.1016/j.bpsc.2018.11.013 30799285
14 Rasmussen CE , Williams CKI . Gaussian processes for machine learning. MIT Press; 2006.
15 Do CB. Gaussian processes; 2008. Available from: http://cs229.stanford.edu/section/cs229-gaussian_processes.pdf.
16 Mohri M , Rostamizadeh A , Talwalkar A . Foundations of machine learning. MIT press; 2018.
17 Shashua A. Introduction to machine learning: class notes 67577; 2009.
18 Duvenaud DK. Automatic model construction with Gaussian processes. Ph.D. Dissertation, University of Cambridge; 2014. Available from: https://www.cs.toronto.edu/~duvenaud/thesis.pdf.
19 Lefebvre A , Delorme R , Delanoë C , Amsellem F , Beggiato A , Germanaud D , et al . Alpha waves as a neuromarker of autism spectrum disorder: the challenge of reproducibility and heterogeneity. Frontiers in neuroscience. 2018;12 :662. doi: 10.3389/fnins.2018.00662 30327586
20 Maruani A , Dumas G , Beggiato A , Traut N , Peyre H , Cohen-Freoua A , et al . Morning plasma melatonin differences in autism: beyond the impact of pineal gland volume. Frontiers in psychiatry. 2019;10 :11. doi: 10.3389/fpsyt.2019.00011 30787884
21 Rigby RA , Stasinopoulos DM . Generalized additive models for location, scale and shape. Journal of the Royal Statistical Society: Series C (Applied Statistics). 2005;54 (3 ):507–554. doi: 10.1111/j.1467-9876.2005.00510.x
22 Borghi E , de Onis M , Garza C , Van den Broeck J , Frongillo EA , Grummer-Strawn L , et al . Construction of the World Health Organization child growth standards: selection of methods for attained growth curves. Statistics in medicine. 2006;25 (2 ):247–265. doi: 10.1002/sim.2227 16143968

