
==== Front
eNeuro
eNeuro
eneuro
eNeuro
eNeuro
2373-2822
Society for Neuroscience

34750155
10.1523/ENEURO.0245-21.2021
eN-NWR-0245-21
1
Research Article: New Research
Cognition and Behavior
Sharing Happy Stories Increases Interpersonal Closeness: Interpersonal Brain Synchronization as a Neural Indicator
https://orcid.org/0000-0002-4939-9791
Xie Enhui 1 *
Yin Qing 1 *
Li Keshuang 1
https://orcid.org/0000-0001-7013-5275
Nastase Samuel A. 2
Zhang Ruqian 1
Wang Ning 1
Li Xianchun 1
1 Shanghai Key Laboratory of Mental Health and Psychological Crisis Intervention, Affiliated Mental Health Center (ECNU), School of Psychology and Cognitive Science, East China Normal University, Shanghai 200062, China
2 Princeton Neuroscience Institute, Princeton University, Princeton, NJ 08544
The authors declare no competing financial interests.

Author contributions: Q.Y., R.Z., N.W., and X.L. designed research; E.X., Q.Y., R.Z., and N.W. performed research; E.X. analyzed data; E.X., K.L., S.A.N., and X.L. wrote the paper.

This work was supported by the Shanghai Key Base of Humanities and Social Science Grant Psychology-2018, National Natural Science Foundation of China Grants 32071082 and 71942001, the Key Specialist Projects of Shanghai Municipal Commission of Health and Family Planning Grant ZK2015B01, and the Programs Foundation of Shanghai Municipal Commission of Health and Family Planning Grant 201540114.

* E.X. and Q.Y. contributed equally to this work.

Correspondence should be addressed to Xianchun Li at xcli@psy.ecnu.edu.cn.
8 11 2021
18 11 2021
Nov-Dec 2021
8 6 ENEURO.0245-21.20211 6 2021
27 9 2021
30 9 2021
Copyright © 2021 Xie et al.
2021
Xie et al.
https://creativecommons.org/licenses/by/4.0/ This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International license, which permits unrestricted use, distribution and reproduction in any medium provided that the original work is properly attributed.

Abstract

Our lives revolve around sharing emotional stories (i.e., happy and sad stories) with other people. Such emotional communication enhances the similarity of story comprehension and neural across speaker-listener pairs. The theory of Emotions as Social Information Model (EASI) suggests that such emotional communication may influence interpersonal closeness. However, few studies have examined speaker-listener interpersonal brain synchronization (IBS) during emotional communication and whether it is associated with meaningful aspects of the speaker-listener interpersonal relationship. Here, one speaker watched emotional videos and communicated the content of the videos to 32 people as listeners (happy/sad/neutral group). Both speaker and listeners’ neural activities were recorded using EEG. After listening, we assessed the interpersonal closeness between the speaker and listeners. Compared with the sad group, sharing happy stories showed a better recall quality and a higher rating of interpersonal closeness. The happy group showed higher IBS in the frontal cortex and left temporoparietal cortex than the sad group. The relationship between frontal IBS and interpersonal closeness was moderated by sharing happy/sad stories. Exploratory analysis using support vector regression (SVR) showed that the IBS could also predict the ratings of interpersonal closeness. These results suggest that frontal IBS could serve as an indicator of whether sharing emotional stories facilitate interpersonal closeness. These findings improve our understanding of emotional communication among individuals that guides behaviors during interpersonal interactions.

emotion
interpersonal brain synchronization
interpersonal closeness
sharing stories
the Shanghai Key Base of Humanities and Social SciencePsychology-2018 the National Natural Science Foundation of China32071082 71942001 Key Specialist Projects of Shanghai Municipal Commission of Health and Family PlanningZK2015B01 the Programs Foundation of Shanghai Municipal Commission of Health and Family Planning201540114 cover-dateNovember/December 2021
==== Body
pmcSignificance Statement

Despite extensive research on interpersonal communication, little is known about emotional communication (happy/sad) between speaker and listener and whether these two types of emotional communication involve differential neurocognitive mechanisms from a brain-to-brain perspective. We address these questions from the perspective of the brain-to-brain approach and suggest that these two types of emotional communication are associated with differential interpersonal brain synchronization (IBS), in particular, subserved by the prefrontal region. Our findings shed light on the effect of sharing emotional (happy/sad) stories on interpersonal closeness and suggest that frontal IBS could serve as an indicator of whether sharing emotional (happy/sad) stories facilitate interpersonal closeness.

Introduction

Sharing specific stories with another person plays an important role in social interaction. Sharing stories is a way for people to organize and convey their thoughts (Willems et al., 2020), a way to enhance people’s ability to predict themselves and each other (Pickering and Garrod, 2013), and a social practice promoting the formation of collective memory (Hirst and Echterhoff, 2012). Maswood and Rajaram (2019) have demonstrated that sharing stories is accompanied by expressing emotional meaning. Sharing an emotional story is a social interaction during which emotional brain states are transmitted between speaker and listeners (Hasson et al., 2012; Chen et al., 2017; Zadbood et al., 2017). For example, Zadbood et al. (2017) demonstrated that the listener mentally reconstructs the episodes of a story when listening to a speaker’s recollection of an audiovisual movie, even if the listener did not watch the movie before. Nonetheless, relatively little is known about the effect of emotional communication on interpersonal relationship.

The theory of Emotions as Social Information Model (EASI) proposes that expressing emotional information is a social signal in interpersonal interaction (Van Kleef, 2009) and thus may increase interpersonal closeness. The listener receives both conscious and unconscious social cues from the speaker’s emotional expressions and the listener can regulate their emotional state to increase synchrony of emotional states with the speaker (Hari et al., 2015). This alignment may influence the interpersonal closeness of the speaker and listener during emotion-related interaction. Previous studies have provided evidence that the expression of emotional information can promote mutual understanding, strengthen interpersonal communication, and promote social connections (Nummenmaa et al., 2012; Dubois et al., 2014; Smirnov et al., 2019).

A stream of research has suggested that sharing both happy and sad stories may be critical to building a good interpersonal relationship (Isgett and Fredrickson, 2015; Shoham et al., 2016). Sharing happy stories can promote the attainment of desirable outcomes, such as obtaining social gratification from interpersonal interactions and strengthening interpersonal bonds (Fredrickson, 2001; Isgett and Fredrickson, 2015) by efficiently shaping a positive image to others (Ranzini and Hoek, 2017; Johnson and Ranzini, 2018). Sharing sad stories can enhance positive impressions and build close relationships based on powerful negative biases (Baumeister et al., 2001; Rozin and Royzman, 2001; Vaish et al., 2008; Fessler et al., 2015; Shoham et al., 2016). Although sharing happy and sad stories may both facilitate the interpersonal closeness, individuals seem to prefer to share the positive events in the story and suppress the negative ones (Gillath et al., 2005; Piotroski et al., 2015). When the speaker is sharing happy stories, the listener may experience feelings of pleasure, and even a sense of well-being; however, when the speaker is sharing sad stories, the listener may experience a sad feeling (Hanley et al., 2017). Such differences in emotional states are associated with differences in behavioral, physiological, and cognitive components (Anderson and Adolphs, 2014), and thus positive emotional state matching between speaker and listener may facilitate interpersonal relationships effectively than negative emotional communication. All of the above suggested that sharing happy stories may play a more important role in enhancing interpersonal closeness than sharing sad stories. However, the definite behavioral effect of sharing different emotional stories (happy/sad) on influencing interpersonal closeness remains unevaluated.

Interpersonal brain synchronization (IBS) can be a neuromarker of various interpersonal relationships during emotional communication (Stephens et al., 2010; Nummenmaa et al., 2012). Previous neuroimaging studies have indicated that sharing emotional stories causes individuals to be “on the same page” neurally (Dikker et al., 2014). The higher similarity of the neural responses in speaker-listener dyads has been associated with an increased shared interpretation of the narrative (Zadbood et al., 2017; Nguyen et al., 2019). Several studies have observed alignment of neural responses between the speaker and listener in a network of high-level cortical regions typically attributed to the prefrontal cortex (PFC) activity during such an emotional communication process (Stephens et al., 2010; Silbert et al., 2014; Zadbood et al., 2017). Further, neuroimaging results suggested that brain activity in the θ band was correlated with emotion, memory encoding, and information transmitting (Klimesch et al., 1996; Ding, 2010; Zheng et al., 2012; Symons et al., 2016). However, the neural process of sharing different emotional stories (happy/sad) on influencing interpersonal closeness remains unclear. Based on previous studies, we expected IBS as a neural indicator to uncover the neural mechanism of sharing emotional stories and interpersonal closeness during interpersonal interaction and expected to observe the strongest closeness-related IBS in the θ band mainly in the PFC.

The present study aims to provide behavioral and neural evidence for evaluating the effect of sharing emotional stories on influencing interpersonal closeness within the theoretical framework of EASI. Building on previous studies (Niedenthal and Setterlund, 1994; Ribeiro et al., 2019), the present study manipulates the valence of emotional stories (Happy vs Sad) to reveal the effects of sharing emotional stories on interpersonal closeness. The neural mechanism of sharing emotional stories influencing interpersonal closeness is investigated from the perspective of brain-to-brain coupling. On the behavioral level, we expected that sharing emotional stories would influence interpersonal closeness. Specifically, we hypothesized that sharing happy stories will increase interpersonal closeness more effectively than sharing sad ones. On the neural level, we expected that sharing happy stories will yield higher IBS than sharing sad stories in the θ band mainly in the PFC. Finally, we hypothesized that enhanced IBS will mediate the effect of sharing emotional stories on influencing interpersonal closeness.

Materials and Methods

Participants

A total of 32 participants (age: 21.3 ± 2.4 years, 16 females) were enrolled as listeners in the present study. Specifically, all the listeners were randomly assigned to listen to the happy stories from a competent speaker as speaker-listener dyads (15 listeners in the happy group) or the sad stories from the same competent speaker as speaker-listener dyads (17 listeners in the sad group).

One competent speaker (female, 19 years of age) was initially determined in a comprehension test. During this comprehension test, an independent sample of n = 10 participants (age: 22.1 ± 2.2 years, eight females) were asked to watch the emotional videos and narrate each video. The narrations were recorded and qualitatively assessed with the understanding of the stories and the accuracy of the emotion in the stories by three independent raters. Suggested items to consider were (1) understanding of the stories, (2) expression of the episodes, (3) the number of scenes remembered, (4) details provided, and (5) the accuracy of emotion in the stories. They reported a score for each participant across the three raters. The brain data for the selected speaker were manually inspected for quality, and the data from the other speakers are not further analyzed here (the rating sheet made is provided in Table 1).

Table 1 Speakers’ comprehension test score

Speaker number	Happy	Neutral	Sad	Average score	
101	12	13	10	11.67	
102	11	21	18	16.67	
103	21	18	25	21.33	
104	16	16	20	17.33	
105	19	10	25	18.00	
106	18	17	12	15.67	
107	25	23	26	24.67	
108	20	16	12	16.00	
109	18	19	15	17.33	
110	10	19	11	13.33	
The rater has included an overall comprehension level out of 10 and the total score for each subject was out of 30.

All participants provided written informed consent. The study had full ethical approval by the University Committee on Human Research Protection (UCHRP; HR 403–2019).

Stimuli

The stimuli consisted of a total of three videos (happy video, sad video, and neutral video). The present study used three audiovisual movies, excerpts from the episodes of happy video (Hail the Judge, ∼5 min in length), sad video (Root and Branches, ∼7 min in length), and neutral video (natural scenes, ∼6 min in length). These videos were chosen to have similar levels of production quality. Further, to assess the valence and the arousal of three videos, 10 raters (age: 20.5 ± 1.6 years, five females) were asked to identify the emotional valence of the videos (happy, neutral, or sad) and their emotional arousal on a 0–9 scale. Moreover, the 10 raters were required to rate the amount of social content and vividness (scale ranging from 1 to 9) on separate nine-point Likert scales. The raters reported a comparative evaluation of the arousal, the amount of social content, and vividness among the happy, neutral, and sad videos. Importantly, there were no significant differences in some ways (emotional arousal, F(2,29) = 1.53, p > 0.05, the amount of social content, F(2,29) = 1.32, p > 0.05, and vividness, F(2,29) = 0.65, p > 0.05) attributes between the happy, neutral, and sad videos. Therefore, we gave more evidence that the minimal baseline differences were demonstrated between the three stimuli.

Each listener received two-story stimuli, one neutral and one happy or sad. The recall duration of each emotional spoken recall recording was the same. The spoken recall recording of the happy story was 4 min, comprising 400 words; the spoken recall recording of the sad story was 4 min, comprising 420 words; and the spoken recall recording of the neutral story was 4 min, comprising 400 words. Audio recordings were obtained from each speaker who watched and recounted the two videos (one neutral and one happy/sad) with EEG recording. The listener listened to two corresponding audio recordings (Fig. 1B).

Figure 1. Experimental design. A, Speaker design. The speaker was invited to watch an emotional video and shared the stories in the video by narrating. B, Listener design. The listener was asked to listen to the story of the video through the speaker’s narration and allowed to recall the story which the speaker shared. C, The task in The Speaker Speaking and The Listener Listening. The specific procedure of sharing stories.

Procedures

The experimental procedures consisted of a resting-state phase and a task phase for both the speaker and the listener sessions. The speaker and the listener performed their tasks separately. In all experimental stages, the neural activity of the speaker and the listener was recorded with EEG. During the resting-state phase (60 s), participants were instructed to relax while keeping their eyes closed without falling asleep and to avoid excessive head motion. For each dyad, an initial resting-state session served as a baseline.

The task phase included two main sessions. In the first session (the speaker session), first, the speaker participants were asked to watch the happy, sad, and neutral videos (Fig. 1A, Speaker Watching); second, the speakers were asked to verbally narrate the stories in the videos and their narrations were recorded (Fig. 1A, Speaker Speaking). The speaker participants’ brain activity was recorded using EEG during speaking. In the second session (the listener session), 32 listeners were invited to listen to the emotional (happy/sad) and neutral stories recordings (The Listener Listening; see Fig. 1B), which from the competent speaker who was chosen in the comprehension test (Fig. 1C), and recall the corresponding recordings (The Listener Recalling; see Fig. 1B).

To control the confounding effects of between-group differences in mood, all listeners were required to report their emotional state immediately before listening. The happy group received happy stories from the competent speaker’s recording, whereas the sad group received sad stories from the competent speaker’s recording. Moreover, sharing neutral stories served as a baseline for sharing emotional performance and therefore it was reasoned that this condition should be performed before the happy or sad condition. To determine the effect of sharing emotional stories on interpersonal closeness, corresponding indices were assessed by self-report scales before recalling (Fig. 1C). The inclusion of others in the self (IOS) scale is a single item, individuals are asked to pick the pair of circles that best describes the interpersonal relationship (Aron et al., 1992). IOS scale has good reliability and validity to assess the interpersonal closeness (Aron et al., 1992). Several lines of research have proposed that IOS scale has good external validity to measure the interpersonal closeness (Simon et al., 2015; Bentley et al., 2017).

EEG data acquisition

The neural activity of each participant was simultaneously recorded with an EEG recording system using a 64-channel system (Compumedics NeuroScan) with a sampling rate of 1000 Hz. The electrode cap was positioned following the standard 10–10 international system. Two vertical and two horizontal electrooculogram (EOG) were placed to detect eye-movement artifacts. Impedances were maintained below 10 kΩ.

Data analysis

Behavioral data analysis

The quality of communication between speaker and listener was evaluated using The Listener Recalling stage (see Fig. 1B), in which listeners were asked to recall everything they remembered from the stories they heard. Quality of recall was assessed by three raters (following the procedure in Zadbood et al., 2017). The raters first established the rating system by which the quality is principally judged by the detail level of the scene and the accuracy of the narration. Based on this system, they then rated all three stories from the listener independently on the same scale (from 0 to 30). The final quality score of each story was determined by averaging the three raters’ scores on this story. Referred to the method of the similar experimental design (Takahashi et al., 2004), the behavioral index used the contrasts by subtracting the neutral condition from the happy condition and sad condition to assess the specific condition effect. The primary behavioral index “δ recall quality” was computed in the following way: δ recall quality = average recall quality in the emotional group (happy or sad) – the corresponding neutral recall quality. That is, the score of the neutral memory served as a baseline, such that the final scores of emotional memories were subtracted by the mean score of the neutral memories. To evaluate the difference of the behavioral index in sharing quality between happy and sad groups, we conducted an independent-sample t test. Cronbach’s αs of 0.91 for the happy video, 0.92 for the sad video, and 0.94 for the neutral video indicate high consistency between the raters.

EEG data analysis

The EEG raw data were preprocessed and analyzed using the EEGLAB toolbox (version 14.1.0; Delorme and Makeig, 2004) and in-house scripts in MATLAB (R2014a, The MathWorks). EEG data were filtered with a bandpass ranging from 1 to 45 Hz and a notch filter at 50 Hz. Data were re-referenced off-line to an average of the left and right mastoid and downsampled to 250 Hz. EEG data were divided into consecutive epochs of 1000 ms. Eye-movement artifacts were removed with an independent component analysis (ICA) method (Makeig et al., 1996). Signals containing EEG amplitudes greater than ±75 μV were excluded.

EEG data were grouped according to 6 regions for subsequent analysis: (1) frontal (F; AF4, F2, FP2, Fz, Afz, F1, FP1, AF3, F3, F5, F7, F8, F6, F4), (2) frontal-central (FC; Fcz, FC1, FC3, C1, C3, C4, C2, FC4, FC2), (3) parietal (P; CP1, P5, P3, P1, Pz, P2, Cp2, P4, P6), (4) left temporoparietal (left TP; FC5, FT7, C5, T7, TP7, CP5, P7), (5) right temporoparietal (right TP; T6-P8, CP6, TP8, C6, T4-T8, FT8, FC6), and (6) occipital (O; PO3, O1, Poz, Oz, PO4, O2). Phase locking value (PLV) is a valid index in EEG brain-to-brain studies (Delaherche et al., 2015; Hu et al., 2018). PLV is a practical method for the direct quantification of frequency-specific synchronization (i.e., transient phase-locking) between two neuroelectric signals and is able to examine the role of neural synchronies as a putative mechanism for long-range neural integration during cognitive tasks. However, compared with the more traditional method of spectral coherence, PLV separates the phase and amplitude components and can be directly interpreted in the framework of neural integration (Lachaux et al., 1999). Thus, the subsequent data were submitted to an IBS analysis known as PLV (Lachaux et al., 1999; Czeszumski et al., 2020). PLV was computed for each pair (i, k) of electrodes for each frequency band according to the following formula: PLVi,k=N−1|∑t=1Nexpj(φi(t)−φk(t))|,

where N represents the number of trials, φ is the phase, | | represents the complex modulus, and i and k indicate the electrode from participants 1 and 2 in a dyad, respectively, where one participant is the speaker and the other is a listener. The PLV ranges from 0 to 1, where PLV equals 1 if the two signals are perfectly synchronized and equals 0 if the two signals are unsynchronized. Phases were extracted using the Hilbert wavelet transform (Schölkopf et al., 2001), and four frequency bands, θ (4–7 Hz), α (8–12 Hz), β (13–30 Hz), and γ (31–48 Hz), were identified as typical frequency ranges in previous studies (Delaherche et al., 2015; Hu et al., 2018). θ Band was expected to observe strongest closeness-related IBS.

Referred to the method of the similar experimental design (Takahashi et al., 2004), the neural index used the contrasts by subtracting the neutral condition from the happy condition and sad condition to assess the specific condition effect. Thus, the present study calculated a δ PLV value in the θ band for each speaker-listener dyad using the equation “δ vPLV = average θ band PLV in the emotional group (happy or sad) – the corresponding neutral average θ band PLV.” We conducted independent-sample t tests (Happy vs Sad) on the IBS of speaker-listener dyads to explore the difference of the IBS in sharing stories between happy and sad groups. Differences were considered significant using an electrode-pairs-level threshold of p < 0.05 (Bonferroni-corrected). All PLV analyses focused on the sharing matchup (The Speaker Speaking-The Listener Listening), which represents sharing emotional stories between speaker and listener (Ahn et al., 2018; Chen et al., 2020).

Correlation between EEG data and behavioral data

To further explore whether the δ value of the IBS was strongly associated with sharing emotional stories, we examined the association between the behavioral (δ recall quality) and neural index (δ PLV in The Speaker Speaking-The Listener Listening).

Moreover, we conducted moderation regression, specifically simple slopes analysis (Aiken and West, 1991), to explore a moderation effect emotion -> PLV × interpersonal closeness. First, we split the file layered by the valence of the emotion (happy/sad). Then, linear regression was used to compare whether β-coefficient was significant under the happy group or the sad group.

Coupling directionality

To estimate the information flow between the speaker and the listener during the Speaker Speaking-Listener Listening matchup, a Granger causality (G-causality) analysis was conducted. According to Granger theory (Granger, 1969), for two given time series X and Y, if the variance of the prediction error for the time series Y at the current time is reduced by including historical information from the time series X in the vector autoregressive model, then the changes in X can be understood to “cause” the changes in Y. The MVGC MATLAB toolbox (Barnett and Seth, 2014) was used to estimate the full multivariate conditional G-causality. The task-related data for each participant were z-scored before G-causality analysis based on the mean and standard deviation of the resting-state signal. A one sample t test was used to compare the G-causality of speaker -> listener with 0.

Prediction of interpersonal closeness

We conducted a predictive analysis to test whether the IBS of the speaker-listener dyads could predict interpersonal closeness. We conducted an exploratory support vector regression (SVR) analysis, a regression method based on SVM, to explore whether the IBS could predict interpersonal closeness (using the LIBSVM toolbox; Chih-Chung and Chih-Jen, 2011). The response variable here was the listeners’ rating score of the interpersonal closeness. IBS from all electrode pairs was used as the features and a random 70% of the dataset was assigned as a training dataset and the remaining 30% of the data were used as a testing dataset. The model was trained using ε-SVR with the radial basis function (RBF). Based on Hou et al. (2020), the parameter ε was set to 0.01. The other two parameters (C, γ) were optimized using grid search via a fivefold cross-validation method in the training set (Yan et al., 2008). Finally, the Pearson correlation coefficient indicated the prediction accuracy between the actual and predicted values (Kosinski et al., 2013). Collectively, these analyses were conducted to explore whether the IBS of the speaker-listener dyads could predict interpersonal closeness and further to test the generalizability and replicability of our results. To verify the dependency structure of the data, the statistical significance of the correlation between the actual and predicted values was tested by 10,000 permutations.

Code availability

The sample data and code described in the article is available on-line at https://github.com/XieEnhui/EEG_PLV. The code is available as Extended Data 1. It can be performed using MATLAB (version 2014a) in a Windows 10 system. Full data and codes concerning this study can be available from the authors on request.

10.1523/ENEURO.0245-21.2021.ed1 Extended Data 1 The code used in the study. Download Extended Data 1, ZIP file.

Results

Behavioral results

Examination of the recall quality from the happy and sad group revealed significantly better quality in the happy group compared with the sad group (t(30) = 4.14, p < 0.001, Cohen’s d = 1.45, independent-sample t test; Fig. 2A).

Figure 2. Behavioral results in the happy and sad group. A, The recall quality (δ value) is shown for happy (Happy-Neutral) and sad (Sad-Neutral) emotions. B, The rating of interpersonal closeness is shown for happy (Happy-Neutral) and sad (Sad-Neutral) groups; **p < 0.01, ***p < 0.001.

In addition, we conducted an independent-sample t test on the self-reported interpersonal closeness scores as measured by the IOS. Specifically, the result showed that the happy group had significantly higher scores than the sad group (t(30) = 2.91, p < 0.01, Cohen’s d = 0.94; Fig. 2B).

IBS of speaker-listener dyads

Based on this result and previous research (Zheng et al., 2012; Symons et al., 2016), the θ band was used as the band of interest. In the θ band (4–7 Hz), we found that the IBS was significantly higher in the happy group than that in the sad group. The results indicated that the significantly increased IBS between dyads was specific to happy versus sad stories in frontal and temporal regions.

IBS during the sharing of emotional stories was measured using task-related PLV. First, we conducted one-sample t tests to examine significant differences for the PLVs between the happy/sad group and baseline. As for happy group, the result found significant PLV in the F site (t(14) = 12.84, p < 0.004, FDR corrected), FC (t(14) = 19.28, p = 0.004, FDR corrected), P (t(14) = 14.60, p < 0.001, FDR corrected), and the left TP site (TP, t(14) = 15.84, p < 0.001, FDR corrected) at the θ band. As for sad group, the result found significant PLV in the F site (t(16) = 10.14, p < 0.003, FDR corrected), FC (t(16) = 12.31, p < 0.003, FDR corrected), P (t(16) = 11.60, p < 0.003, FDR corrected), and the left TP site (TP; t(16) = 14.13, p < 0.001, FDR corrected) at the θ band. Then, we conducted independent-sample t tests to examine significant differences for the PLVs between happy and sad groups. We found that the happy group showed higher PLV than the sad group in the F site (t(30) = 3.22, p = 0.003, Cohen’s d = 1.14, FDR corrected; Fig. 3A) and the left TP site (t(30) = 3.87, p = 0.001, Cohen’s d = 1.36, FDR corrected; Fig. 3B) at the θ band. No significant results were found in others regions (see details in Table 2). Previous research has widely suggested that the frontal area is related to emotional communication and language-based interaction (Ahn et al., 2018). Moreover, the left TP is related to the high-level metallization during communications (Samson et al., 2004). Therefore, our further analysis would focus on the PLV in the left TP.

Table 2 PLV at different regions and in the θ band between happy and sad group (FDR corrected)

ROIs	PLV of the happy group (mean ± SD)	PLV of the sad group (mean ± SD)	t	d	df	p (corrected)	
F	0.32 ± 0.10	0.21 ± 0.09	3.22	1.14	30	0.009	
FC	0.47 ± 0.09	0.45 ± 0.15	0.47	0.17	30	0.960	
P	0.35 ± 0.09	0.32 ± 0.11	0.81	0.29	30	0.854	
Right TP	0.01 ± 0.05	0.00 ± 0.09	0.39	0.14	30	0.839	
Left TP	0.39 ± 0.10	0.27 ± 0.08	3.87	1.36	30	0.006	
O	0.02 ± 0.10	0.01 ± 0.05	0.94	0.11	30	0.752	
F, frontal site; FC, frontal-central site; P, parietal site; right TP, right temporoparietal site; left TP, left temporoparietal site; O, occipital site.

Figure 3. PLV of different groups [happy (Happy-Neutral) and sad (Sad-Neutral)] in sharing matchup (The Speaker Speaking-The Listener Listening). A, The PLV in the θ band at the F site. B, The PLV in the θ band at the F site. All after FDR correction; **p < 0.01.

Neural-behavioral correlation

We examined the association between the recall quality and PLV in the θ band. Results revealed that the recall quality showed a significant, positive association with the frontal PLV in the θ band (r(32) = 0.64, p < 0.001; Fig. 4A). We found no significant association with the left TP PLV in the θ band (r(32) = 0.22, p = 0.27; Fig. 4B). Self-reported interpersonal closeness showed a significant and positive association with the frontal PLV in the θ band (r(32) = 0.64, p < 0.001; Fig. 4C). We found no significant association with the left TP PLV in the θ band (r(32) = 0.34, p = 0.06; Fig. 4D).

Figure 4. Correlation between behavioral results and frontal IBS. A, Correlation between the recall quality (δ value) and the PLV in the θ band (δ value). The frontal PLV in the θ band positively correlated with the recall quality of dyads. B, We found the left TP PLV in the θ band was not significantly correlated with recall quality of dyads. C, Correlation between interpersonal closeness and the PLV in the θ band. The frontal PLV in the θ band positively correlated with interpersonal closeness of dyads. D, The left TP PLV in the θ band was nonsignificant correlated with interpersonal closeness of dyads; *p < 0.05, ***p < 0.001.

A moderation effect was estimated, results revealed that the β-coefficient was significant in the happy group (β = 0.68, SE = 3.74, t = 3.36, phappy < 0.01), but the β-coefficient was nonsignificant in the sad group (β = 0.45, SE = 3.77, t = 1.98, psad = 0.07). Thus, PLV × self-reported interpersonal closeness was moderated by the valence of emotion.

Coupling directionality

The G-causality analysis was used to measure the directional information flow (i.e., speaker -> listener). The one sample t test showed that there was a significant difference between 0 and the G-causality of speaker -> listener in The Speaker Speaking-The Listener Listening matchup (t(31) = 13.35, p < 0.001). To sum up, the result indicated that the information could only be transmitted from the speaker to the listener and the speaker is a significant predictor of future values of the listener.

Prediction of interpersonal closeness

Evaluating whether IBS as a neural indicator in the present study can be used to predict the interpersonal closeness between speaker-listener dyads, we used the SVR analysis. The results showed that the correlation coefficient between the actual and predicted interpersonal closeness of the testing dataset was ∼0.98, p < 0.001 (Fig. 5A). As expected, the real r values were significantly greater than the majority of the 10,000 permuted r values (Fig. 5B). Thus, the IBS in the frontal region as the specific neural-behavioral related index can predict the interpersonal closeness between speaker-listener dyads.

Figure 5. Frontal IBS in the θ band can effectively predict interpersonal closeness. A, Regression predicted by SVR between real value and predict value. B, The r value is calculated as a metric of prediction interpersonal closeness. The significance level (threshold at p < 0.05) is calculated by comparing the r value from the correct labels (dotted line) with 10,000 randomization samples with shuffled labels (blue bars); ***p < 0.001.

Discussion

In the present study, we explored (1) the association between sharing stories and interpersonal closeness and (2), its underlying neural correlates (3) and, the different roles of happy and sad emotions (i.e., Happy vs Sad) in sharing stories and building interpersonal closeness. As expected, the present study revealed that the behavioral index (the quality of recall after hearing an emotional story) was positively associated with interpersonal closeness in both happy and sad groups. Compared with the sad group, the happy group showed better recall quality and reported higher interpersonal closeness. Moreover, higher task-related IBS was found for the happy group. Within the happy group, sharing stories moderated the IBS and thus promoted interpersonal closeness. Finally, the F site IBS can be used to predict interpersonal closeness. The aforementioned results are discussed in detail as follows.

Our results showed a positive association between sharing emotional stories and interpersonal closeness at the behavioral level. Further, in the light of EASI, humans tend to synchronize with each other’s behavior (McCarthy and Duck, 1976; Dubois et al., 2016) and physiological states (Konvalinka et al., 2010) during emotional expression, our results suggested that sharing happy and sad stories can facilitate interpersonal closeness. Consistent with previous studies, we found that sharing happy stories was more likely to be transferred and received than sharing sad stories (Piotroski et al., 2015), we also found that the happy group showed a better recall quality compared with the sad group and led to higher interpersonal closeness. Moreover, initial behavioral studies have shown that participants preferred positive experiences on social media (Gable et al., 2004; Dorethy et al., 2014; Pounders et al., 2016), and thus sharing happy stories may represent a positive image and be good for building interpersonal relationships with strangers (Birnbaum et al., 2020).

Examining the cognitive and neural processes involved in social interaction behaviors hinges on investigating brain-to-brain synchronization during social interaction. “Two-person neuroscience” in sharing stories has higher ecological validity than single-brain recoding because “two-person neuroscience” is closer to the real-life interactions (García and Ibáñez, 2014; Joy et al., 2018; Redcay and Schilbach, 2019). Moreover, brain-to-brain studies have been widely accepted to unveil the interpersonal neural correlates in the context of social interactions (Lu et al., 2019; Chen et al., 2020). Based on the neuroimaging studies, sharing stories may be inherently reflected on the neural level (Tamir and Mitchell, 2012; Berger, 2014), and comprehension of narrations was driven by the neural similarity between the speaker and the listener (Silbert et al., 2014; Nguyen et al., 2019). A similar understanding of stories during interpersonal interaction led to enhanced IBS which represented the higher neural similarity of speaker-listener dyads (Hasson et al., 2012; Jiang et al., 2015; Nozawa et al., 2016; Chen et al., 2020). Therefore, the present study used brain-to-brain recording to evaluate the dynamic neural interaction between the speaker and the listener, revealing a brain-to-brain interaction pattern in the process of sharing stories (the sharing matchup). Referred to previous emotional communication brain-to-brain studies and audio brain-to-brain studies (Smirnov et al., 2019; Hou et al., 2020), the present study was not real-time interaction. Consistent with previous studies (Tamir et al., 2015; Kulahci and Quinn, 2019), our findings suggested that high IBS levels represented a high-level story comprehension of sharing stories and that was essential to increase interpersonal closeness between individuals.

We found significant IBS between speaker and listener in the frontal cortex during interaction in the θ band, consistent with previous studies which indicated that θ band was associated with emotion and memory encoding (Klimesch et al., 1996; Ding, 2010; Symons et al., 2016). Previous brain-to-brain studies have found strong interpersonal neural synchronization in the frontal cortex using the interactive paradigm involving verbal communication (Ahn et al., 2018; Bohan et al., 2018). Moreover, prior studies have uncovered that the frontal cortex critically contributes to recognizing emotions and encoding information (Abrams et al., 2011; De Borst et al., 2016). Therefore, our finding is consistent with previous findings, demonstrating that the frontal cortex was correlated with establishing a frame of emotional information.

Our results indicated the valence of emotion played a moderating role between IBS and interpersonal closeness. A recent study has shown that the neural synchronization between the speaker and the listener was associated with emotional features of stories and that the neural synchronization created a tacit understanding between the speaker and the listener, facilitating communication and improving interpersonal relationships (Smirnov et al., 2019). It is worth noting that only the happy emotion (relative to neutral) played a moderating role in enhancing IBS. Although the theory of EASI proposes that emotional expression will increase mutual understanding between individuals, compared with positive emotional expression, the effect of negative emotional expression is subtle (Dubois et al., 2016). Individuals prefer to share positive self-related details (i.e., happy stories about the videos you watched) in the presence of strangers and they also wish to transfer ideal images (Tamir and Mitchell, 2012; Baek et al., 2017). On the neural level, our result further evaluated the key role of different emotions (i.e., happy and sad) in the mediation effect of sharing stories on interpersonal closeness. To sum up, our results supported that sharing happy stories is more helpful in enhancing speaker-listener interaction.

Our GCA results further showed that there was a significant directionality of the enhanced IBS between the speaker and the listener, implying that the speaker was a significant predictor of future values of the listener above and beyond past values of the listener. Our findings were consistent with previous studies in unilateral communication or unilateral sharing, the speaker owns more information than the listener (Tworzydło, 2016). Based on the verbal cues of the speaker, the listener would frame the information, fill in the content, and adjust the content during the dynamic interactive process (Chen et al., 2017; Zadbood et al., 2017; Nguyen et al., 2019). In line with previous findings, listeners would perform as followers during sharing emotional stories and this performance is influenced by the speaker (Stephens et al., 2010; Jiang et al., 2015; Bohan et al., 2018). Therefore, the directionality of IBS in our study highlighted the point that sharing emotional stories were dominated by the speaker.

Our results revealed the predictive effect of frontal IBS for interpersonal closeness through SVR. These findings were in line with recent studies revealing that synchronized brain activity served as a reliable neural-classification feature (Cohen et al., 2018; Hou et al., 2020; Pan et al., 2020). Moreover, a growing number of studies have used the combination of machine learning and the IBS measurement in social neuroscience, so we considered more features, such as the time-frequency neural features from single-trial event-related spectral perturbation (ERSP) patterns (Makeig et al., 2004; Chung et al., 2015).

The present study had several limitations. First of all, the present study focused on specific happy and sad videos. Although the present study demonstrated that there is no difference between videos except for their valence, so the different effects on sharing stories are not driven by other variables related to the stories (e.g., recall duration, vividness, social context, etc.), the generalizability of the present results to more emotional videos needs to be examined in future studies. Second, spatial resolution is restricted in EEG, which is distributed on the skull and scalp (Hedrich et al., 2017), limiting measurements to specific areas during sharing emotional stories of speaker-listener dyads. Our findings indicated that frontal and temporal cortices were important in sharing emotional stories. Although the ventromedial PFC (VMPFC) and anterior cingulate cortex (ACC) play a crucial role in sharing emotional information activities (Killgore et al., 2013), EEG is unable to measure these two areas. Finally, the exploratory SVR predictive analysis is constrained by relative sample size (although our sample size is similar to those reported in previous classification and prediction analyses based on brain-to-brain coupling data; Jiang et al., 2012; Dai et al., 2018; Pan et al., 2020). Future replications are encouraged to consolidate the current findings by increasing both the sample size and the number of testing blocks.

In conclusion, the present study showed that sharing both happy and sad stories could increase interpersonal closeness between individuals. Moreover, findings at the neural level suggested that only sharing happy stories moderated the frontal IBS and thus promoted interpersonal closeness. These insights contribute to a deeper understanding of the neural correlates of sharing different emotional stories with interpersonal closeness. Future research may explore the neural mechanism of sharing stories by using IBS as an effective neural indicator.

Acknowledgements: We thank Yibin Shi for her valuable comments on earlier drafts.

Synthesis

Reviewing Editor: Macià Buades-Rotger, University of Luebeck

Decisions are customarily a result of the Reviewing Editor and the peer reviewers coming together and discussing their recommendations until a consensus is reached. When revisions are invited, a fact-based synthesis statement explaining their decision and outlining what is needed to prepare a revision will be listed below. The following reviewer(s) agreed to reveal their identity: Shannon Burns.

Dear authors,

Thanks for your work on interbrain synchrony and interpersonal closeness. While most of our concerns have been successfully addressed, I cannot recommend the manuscript for publication until some last substantial changes are incorporated. Two general themes must be addressed: a) the manuscript must be proofread by a proficient English speaker as the language is overall poor (see e.g., the minor concerns below); and b) the authors should include content from the rebuttal in the actual manuscript for the sake of transparency. In the following I list these issues in more detail:

Major concerns:

- Page 4: the introduction still fails to pinpoint the exact research question and how it fits in the literature. How, precisely, does this study inform the literature? What do we know not that we did not know earlier? Furthermore, the authors should briefly describe where in the brain and in which frequency bands they expected to observe strongest closeness-related IBS.

- Page 6: the authors write “we gave more evidence that the videos did not significantly differ in the emotional arousal, the amount of social content, and vividness, but only in the valence", yet they do not provide any actual results. Please provide the statistics reported in the rebuttal as well as the demographics of the 10 additional valence/arousal raters. Also, please rephrase the paragraph added on page 5 more clearly. The following part is especially confusing: “Results identified the valence of happy video is > 7 (happy), neutral video is 4 < rating < 6 (neutral), and sad video is < 3 (sad).” What does this mean? Is this really “identified by the results” or is it simply an arbitrary scoring?

- Also on page 6, the authors write “The emotional arousal of spoken recall recordings was evaluated by listeners (range from 1 to 7). The average emotional arousal of the happy story recording was 6, the average emotional arousal of the neutral story recording was 5, and the average emotional arousal of the sad story recording was 6.” Which listeners are these? Please specify.

- Page 10: the authors should include the justification for using PLV instead of spectral coherence in the manuscript. That is, the reply on page 8 of the rebuttal should be on the manuscript.

- Page 15: the authors should provide more information about the regression model reported.

- Please provide a data availability statement and upload all data and code in a public repository so results can be reproduced. If this is not possible, include it in the availability statement.

- What is the scale for the interpersonal closeness measure? What evidence is there of its validity? Please provide some more details.

Minor concerns:

This is by no means an exhaustive list but it should illustrate the need for proofreading:

- Lines 95-102: listeners do not “evoke", they “experience” emotions. The ones doing the evoking are the speakers.

- Line 319: “The result found that”. Results do not find anything, they are found by someone.

- Line 331: “A subsequent correlation analysis examined the association”. The correlation analysis did not examine anything, the authors did.

-
==== Refs
References

Abrams DA, Bhatara A, Ryali S, Balaban E, Levitin DJ, Menon V (2011) Decoding temporal structure in music and speech relies on shared brain resources but elicits different fine-scale spatial patterns. Cereb Cortex 21 :1507–1518. 21071617
Ahn S, Cho H, Kwon M, Kim K, Kwon H, Kim BS, Chang WS, Chang JW, Jun SC (2018) Interbrain phase synchronization during turn‐taking verbal interaction—a hyperscanning study using simultaneous EEG/MEG. Hum Brain Mapp 39 :171–188. 10.1002/hbm.23834 29024193
Aiken LS, West SG (1991) Multiple regression: testing and interpreting interactions. Newbury Park: Sage.
Anderson DJ, Adolphs R (2014) A framework for studying emotions across species. Cell 157 :187–200. 10.1016/j.cell.2014.03.003 24679535
Aron A, Aron EN, Smollan D (1992) Inclusion of other in the self scale and the structure of interpersonal closeness. J Pers Soc Psychol 63 :596–612. 10.1037/0022-3514.63.4.596
Baek EC, Scholz C, O’Donnell MB, Falk EB (2017) The value of sharing information: a neural account of information transmission. Psychol Sci 28 :851–880. 28504911
Barnett L, Seth AK (2014) The MVGC multivariate Granger causality toolbox: a new approach to Granger-causal inference. J Neurosci Methods 223 :50–68. 24200508
Baumeister RF, Bratslavsky E, Finkenauer C, Vohs KD (2001) Bad is stronger than good. Rev Gen Psychol 5 :323–370. 10.1037/1089-2680.5.4.323
Bentley SV, Greenaway KH, Haslam SA (2017) Cognition in context: social inclusion attenuates the psychological boundary between self and other. J Exp Soc Psychol 73 :42–49.
Berger J (2014) Word of mouth and interpersonal communication: a review and directions for future research. J Consumer Psychol 24 :586–607. 10.1016/j.jcps.2014.05.002
Birnbaum GE, Iluz M, Reis HT (2020) Making the right first impression: sexual priming encourages attitude change and self-presentation lies during encounters with potential partners. J Exp Soc Psychol 86 :103904. 10.1016/j.jesp.2019.103904
Bohan D, Chuansheng C, Yuhang L, Lifen Z, Hui Z, Xialu B, Wenda L, Yuxuan Z, Li L, Taomei G, Guosheng D, Chunming L (2018) Neural mechanisms for selectively tuning into the target speaker in a naturalistic noisy situation. Nat Commun 9 :1–12.29317637
Chen J, Leong YC, Honey CJ, Yong CH, Norman KA, Hasson U (2017) Shared memories reveal a shared structure in neural activity across individuals. Nat Neurosci 20 :115–125.27918531
Chen M, Zhang T, Zhang R, Wang N, Yin Q, Li Y, Liu J, Liu T, Li X (2020) Neural alignment during face-to-face spontaneous deception: does gender make a difference? Hum Brain Mapp 41 :4964–4981. 10.1002/hbm.25173 32808714
Chih-Chung C, Chih-Jen L (2011) LIBSVM: a library for support vector machines. ACM Trans Intell Syst Technol 2 :1–27. 10.1145/1961189.1961199
Chung D, Yun K, Jeong J (2015) Decoding covert motivations of free riding and cooperation from multi-feature pattern analysis of EEG signals. Soc Cogn Affect Neurosci 10 :1210–1218. 25688097
Cohen SS, Jens M, Gad T, Denise R, Stella FAL, Simon H, Parra LC (2018) Neural engagement with online educational videos predicts learning performance for individual students. Neurobiol Learn Mem 155 :60–64. 10.1016/j.nlm.2018.06.011 29953947
Czeszumski A, Eustergerling S, Lang A, Menrath D, Gerstenberger M, Schuberth S, Schreiber F, Rendon ZZ, König P (2020) Hyperscanning: a valid method to study neural inter-brain underpinnings of social interaction. Front Hum Neurosci 14 :39. 10.3389/fnhum.2020.00039 32180710
Dai B, Chen C, Long Y, Zheng L, Zhao H, Bai X, Liu W, Zhang Y, Liu L, Guo T, Ding G, Lu C (2018) Neural mechanisms for selectively tuning into the target speaker in a naturalistic noisy situation. Nat Commun 9 :2405.29921937
De Borst AW, Valente G, Jääskeläinen IP, Tikka P (2016) Brain-based decoding of mentally imagined film clips and sounds reveals experience-based information patterns in film professionals. Neuroimage 129 :428–438. 26826515
Delaherche E, Dumas G, Nadel J, Chetouani M (2015) Automatic measure of imitation during social interaction: a behavioral and hyperscanning-EEG benchmark. Pattern Recogn Lett 66 :118–126. 10.1016/j.patrec.2014.09.002
Delorme A, Makeig S (2004) EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis. J Neurosci Methods 134 :9–21. 10.1016/j.jneumeth.2003.10.009 15102499
Dikker S, Silbert LJ, Hasson U, Zevin JD (2014) On the same wavelength: predictable language enhances speaker-listener brain-to-brain synchrony in posterior superior temporal gyrus. J Neurosci 34 :6267–6272. 10.1523/JNEUROSCI.3796-13.2014 24790197
Ding M (2010) Theta Oscillations Mediate Interaction between Prefrontal Cortex and Medial Temporal Lobe in Human Memory. Cereb Cortex 20 :1604–1612.19861635
Dorethy MD, Fiebert MS, Warren CR (2014) Examining social networking site behaviors: photo sharing and impression management on Facebook. Int Rev Soc Sci Human 6 :111–116.
Dubois D, Bonezzi A, De Angelis M (2014) Positive with strangers, negative with friends: how interpersonal closeness affect word-of-mouth valence through self-construal. ACR N Am Adv 4 :41–46.
Dubois D, Bonezzi A, De Angelis M (2016) Sharing with friends versus strangers: how interpersonal closeness influences word-of-mouth valence. J Market Res 53 :712–727. 10.1509/jmr.13.0312
Fessler DMT, Pisor AC, Navarrete CD (2015) Negatively-biased credulity and the cultural evolution of beliefs. PLoS One 9 :e95167. 10.1371/journal.pone.0095167
Fredrickson BL (2001) The role of positive emotions in positive psychology. The broaden-and-build theory of positive emotions. Am Psychol 56 :218–226. 10.1037/0003-066X.56.3.218 11315248
Gable SL, Reis HT, Impett EA, Asher ER (2004) What do you do when things go right? The intrapersonal and interpersonal benefits of sharing positive events. J Pers Soc Psychol 87 :228–245. 10.1037/0022-3514.87.2.228 15301629
García AM, Ibáñez A (2014) Two-person neuroscience and naturalistic social communication: the role of language and linguistic variables in brain-coupling research. Front Psychiatry 5 :124.25249986
Gillath O, Bunge SA, Shaver PR, Wendelken C, Mikulincer M (2005) Attachment-style differences in the ability to suppress negative thoughts: exploring the neural correlates. Neuroimage 28 :835–847. 10.1016/j.neuroimage.2005.06.048 16087352
Granger CWJ (1969) Investigating causal relations by econometric models and cross-spectral methods. Econometrica 37 :424–438. 10.2307/1912791
Hanley N, Boyce C, Czajkowski M, Tucker S, Noussair C, Townsend M (2017) Sad or happy? the effects of emotions on stated preferences for environmental goods. Environ Resour Econ 68 :821–846.
Hari R, Henriksson L, Malinen S, Parkkonen L (2015) Centrality of social interaction in human brain function. Neuron 88 :181–193. 26447580
Hasson U, Ghazanfar AA, Galantucci B, Garrod S, Keysers C (2012) Brain-to-brain coupling: a mechanism for creating and sharing a social world. Trends Cogn Sci 16 :114–121. 22221820
Hedrich T, Pellegrino G, Kobayashi E, Lina JM, Grova C (2017) Comparison of the spatial resolution of source imaging techniques in high-density EEG and MEG. Neuroimage 157 :531–544. 28619655
Hirst W, Echterhoff G (2012) Remembering in conversations: the social sharing and reshaping of memories. Annu Rev Psychol 63 :55–79. 10.1146/annurev-psych-120710-100340 21961946
Hou Y, Song B, Hu Y, Pan Y, Hu Y (2020) The averaged inter-brain coherence between the audience and a violinist predicts the popularity of violin performance. Neuroimage 211 :116655. 10.1016/j.neuroimage.2020.116655 32084565
Hu Y, Pan Y, Shi X, Cai Q, Li X, Cheng X (2018) Inter-brain synchrony and cooperation context in interactive decision making. Biol Psychol 133 :54–62. 29292232
Isgett SF, Fredrickson BL (2015) Broaden-and-build theory of positive emotions. In: International encyclopedia of the social and behavioral sciences, Ed 2 (Wright JD, ed), pp 864–869. Oxford: Elsevier.
Jiang J, Dai B, Peng D, Zhu C, Liu L, Lu C (2012) Neural synchronization during face-to-face communication. J Neurosci 32 :16064–16069. 10.1523/JNEUROSCI.2926-12.2012 23136442
Jiang J, Chen C, Dai B, Shi G, Ding G, Liu L, Lu C (2015) Leader emergence through interpersonal neural synchronization. Proc Natl Acad Sci USA 112 :4274–4279. 10.1073/pnas.1422930112 25831535
Johnson BK, Ranzini G (2018) Click here to look clever: self-presentation via selective sharing of music and film on social media. Comput Hum Behav 82 :148–158. 10.1016/j.chb.2018.01.008
Joy H, Adam NJ, Zhang X, Swethasri D, Yumie O (2018) A cross-brain neural mechanism for human-to-human verbal communication. Soc Cogn Affect Neurosci 13 :907–320.30137601
Killgore WDS, Schwab ZJ, Tkachenko O, Webb CA, DelDonno SR, Kipman M, Rauch SL, Weber M (2013) Emotional intelligence correlates with functional responses to dynamic changes in facial trustworthiness. Soc Neurosci 8 :334–346. 10.1080/17470919.2013.807300 23802123
Klimesch W, Doppelmayr M, Russegger H, Pachinger T (1996) Theta band power in the human scalp EEG and the encoding of new information. Neuroreport 7 :1235–1240. 8817539
Konvalinka I, Vuust P, Roepstorff A, Frith CD (2010) Follow you, follow me: continuous mutual prediction and adaptation in joint tapping. Q J Exp Psychol 63 :2220–2230.
Kosinski M, Stillwell D, Graepel T (2013) Private traits and attributes are predictable from digital records of human behavior. Proc Natl Acad Sci USA 110 :5802–5805. 10.1073/pnas.1218772110 23479631
Kulahci IG, Quinn JL (2019) Dynamic relationships between information transmission and social connections. Trends Ecol Evol 34 :545–554. 10.1016/j.tree.2019.02.007 30902359
Lachaux JP, Rodriguez E, Martinerie J, Varela FJ (1999) Measuring phase synchrony in brain signals. Hum Brain Mapp 8 :194–208. 10.1002/(SICI)1097-0193(1999)8:4<194::AID-HBM4>3.0.CO;2-C 10619414
Lu K, Xue H, Nozawa T, Hao N (2019) Cooperation makes a group be more creative. Cereb Cortex 29 :3457–3470. 10.1093/cercor/bhy215 30192902
Makeig S, Bell AJ, Jung TP, Sejnowski TJ (1996) Independent component analysis of electroencephalographic data. Adv Neural Inf Process Syst 145–151.
Makeig S, Debener S, Onton J, Delorme A (2004) Mining event-related brain dynamics. Trends Cogn Sci 8 :204–210. 10.1016/j.tics.2004.03.008 15120678
Maswood R, Rajaram S (2019) Social transmission of false memory in small groups and large networks. Top Cogn Sci 11 :687–709. 10.1111/tops.12348 29785724
McCarthy B, Duck SW (1976) Friendship duration and responses to attitudinal agreement-disagreement. Br J Soc Clin Psychol 15 :377–386. 10.1111/j.2044-8260.1976.tb00049.x
Nguyen M, Vanderwal T, Hasson U (2019) Shared understanding of narratives is correlated with shared neural responses. Neuroimage 184 :161–170. 30217543
Niedenthal PM, Setterlund MB (1994) Emotion congruence in perception. Pers Soc Psychol Bull 20 :401–411. 10.1177/0146167294204007
Nozawa T, Sasaki Y, Sakaki K, Yokoyama R, Kawashima R (2016) Interpersonal frontopolar neural synchronization in group communication: an exploration toward fNIRS hyperscanning of natural interactions. Neuroimage 133 :484–497. 10.1016/j.neuroimage.2016.03.059 27039144
Nummenmaa L, Glerean E, Viinikainen M, Jääskeläinen IP, Hari R, Sams M (2012) Emotions promote social interaction by synchronizing brain activity across individuals. Proc Natl Acad Sci USA 109 :9599–9604. 22623534
Pan Y, Dikker S, Goldstein P, Zhu Y, Yang C, Hu Y (2020) Instructor-learner brain coupling discriminates between instructional approaches and predicts learning. Neuroimage 211 :116657. 32068165
Pickering MJ, Garrod S (2013) An integrated theory of language production and comprehension. Behav Brain Sci 36 :329–347. 10.1017/S0140525X12001495 23789620
Piotroski JD, Wong TJ, Zhang T (2015) Political incentives to suppress negative information: evidence from Chinese listed firms. J Account Res 53 :405–459. 10.1111/1475-679X.12071
Pounders K, Kowalczyk Christine M, Stowers K (2016) Insight into the motivation of selfie postings: impression management and self-esteem. EJM 50 :1879–1892. 10.1108/EJM-07-2015-0502
Ranzini G, Hoek E (2017) To you who (I think) are listening: imaginary audience and impression management on Facebook. Comput Hum Behav 75 :228–235. 10.1016/j.chb.2017.04.047
Redcay E, Schilbach L (2019) Using second-person neuroscience to elucidate the mechanisms of social interaction. Nat Rev Neurosci 20 :495–505. 31138910
Ribeiro FS, Santos FH, Albuquerque PB, Oliveira-Silva P (2019) Emotional induction through music: measuring cardiac and electrodermal responses of emotional states and their persistence. Front Psychol 10 :451. 30894829
Rozin P, Royzman EB (2001) Negativity bias, negativity dominance, and contagion. Pers Soc Psychol Rev 5 :296–320. 10.1207/S15327957PSPR0504_2
Samson D, Apperly IA, Chiavarino C, Humphreys GW (2004) Left temporoparietal junction is necessary for representing someone else’s belief. Nat Neurosci 7 :499–500. 10.1038/nn1223 15077111
Schölkopf B, Platt JC, Shawe-Taylor J, Smola AJ, Williamson RC (2001) Estimating the support of a high-dimensional distribution. Neural Comput 13 :1443–1471. 11440593
Shoham M, Moldovan S, Steinhart Y (2016) Positively useless: irrelevant negative information enhances positive impressions. J Consumer Psychol 147–159.
Silbert LJ, Honey CJ, Simony E, Poeppel D, Hasson U (2014) Coupled neural systems underlie the production and comprehension of naturalistic narrative speech. Proc Natl Acad Sci USA 111 :E4687–E4696. 10.1073/pnas.1323812111 25267658
Simon G, Chris S, Fabio T, Mariapaz E (2015) Measuring the closeness of relationships: a comprehensive evaluation of the ‘inclusion of the other in the self’ scale. PLoS One 10 :e0129478.26068873
Smirnov D, Saarimäki H, Glerean E, Hari R, Sams M, Nummenmaa L (2019) Emotions amplify speaker-listener neural alignment. Hum Brain Mapp 40 :4777–4788. 31400052
Stephens GJ, Silbert LJ, Hasson U (2010) Speaker–listener neural coupling underlies successful communication. Proc Natl Acad Sci USA 107 :14425–14430. 10.1073/pnas.1008662107 20660768
Symons AE, Wael ED, Michael S, Kotz SA (2016) The functional role of neural oscillations in non-verbal emotional communication. Front Hum Neurosci 10 :239–253. 27252638
Takahashi H, Koeda M, Oda K, Matsuda T, Matsushima E, Matsuura M, Asai K, Okubo Y (2004) An fMRI study of differential neural response to affective pictures in schizophrenia. Neuroimage 22 :1247–1254. 15219596
Tamir DI, Mitchell JP (2012) Disclosing information about the self is intrinsically rewarding. Proc Natl Acad Sci USA 109 :8038–8043. 10.1073/pnas.1202129109 22566617
Tamir DI, Zaki J, Mitchell JP (2015) Informing others is associated with behavioral and neural signatures of value. J Exp Psychol Gen 144 :1114–1123. 26595840
Tworzydło D (2016) Public relations — the tools for unilateral communication and dialogue on the internet. Market Sci Res Organiz 20 :79–90.
Vaish A, Grossmann T, Woodward A (2008) Not all emotions are created equal: the negativity bias in social-emotional development. Psychol Bull 134 :383–403. 10.1037/0033-2909.134.3.383 18444702
Van Kleef GA (2009) How emotions regulate social life. Curr Dir Psychol Sci 18 :184–188. 10.1111/j.1467-8721.2009.01633.x
Willems RM, Nastase SA, Milivojevic B (2020) Narratives for neuroscience. Trends Neurosci 43 :271–273. 32353331
Yan A, Wang Z, Cai Z (2008) Prediction of human intestinal absorption by GA feature selection and support vector machine regression. Int J Mol Sci 9 :1961–1976. 10.3390/ijms9101961 19325729
Zadbood A, Chen J, Leong YC, Norman KA, Hasson U (2017) How we transmit memories to other brains: constructing shared neural representations via communication. Cereb Cortex 27 :4988–5000. 28922834
Zheng C, Quan M, Zhang T (2012) Decreased connectivity by alteration of neural information flow in theta oscillation in depression-model rats. J Comput Neurosci 33 :547–558. 22648379

