
==== Front
Diagnostics (Basel)
Diagnostics (Basel)
diagnostics
Diagnostics
2075-4418
MDPI

10.3390/diagnostics11081373
diagnostics-11-01373
Review
Deep Learning Application for Analyzing of Constituents and Their Correlations in the Interpretations of Medical Images
https://orcid.org/0000-0003-4548-1787
Ursuleanu Tudor Florin 123
https://orcid.org/0000-0002-0645-4228
Luca Andreea Roxana 14*
Gheorghe Liliana 15*
Grigorovici Roxana 1
Iancu Stefan 1
Hlusneac Maria 1
Preda Cristina 16
Grigorovici Alexandru 12
Antani Sameer Academic Editor
1 Faculty of General Medicine, “Grigore T. Popa” University of Medicine and Pharmacy, 700115 Iasi, Romania; tudorursuleanu@yahoo.com (T.F.U.); roxanagrigorovici@yahoo.com (R.G.); istefan81@gmail.com (S.I.); mariahlusneac0@gmail.com (M.H.); cpreda1@yahoo.com (C.P.); alexandrugrigorovici@yahoo.com (A.G.)
2 Department of Surgery VI, “Sf. Spiridon” Hospital, 700111 Iasi, Romania
3 Department of Surgery I, Regional Institute of Oncology, 700483 Iasi, Romania
4 Department Obstetrics and Gynecology, Integrated Ambulatory of Hospital “Sf. Spiridon”, 700106 Iasi, Romania
5 Department of Radiology, “Sf. Spiridon” Hospital, 700111 Iasi, Romania
6 Department of Endocrinology, “Sf. Spiridon” Hospital, 700111 Iasi, Romania
* Correspondence: lucaandreearoxana@yahoo.com (A.R.L.); lilianagheorghe123@gmail.com (L.G.)
30 7 2021
8 2021
11 8 137307 7 2021
27 7 2021
© 2021 by the authors.
2021
https://creativecommons.org/licenses/by/4.0/ Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).
The need for time and attention, given by the doctor to the patient, due to the increased volume of medical data to be interpreted and filtered for diagnostic and therapeutic purposes has encouraged the development of the option to support, constructively and effectively, deep learning models. Deep learning (DL) has experienced an exponential development in recent years, with a major impact on interpretations of the medical image. This has influenced the development, diversification and increase of the quality of scientific data, the development of knowledge construction methods and the improvement of DL models used in medical applications. All research papers focus on description, highlighting, classification of one of the constituent elements of deep learning models (DL), used in the interpretation of medical images and do not provide a unified picture of the importance and impact of each constituent in the performance of DL models. The novelty in our paper consists primarily in the unitary approach, of the constituent elements of DL models, namely, data, tools used by DL architectures or specifically constructed DL architecture combinations and highlighting their “key” features, for completion of tasks in current applications in the interpretation of medical images. The use of “key” characteristics specific to each constituent of DL models and the correct determination of their correlations, may be the subject of future research, with the aim of increasing the performance of DL models in the interpretation of medical images.

medical image analysis
types of data and datasets
methods of incorporating knowledge
deep learning models
applications in medicine
==== Body
1. Introduction

The performance of deep learning architectures (DL) has a continuously improved by increasing the number and quality, respectively diversification data resources similar to medical data, developing specific methods of integrating data into DL models according to the objectives for which they were built and perfecting the construction of DL models used in medical applications.

Deep learning (DL) has experienced an exponential development of medicine, but applications in interpretations of medical imaging are in continuous development. DL has managed to achieve performance in diagnosis, classification, detection, segmentation, reconstruction of medical images [1] but also in achieving the correlation between image diagnosis and patient survival, predicting new directions of development [2].

The novelty in our paper consists in the unitary approach, of the constituent elements of DL models, namely, data, tools used by DL architectures or specifically constructed DL architecture combinations and highlighting their “key” features, for completion of tasks in current applications in the interpretation of medical images.

In this article we present in primarily, a unitary, complete, up-to-date analysis of scientific data, methods of knowledge incorporation, a classification and description of DL models according to the structure and objectives for which they were designed and presentation of medical applications according to these tasks. Secondly, it describes the specific correlations between data, data integration methods, deep learning models used in the interpretation of diagnostic medical images and their applications in medicine. Finally presents problems and future challenges.

The structure is composed of Section 2 describes types of images, medical data used by deep learning architectures, Section 3 describes DL models according to the objectives for which they were created, medical application, associating the types of data, Section 4 methods of incorporating images, information and medical data, in addition to the objective of DL. Section 5 contributions of the methods of incorporating images, information and medical data in medical applications, Section 6 research issues and future challenges.

Methodology:

We have identified and selected significant research papers published in 2009–2020, mainly from 2016 and 2020, with some papers from 2021. We focus on papers from the most reputable publishers, such as IEEE, Elsevier, Springer, MDPI, Nature, SPIE, PLOS, Wiley, RSNA, SCIRP. Some works have been selected from arXiv. I have reviewed more than 273 papers on different DL topics. There are 17 works from 2021, 56 works from 2020, 56 works from 2019, 38 works from 2018, 58 works from 2017, 25 works from 2016 and 10 work from 2015. This indicates that this review focus on the latest publications in the field of DL. The selected papers have been analyzed and reviewed for: descriptions types of images, medical data used by deep learning architectures (Section 2), descriptions DL models according to the objectives for which they were created, medical application, associating the types of data (Section 3), methods of incorporating images, information and medical data, in addition to the objective of DL (Section 4), contributions of the methods of incorporating images, information and medical data in medical applications (Section 5), research issues and future challenges (Section 6). Most keywords used for search criteria for this review work are (Deep Learning and Data types), (Deep Learning and Data Sets), (Deep Learning and Methods of Incorporation of Medical Knowledge and Data), (Deep Learning Models and Models), (Deep Learning and Architectures), ((Deep Learning) and (Medical Image Analysis) and (Detection/Classification/Segmentation/Localization/Reconstruction/Recovery)), (Deep Learning and Detection/Classification/Segmentation/Localization/Reconstruction), (Deep Learning and Images and Applications in Medicine), (Deep Learning and Interpretation Medical Images). Figure 1 shows our search structure of the survey paper.

2. Scientific Data and Dataset

2.1. Types of Images and Datasets in the Medical Domain

Medical data, types of images, images from time series, audio-video data represent unstructured information have a need for labeling because they make the process of data extraction difficult because they suffer high levels of noise and variability, and classical deep learning architectures achieve low performance in interpretations of medical images.

The interpretation of medical images in diagnostic radiology through the use of deep learning architectures has applications in cancer diagnosis, with satisfactory results in the diagnostic detection of breast cancer, lung cancer, glaucoma and skin cancer.

CT, PET-CT, MRI, X-rays, Ultrasound, Diagnostic Biopsy, Mammography and Spectrography are the most used imaging and exploratory investigations in the process of image interpretation, in the objective of extracting characteristics, reducing or enlarging the size, in the group, segmentation and classification of images and by using integration methods contribute to the performance of deep learning models, see Figure 2 [3].

Acronyms: MRI Magnetic Resonance Images, CT Computed Tomography, SLO Scanning Laser Ophthalmoscopy images, X-ray on weakly-supervised classification and localization of common thorax diseases.

Larger datasets, compared to the small size of many medical datasets, result in better deep learning models [4]. The large and well-annotated data sets are: ImageNet, COCO 2, (open source) medical data sets, see Figure 3.

Acronyms: MRI Magnetic Resonance Images, CT Computed Tomography, SLO Scanning Laser Ophthalmoscopy images, The Alzheimer’s disease neuroimaging initiative (ADNI), Automated cardiac diagnosis challenge (ACDC), The autism brain imaging data exchange (ABIDE), Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases (Chestx-ray14), The lung image database consortium (LIDC) and image database resource initiative (IDRI) (LIDC-IDRI), Algorithms for automatic detection of pulmonary nodules in computed tomography images (LUNA16), Large dataset for abnormality detection in musculoskeletal radiographs (MURA), Machine learning algorithms for brain tumor segmentation, progression assessment, and overall survival prediction in the brats challenge (BraTS2018), Locating blood vessels in retinal images (STARE), Digital database for screening mammography (DDSM), Automated mining of large-scale lesion annotations and universal lesion detection with deep learning (DeepLesion), Cardiac Magnetic Resonance Images (Cardiac MRI), International skin imaging collaboration (ISIC).

The knowledge of experienced clinical-imagists, follow certain characteristics in images, namely, contrast, color, appearance, topology, shape, edges, etc., contributes to the performance of medical image interpretation through the use of deep learning models, namely, anomaly detection by identifying the characteristics in the image; image segmentation; image reconstruction; combining two different images into one [5].

The knowledge of imaging doctors can be classified as follows:Low-level medical data Areas of attention of physicians in medical images [6],

Disease characteristics [7],

High-level medical data Labels–Diagnostic pattern [8],

Diagnostic training model that represents specific data identified by doctors [9].

The type and volume of medical data, the labels, the category of field knowledge and the methods of their integration into the DL architectures implicitly determine their performance in medical applications.

2.2. Types of Images and Medical Data Used for Diagnosis–Classification of Diseases in Medical Images

We will further expose, the types of medical images and data used in diagnosis-classification, segmentation, detection, reconstruction, recovery and, respectively, the generation of medical reports.

Natural images–from natural datasets, ImageNet 1 (over 14 million images tagged in 20 k categories) and COCO 2 (with over 200 images annotated in 80 categories).

Medical images-from medical datasets of the same diseases in similar and different ways or from different diseases [10].

High-level medical data (diagnostic pattern), low-level medical data (areas of images, disease characteristics).

Specific data identified by doctors (attention maps, hand-highlighted features) increase the diagnostic performance of deep learning networks (no comparative studies have been conducted).

2.3. Types of Images and Medical Data Used for Diagnosis Detection of Lesions and Abnormalities in Medical Images

Large natural images (ImageNet) are incorporated for the detection of characteristics in the medical images. Natural images are used in multiple applications.

Medical images are used in multiple applications. Multi-modal medical images, PET images are incorporated for the detection of lesions in CT scans.

High-level medical data (diagnostic pattern), low-level medical data (areas of images, disease characteristics).

Specific data identified by doctors (attention maps, hand-highlighted features) increase the diagnostic performance of deep learning networks (no comparative studies have been carried out).

2.4. Types of Images and Medical Data Used for Diagnosis–Segmentation into Medical Images

Natural Images, ImageNet, PASCAL VOC “static data” set, Sports-1M video datasets [11].

Medical images, (CT, MRI, Angio-CT, butt eye images, annotated retinal images) used in multiple applications.

External medical data and images of other diseases, dataset 3DSeg-8 [12].

High-level and low-level medical data, e.g., anatomical aspects of the image, shape, position, typology of lesions integrated into segmentation tasks, example of the ISBI 2017 dataset used in skin injury segmentation. Many applications use additional data with satisfactory results to improve CT image segmentation tasks in order to improve applications for MRI use [13].

Medical data from doctors, hand-made features, hand-highlighted features, are first processed from the reference images. These features are used in the BRATS2015 dataset in input-level merging image segmentation applications.

2.5. Medical Data and Manual Features Used for Image Reconstruction

X-ray projections in CT or spatial frequency information in MRI) [14,15], image reconstruction with optical diffuse tomography (DOT), reconstruction of magnetic resonance imaging by compressed detection (CS-MRI) [16], reconstruction of the image with diffuse optical tomography (DOT) of limited-angle breast cancer and limited sources in a strong scattering environment [17,18], recovery of brain MRI images, target contrast using GAN [19] are methods based on deep learning have been widely applied in this area.

2.6. Medical Data and Manual Features Used for Image Recovery

Knowledge from natural images, medical datasets for example, age and sex of patients, characteristics extracted from health areas.

2.7. Medical Data Used to Generate Medical Reports

Subtitling medical images, templates from radiologist reports, visual characteristics of medical images, generating reports using the IU-RR dataset.

3. DL Models Description and Classification According to the Tasks in Medical Images Analyses

We will describe the deep learning architectures in relation to the purpose and tasks for which they were designed, namely, diagnosis-classification, detection, segmentation, reconstruction.

3.1. DL Architectures Designed for Diagnosis–Classification in Medical Images

CNN, AlexNet, GoogLeNet, VGGNet, ResNet, DenseNet are used for diagnosis, classification, diseases.

GoogLeNet, VGGNet, ResNet are used for diagnosis, classification of superficial and deep corneal ulcers with accuracy of over 90%.

DenseNet [20] used for diagnostic classification of lung nodules on X-Rey with accuracy of over 90% Architectures designed to detect objects in natural images used to detect objects in medical images.

3.2. DL Architectures Designed for Diagnosis Detection of Lesions, Abnormalities in Medical Images

Two-stage models for injury and organ detection consist of a network of regional proposals (RPN) that involves the locations of candidate objects and a detection network that selects regional proposals are Faster R-CNN [21] and Mask R-CNN [18,22].

Models with a faster and simpler stage, which go over the stage of the proposal of the region and run the detection directly, taking into account the probability that the object will appear at every point in the image such as YOLO (You Only Look Once) [23], SSD (Single Shot MultiBox Detector) [9] and RetinaNet [24].

Combined FCN and GAN architectures, through PET images are generated first from CT scans then synthesized PET images are used in a false positive reduction layer [18,25].

3.3. DL Architectures Designed for Diagnosis Segmentation of Medical Images

Three categories can be exemplified: FCN-based models [26]; U-Net-based models [27]; GAN-based models [28].

3.3.1. FCN Achieves Goals of Segmenting the Medical Image with Good Results

Types of FCN: Cascading FCN [29,30], parallel FCN [31] and recurrent FCN [32] also achieve medical image segmentation goals with good results.

3.3.2. U-Net-Based Models

U-Net [27] and its derivatives segment the medical image with good results. U-Net is based on the FCN structure, consisting of a series of convolutional and devolutionary layers and with short connections between equal resolution layers. U-Net and its variants such as UNet ++ [33] and recurrent U-Net [34] perform well in many medical image segmentation tasks [18,35].

3.3.3. GAN-Based Models

GAN is a type of mixed architecture (supervised and unsupervised) called semi-supervised architecture, an architecture composed of two neural networks, a generator and a discriminator or classifier, which compete with each other in a contradictory formation process [28]. In models, the generator is used to predict the target mask based on encoder-decoder structures (such as FCN or U-Net) [18]. The discriminator serves as a form regulator that helps the generator achieve satisfactory segmentation results [16,33]. GAN has use in the generation of synthetic instances of different classes.

3.4. DL Architectures Designed for Diagnosis, Classification, Segmentation, Detection and Reconstruction of Medical Images

Deep auto-encoders (AUD) are included in the type of unsupervised learning that uses unlabeled input data, there is no a priori knowledge, and the results to be obtained from the processing of input data are unknown, and can learn to organize information without providing an error calculation to evaluate the possible solution [36,37]. The main feature of the autoencoder is represented by the input and output layers have the same size, and the output must reproduce the input, while the hidden layers are smaller in size because the input patterns are progressively encoded and decoded throughout the process, and has the ability to extract the fundamental characteristics of the input, being used to reduce the size of the data, but also to reduce noise in input data (such as images). They are often used for data reconstruction (image and signal), denoising or augmentation [37,38].

3.5. Medical Applications of DL Models According to the Scope for Which They Were Used, Classification, Segmentation, Detection and Reconstruction of Medical Images

DL architectures, e.g., CNN, U-Net, ResNet, VGGNet, AlexNet, RNN, GAN, DBN, YOLO and respectively, the types of combined architectures VGGNet + CNN, CNN + LSTM, GAN + U-Net, VGGNet + U-Net, RCC + U-Net which have as tasks classification, segmentation, detectionand reconstruction of medical images are the most used and have the best performance and contribution to medical applications (see Table 1) [39].

4. DL Model Description and Classification According to Medical Data Types Used, Objectives and Performances in Medical Applications

4.1. DL Models According to the Characteristics and Tasks for Which They Were Designed

CNN (convolutional neural network) are popular in areas where the shape of an object is an important feature, such as image analysis [5,39,94,95], particularly in the study of cancers and bodily injuries in the medical sector [96,97] and video analysis [39,98].

CNN contains convolutive layers, grouping layers, dropout layers, and an output layer, hierarchically positioned that each learn stun specific characteristics in the image [99].

CNN in image analysis has low performance when high-resolution datasets are considered [100] and when localization over large patches is required, especially in medical images [101,102].

We will synthesize in Figure 4 Classification of DL models according to the characteristics and tasks for which they were designed, classification of DL models according to the characteristics and tasks for which they were designed and describe them later [102].

DL architectures classification [103]:

Supervised DL models:Recurrent Neural Networks (RNN), Long short-term memory (LSTM), Gated Recurrent Unit (GRU),

Convolutional Neural Network (CNN)

Generative Adversarial Network (GAN).

Unsupervised deep learning models:Deep Network of Beliefs (DBN),

Deep Transfer Network (DTN),

Tensor Deep Stack Networks (TDSN),

Autoencoders (AE).

CNN’s performance is strongly influenced by the selection of hyper-parameters. Any small changes in hyper-parameters will affect CNN’s overall performance. Therefore, careful selection of parameters is an extremely significant problem that should be taken into account during the development of the optimisation scheme.

Impressive and robust hardware resources, such as GPs, are needed for an effective CNN workout. Moreover, they are also needed to explore the effectiveness of using CNN in intelligent and embedded systems.

Exploitation of depth and various structural adaptations is significantly improved in CNN’s learning capacity. Replacing the traditional layer configuration with blocks leads to significant progress in CNN’s performance, as shown in recent literature. Today, the development of new and efficient block architectures is the main trend in the new research models of CNN architectures. HRNet is just one example that shows that there are always ways to improve the architecture. Cloud-based platforms are expected to play a key role in the future development of DL computing applications [104].

Several deep learning, computer assisted diagnosis (CAD) systems for digital breast tomosynthesis (DBT) are currently available and many new systems will be developed. However, there are still many challenges to overcome. As Wang et al. [105] have recently demonstrated, published models for the full-field digital mammography (FFDM) classification fail when applied to different datasets, even when these data sets include purchases using similar equipment. For FFDMs, deep learning-based detection models have proven to be performing with almost human precision [106]. As more studies and data become available, there is no reason to believe that this should be different for DBT. However, the trained radiologist can adapt when analyzing different data sets, indicating that high-performance deep learning models still lack the “key” characteristics that differentiate the disease from normal [107].

Image analysis performance is enhanced by the use of the following architectures: AlexNet, VGGNet and ResNet, YOLO or U-net that we describe below:

AlexNet was proposed by Krizhevsky et al. [97] for the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012 [39].

AlexNet [103] consists of 8 layers, 5 layers of convolution and 3 dense, fully connected layers, overlapping overlay, abandonment, data augmentation, ReLU activations after each convolutive layer and fully connected, SGD with impulse [97]. AlexNet is used for image recognition in image analysis and is usually applied to issues involving semantic segmentation and high-resolution data classification tasks [39,70,73].

VGG (Visual Geometry Group): Consists of 13 convolution layers (in VGG16) & 16 convolution layers (in VGG19), 3 dense layers, pooling and three RELU units, very small responsive fields [108]. VGG is used for object recognition, classification of medical images [109,110] and image segmentation [18,36] VGG loses accuracy when the depth becomes too high.

ResNet (Residual Neural Network): Contains closed units or closed recurring units and has a strong similarity to recent successful elements applied in RNNs [103]. ResNet is characterized by: residual mapping, identity function, and a two-layer residual block, one layer learns from the residue, the other layer learns from the same function and has high level of performance in image classification [111] and audio analysis tasks [39,112].

GoogLeNet is built from 22 deep LAYERS CNN and 4 million parameters and contains several layer filters and stacked convolution layers [113]. It was used for batch normalization, image distortions, and RMSprop [103].

U-Net, developed by Ronneberger [101], addresses the problem of locating images of a standard CNN by extracting data features followed by reconstruction of the original dimension through an upsampling operation. U-Net is a type of Enconder-Decoder network in which the codification output belongs to the input space. U-Net is used in single-stage segmentation and classification [114], specifically in the location of cancerous lesions [38,115,116]. SegNet [39,117] is a U-Net variant that uses maximum grouping indices in the upsampling step that reduces the complexity of U-Net space [118].

RNNs were developed by Rumelhart et al. [119] using with efficiency the correlations existing between input data of a prediction problem, through which they process sequential data in relation to text analysis [84,119,120] in electronic medical records to predict diseases [121,122] and speech recognition [123]. RnN variants are: one-way, learning from the past and predicting the future and bidirectional that uses the future to restore the past. RNN has the following variants: LSTM, GRU, Recursive NNs and two-way RNNs (BiRNN). LSTMs were introduced by Hochreiter and Schmidhuber [39,103,124] and consist of: the gate of oblivion that alleviates the escape and explosion gradient, the entrance gate and the exit gate, the last two track the flow of data coming in and out of the cell. They were used in speech recognition [45], path prediction [46] and medical diagnosis [64], in which the authors proposed an LSTM network, called DeepCare, combining different types of data to identify clinical diseases.

GURs (recurrent unit gated) created by Kyunghyun Cho et al. in 2014 [48], solve the problem of increasing the time complexity of LSTM, when large amounts of data are used. The GRU consists of a reset gate in which it is decided how much information from the past is transmitted in the future, and an update gate that decides how much information from the past can be forgotten. GRU and LSTMs have similar applications especially in speech recognition [39,125].

The two-way recurring neural network and the Boltzmann BRNNs introduced by Schuster and Paliwal [44] are characterized by the fact that the hidden state is updated by using past information, as in a classic RNN, and by using information related to future moments. They were applied in handwriting and speech recognition, where they are used to detect missing parts of a sentence in a knowledge of the other words [41,126]. BM models are a family of RNNs that are easy to implement and that reproduce many probability distributions, BMs are used in image classification. BMs combined with other models are used to locate objects [39,40,127]. In the classification of images, BMs are used to identify the presence of a tumor [128]. BM models are slow and ineffective when the data size increases exponentially due to the complete connection between neurons [129]. A restricted BM was proposed in which relaxing the connections between neurons of the same or one-way connection between neurons would solve the problem of the classic BM model [5].

AEs, developed by Rumelhart et al. [119], consisting of encoder and decoder, with the aim of reducing the size of the data through significant representations and learning data characteristics for the reconstruction of outputs. They are used in applications in medical image analysis [72,130], natural language processing [67] and video analysis [68].

Additional variants of AE that can be found in the literature are variational AE (VAE). In a VAE, the encoder is represented by the probability density function of the input into the feature space and, after the encoding stage, a sampling of the new data using the PDF is added. Differently from the DAE and the SAE, a VAE is not a regularized AE, but is part of the generation class [39].

GAN it is used to generate synthetic training data from original data using latent distribution [131]. It consisted of two networks, a generator estimates false data from input data, and a discriminator, which differentiates fake data from real data and separates it in order to increase the quality of the data generated. GAN has two problems: the problem of the collapse of the mode, and the fact that, can become very unstable [103].

DBN: The DBN (Deep Network of Beliefs), created by Hinton [132], consists of two networks that build each other: of beliefs represented by an acyclic graph composed of layers of stochastic binary units with weighted and respectively weighted connections, restricted Boltzmann Machines which is a stochastic. DBNs are applied in image recognition and speech recognition, in classification to detect lesions in medical diagnosis and, in video recognition to identify the presence of persons [133], in speech recognition to understand missing words in a sentence [134] and in application on physiological signals to recognize human emotion [39,135,136].

DTN contains a characteristic extraction layer, which teaches a shared feature subspace in which marginal source distributions and target samples are drawn close and a layer of discrimination that match conditional distributions by classified transduction [103,106].

TDSN contains two parallel hidden representations that are combined using a bilinear mapping [137]. This arrangement provides better generalization compared to the architecture of a single module. The prejudices of the generalizers with regard to the learning set shall be inferred. It works effectively and better than an eco-validation strategy when used with multiple generalizers compared to individual generalizers.

DIM maximizes mutual information between an input and output of a highly flexible convolutive encoder [103,138] by forming another neural network that maximizes a lower limit on a divergence between the marginal product of encoder input and output. Estimates obtained by another network can be used to maximize the reciprocal information of the features in the input encoder. The memory requirement of the DIM is lower because it requires only encoder not decoder.

4.2. Combinations of Different DL Models Depending on the Type of Data Involved in the Problem to Be Solved

DL models can be combined in five different ways depending on the type of data involved in the problem to be solved. Of these, three types of HA (hybrid architectures), namely the integrated model, the built-in model and the whole model.

In the integrated model, the output of the convolution layer is transmitted directly as input to other architectures to the residual attention network, the recurrent convolutive neural network (RCNN) and the model of the recurrent residual convolutive neural network (IRRCNN) [103,139].

In the built-in model (the improved common hybrid CNN-BiLSTM), the size reduction model and the classification model perform together, the results of one represent the inputs for the other model. In the model (EJH-CNN-BiLTM), several basic models are combined.

In the transfer learning model (TL) is trained and uses the same type of problem. CNN models that use the TL model are VGG (e.g., VGG16 or VGG19), GoogLeNet (e.g., InceptionV3), Inception Network (Inception-v4), Repiuled Neural Network (e.g., ResNet50), AlexNet. Joint AB based DL combines max pooling, and careful sharing [103].

4.3. Combinations of Different DL Models to Benefit from the Characteristics of Each Model with Medical Applications Are: CNN + RNN, AE + CNN and GAN + CNN

CNN + RNN are used for the capabilities of the CNN feature extraction model and the RNNs [140]. Because the result of a CNN is a 3D value and an RNN works with 2D-data, a remodeling layer is, associated between CNN and RNN, to convert production of CNN into an array. CNN + RNN have been successfully applied in text analysis to identify missing words [141] and image analysis to increase the speed of magnetic resonance image storage [49,50]. CNN + RNN variants are obtained by replacing the Standard RNN component with an LSTM component [39,48,65].

AE + CNN architecture combines AE as a pre-training model when using data with high noise levels, and a CNN as a feature extractor model. AE + NVs have an application in image analysis to classify noisy medical images [76] and in the reconstruction of medical images [86,130].

GAN + CNN combines GAN as a pre-workout model to moderate the problem of over-mounting, and a CNN, used as a feature extractor. It has applications in image analysis [39,88,142].

The DL architectures applied especially in image analysis are CNN, AE and GAN. NVs preserve the spatial structure of the data, and are used as feature extractors (especially U-Net), AEs reduce the characteristics of complex images in the analysis process, and GANs are pre-training architectures that select input categories to control overfitting.

U-Net + Kite-Net + Attention U-Net + HarDNet-MSEG ahitecture, the DL model imagined by Luca, A.R. & all [143], combined model it designed takes into account the key features of the architectures involved: U-Net will be enhanced with a block context aggregation encoder and still retains the low-level image features that result from U-Net, but will generate slightly finer segmentation without adding costs due to context aggregation blocks; Kite-Net will contain a unit with attention gates and a Kite-Net decoder, in this way add a benefit of attention to the details of Kite-Net; a partial decoder like the one in the HarDNet-MSEG architecture used as the new U-Net decoder to reduce training time; U-Net Attention that suppresses irrelevant regions, key features, does not add significant computing costs, with a slightly smoother segmentation of image features. This combined DL model is not demonstrated in practice being a project [143,144].

4.4. Applications in Medicine and the Performance of DL Models Depending on the Therapeutic Areas in Which They Were Used

We further highlight the acquisitions in the study of deep learning and its applications in the analysis of the medical image [41]. You can easily identify references to image labeling and annotation, developing new deep learning models with increased performance, and new approaches to medical image processing:diagnosis of cancer by using CNN with different number of layers [145],

studying deep learning optimization methods and applying in the analysis of medical images [146],

development of techniques used for endoscopic navigation [147],

highlighting the importance of data labelling and annotation and knowledge of model performance [148,149],

perfecting the layer-wise architecture of convolution networks [103], lesson the cost and calculation time for processor training [150],

description of the use of AI and its applications in the analysis [103] of medical images [151],

diagnosis in degenerative disorder using deep learning techniques [152] and,

detection of cancer by processing medical images using the medium change filter technique [153],

classification of cancer using histopathological images and highlighting the rapidity of Theano, superior tensor flow [153],

development of two-channel computational algorithms using DL (segmentation, extraction of characteristics, selection of characteristics and classification and classification, extraction of high-level captures respectively) [154],

malaria detection using a deep neural network (MM-ResNet) [155].

We will exemplify in Table 2 [37] applications in medicine and the performance of DL models depending on types of medical images and the therapeutic areas in which they were used.

5. Description of Methods for Incorporating Data Types and the Applications in Which They Are Used

5.1. Schematically Present the Methods of Knowledge Incorporation and the Types of Data Used for DL Objectives in the Interpretation of Medical Images

We will exemplify the methods of incorporation of medical knowledge and data according to the purpose of DL models in medical applications, namely, diagnosis-classification, detection, segmentation, reconstruction and recovery of medical images, generation of medical reports, see Figure 5.

5.2. Classification in Medical Images

5.2.1. Methods of Incorporating Information

Transfer learning uses multimodal medical images and natural images.

Multitask learning uses medical data from other diseases.

Curriculum learning uses pattern training to incorporate medical data from doctors.

Network design uses diagnostic pattern from medical data from doctors.

Attention mechanism used areas doctors focus on from medical data from doctors.

Decision level fusion uses features doctors focus on from medical data from doctors.

Multi-task learning/network design used from medical data from doctors

5.2.2. Methods of Incorporation of Medical Data from Doctors for Diagnosis and Classification

Imaging doctors when interpreting medical images use patterns or procedures in diagnosing diseases. Incorporating these patterns and procedures from physicians into deep learning networks increases their performance.

Types of medical data used in deep learning models for diagnosing the disease: paternal training,

paternal diagnosis,

target regions,

hand crafted features (appearance, structures, shapes),

related diagnostic information

other types of diagnostic-related information

(1). The training model consists in the curricular learning through which tasks, images evolve from simple to complex in the training process. The curriculum involves a suite of training samples classified in ascending order of learning difficulty. The training model through curricular learning introduced into the deep learning network is developed by [162].

(2). General models of diagnosis of doctors, namely, the patterns and procedures used by imaging doctors when interpreting medical images. Radiologists diagnose imaging in three stages in the interpretation of X-ray images of the chest: overview, local lesion regions and subsequently combine general data [163].

(3). The use of the diagnostic pattern of radiologists for the diagnosis of thoracic disease) by extracting and combining global and local traits is carried out in [163]. Target regions or “attention maps”. Imaging doctors focus on specific areas in the diagnosis of diseases, “warning maps”, which indicates the target areas when interpreting images.

(4). Attention features (appearance, structure, shapes), “handcrafted characteristics”, as they are made by doctors, can be described characteristics, asymmetry, edge, color, margin, shape, micro-calcification and echo pattern, acoustic attenuation, side acoustic shade, and also benign-malignant risk of pulmonary nodules is classified by six characteristics of nodules: calcification, sphericality, edge, spiculation and texture and other.

(5). Related Diagnostic Information (Merger at Decision Level, Characteristics Level Fusion, Imput-Level Fusion, Features as Labels).

Merger at decision-level. The CNN classifier model automatically extracts and combines by merger at the decision-making level of handcrafted characteristics and extracted characteristics (contrast, texture, spiculation of the image) from CNN, by merger-level decision-level results from two classifiers [164].

Characteristic-level fusion. Feature-level fusion model combines two handcrafted features, parameter less threshold adhesion statistics and gray-level co-occurrence matrix, with the five groups of deep learning features extracted from five different deep models [18,37].

Input-level fusion. Input-level fusion is achieved by the fact that handmade features are used as patches that describe specific features and are used as input for CNN followed by combination in solving the problem. In some models these patches are used as input into DScGAN to increase diagnostic performance.

Using features as labels of CNN. Image classification labels and labels of handmade features are included into deep learning patterns through the multi-task learning arhitecture to increase their performance.

(6). Other Types of Diagnostic-Related Information (Additional Labels, Additional Clinical Diagnostic Reports).

These are represented by additional labels and clinical diagnostic reports. Type of additional category labels for medical images, normal, malignant or benign, condition of the lesions is incorporated into a multi-task learning structure can improve the performance of the diagnosis of major classification load [18].

Additional clinical diagnostic reports. The clinical report is a summary of descriptions of the doctor made during the imaging examination.

5.3. Detection in Medical Images

We can exemplify four categories: paternal training,

paternal diagnosis,

target regions,

hand crafted features (appearance, structures, shapes).

5.3.1. Paternal Training Is the Resolution of Tasks with Increasing Difficulties That Use Curricular Learning to Identify and Locate Lesions in Medical Images

CASED performs adaptive curriculum sampling to solve the problem of highly data imbalance and makes it possible for the model to distinguish nodules from immediate proximity and subsequently enlarges the hard-declassified global context, up to uniform categories in the empirical data pool. In this way, CASED is the most performant and is used in the detection of pulmonary nodules in thoracic CT [165].

LUNA16 also based on curricular learning is used in the detection of cardiac [166].

5.3.2. Paternal Diagnosis

Radiologists use patterns to locate lesions in medical images, namely:Combine images in different settings (brightness and contrast),

Uses bilateral, transverse, adjacent images,

Radiologists combine collected images in different settings (brightness and contrast) to locate lesions by visual interpretation of CT images. In the same way is built a model with multi-viewing features (FPN) brightness and contrast, combined later using an attention module that identifies the position with an increase in accuracy compared to NIH DeepLesion [167].

Bilateral information is compared by radiologists when interpreting images.

5.3.3. Handmade Characteristics

Handmade characteristics, e.g., locations, structures, shapes are represented by “Hand-Crafted Characteristics” for Identifying target objects, nodules or lesions in medical images.

5.3.4. Target Regions

The description of the target regions, e.g., information, radiological reports, additional labels is extracted from the radiological information and coupled with the curricular learning and the results are used by the network in the ascending order of the difficulties.

5.4. Segmentation of Lesions and Organs into Medical Images

5.4.1. Incorporation of Data from Natural Datasets or Medical Data Sets

Transfer learning uses data from natural images for performance in the segmentation of the medical image. The transfer of the acquired data of a CNN arhitectures originally trained for segmenting WM hyper-intensity on old low-resolution data to new data from the same scanner, but with good image resolution is studied by [168].

Multimodal learning in which MRI, CT, are used simultaneously by pre-trained architecture deep learning.

5.4.2. Incorporation of Knowledge from Doctors

Training pattern. For the segmentation of lesions into medical images deep learning models used curriculum learning.

Diagnostic pattern. Specific patterns used by doctors and embedded in the network.

Characteristics of the image (shape, location, topology).

Radiologists rely on certain characteristics of the image, shape, position, typological lesions, when interpreting medical images.

There are three types of incorporation of features injuries from medical imaging in deep learning architectures:incorporating the characteristics of the lesions in the post-processing stage,

incorporating the characteristics of the lesions as elements of regularization in the loss function,

learning the characteristics of the lesion through generational models.

5.4.3. Incorporation Handmade Characteristics from Doctors

For input fusion, handmade characteristics are transformed into input patches, subsequently, the original image patches and the tagged patches are inserted into a deep segmentation network [18].

5.5. Reconstruction of Medical Image

The objective is to reconstruct a diagnostic image from a series of measurements.

5.6. Recovery of Medical Image

Deep learning architecture use knowledge from natural images (pre-trained VGG model based on ImageNet) or medical data.

5.7. Generating Medical Reports

The deep learning models for image subtitles have been successfully applied for the automatic generation of medical reports [169,170]. Some templates in radiologist reports are used during the sentence generation process [80,167].

Model-agnostic method attempts to learn the short description of the text to explain this decision-making process [171] and transfer the visual characteristics of medical images to a graph of anomalies [18].

Module to incorporate the pre-built graph on multiple findings of the disease to help generate reports by using the IU-RR dataset [18,172].

5.8. Applications in Medicine, Methods of Incorporation of Types of Data, Datasets and Their Correlation

Imaging doctors combine data from different stages and experiences as opposed to DL models that incorporate the same types and modes of handcrafted features. Data quality and volume, annotations and labels, identification and automatic extraction of specific medical terms can help deep learning models perform in the tasks of image analysis [18] Simultaneous incorporation of different medical knowledge types features, labels, into DL architectures increases their performance (see Table 3) [102].

6. Conclusions

In this paper, as a research novelty, we approached in a unitary way, the constituent elements of DL models:Updated presentation of data types, DL models used in medical image analysis;

Correlation and contribution to the performance of DL models of the constituent elements: data type, incorporation methods and DL architectures;

Features and “key” tasks of DL models for the successful completion of tasks in applications in the interpretation of medical images.

The quality of the data and their volume, annotations and labels, the identification and automatic extraction of specific terms, from reports, guides, books in the medical field, can increase the diagnostic accuracy of doctors and help deep learning models perform in the tasks of image analysis. Doctors use a descriptive language, namely, contour, contrast, appearance, localization, topology, etc., or compare bilateral images. The incorporation of these representations, attributes from images, in DL architectures increase their performance.

Imaging doctors combine data from different stages and experiences as opposed to DL models that incorporate the same types and modes of handcrafted features. Data quality and volume, annotations and labels, identification and automatic extraction of specific medical terms can help deep learning models perform in the tasks of image analysis [18]. Incorporating these features, labels, into DL architectures increases their performance [102].

The diagnostic model, the training model simultaneously incorporates high-level and low-level knowledge (handcrafted features, anatomical priorities). High-level medical data is incorporated as input images, and low-level medical data is learned using specific network structures [18,237] and along with direct networking, information from low-level medical data can also be used to design training commands when combined with the easy-to-use training model [18,173]. Simultaneous incorporation of different medical knowledge types can increase performance of deep learning patterns in medical applications.

DL can be a support in solving complex problems, with uncertainties of options in investigations and therapy and could help medically and by filtering, providing data from literature. This aspect leads to a personalized medicine of the patient’s disease with diagnostic and therapeutic options based on scientific evidence. Another aspect is represented by the time encoded by the doctor in patient care, time gained by the constructive and effective support of DL in medical decision-making and synthesis activities.

The use of “key” characteristics specific to each constituent of DL models and the correct determination of their correlations, may be the subject of future research, with the aim of increasing the performance of DL models in the interpretation of medical images.

7. Research Problems

Problems in medical image analysis can be categorized as follows:identification and automatic extraction and standardization of specific medical terms,

representation of medical knowledge,

incorporation of medical knowledge.

Problems in medical image analysis are related to:

medical images provided as data for deep-street models require: quality, volume, specificity, labelling.

providing data from doctors, descriptive data, labels are ambiguous for the same medical and non-standard references.

laborious time in data processing are problems to solve in the future.

lack of clinical trials demonstrating the benefits of using DL medical applications in reducing morbidity and mortality and improving patient quality of life [39,102,264,265].

Full analysis of the mechanism of realization of medical applications, from data, databases, methods of incorporation of knowledge into DL models and improvement of DL models to their performance transposed into medical applications lead to the following problems to be solved: identification and automatic extraction of specific terms from medical documents, representation of medical knowledge, incorporation of medical knowledge.

Specific medical terms and descriptive attributes corresponding to diseases in medical images, by incorporating in DL models improve their performance and therefore involve solving problems related to the identification and automatic extraction of specific terms from medical documents, the presentation of medical knowledge, the incorporation of medical knowledge.

Problems in medical image analysis are related to quality, volume, specificity and data labelling in medical images used for a particular action by DL. Also, the provision of data from doctors, handmade, ambiguous expressions for the same medical references, uncertain limits of segments in images, low resolution of images, annotations, labels and laborious time in data processing are problems to solve in the future.

Another problem is the lack of clinical trials demonstrating the benefits of using DL’s medical applications in reducing morbidity and mortality and improving the quality of life of patients.

8. Future Challenges

These consist of domain adaptation, knowledge graph, generational models, and network architecture search techniques.

The adaptation of the domain consisted of transferring information from a source domain to a target domain, such as adversarial learning [266], makes it narrow the domain change between source and target domain in input space [267], feature space [268,269] and output space [270,271]. It can be used to transfer knowledge of one set of medical data to another [212] even when they have different modes of imaging or belong to different diseases [18,168,272]. UDA (unsupervised adaptation of the field) that uses medical labels has demonstrated performance in disease diagnosis and organ segmentation [18,81,188,255,273].

The knowledge graph, which has the specificity of incorporating multimodal medical data achieves performance in the analysis of the medical image and the creation of medical reports [167]. The graphs of medical data describing, the relationship between different types of knowledge, the relationship between different diseases, the relationship between medical datasets and a type of medical data, help the models of deep learning to perform [274].

Generative models, GAN and AE are used for segmentation tasks in particular. GAN uses MRI datasets for CT image segmentation [18,225,272]. GAN is a type of unsupervised deep learning network used in medical image analysis. AE are used in extracting characteristics, shape priorities in objects such as organs or lesions, completely unsupervised and are easily incorporated into the process of network training [18,85,237].

In traditional machine learning, the common learning process is separated and is carried out only on certain models, data sets and tasks. Therefore, knowledge is not retained or transferred to each other models. Instead, in deep learning, transfer learning can use knowledge such as the weights and characteristics of a pre-trained model to prepare a new model, as well as to address problems in the task that has a smaller amount of data. Transfer learning with deep learning patterns is faster, has improved accuracy and/or needs less training data [275].

A new approach to transfer learning, to address the problem of lack of data training in medical imaging tasks is represented by the technique of learning by transfer called dual transfer learning. Using the characteristics learned to improve the performance of other tasks by, such as classification in skin lesions, such us, benign and malignant or in the case of breast lesions to classify histological mammary images into four classes: invasive carcinoma, in situ carcinoma, benign tumor and normal tissue [276].

Using cloud computing provides a solution for managing the enormous amount of data. It also helps to increase efficiency and reduce costs. In addition, it offers the flexibility to train DL architectures [104].

With the recent development of computing tools, including a chip for neural networks and a mobile GPU, we will see more deep learning applications on mobile devices. It will be easier for users to use DL [104].

Network Architecture Search Technique (NAS) can automatically identify a certain network architecture in computer vision tasks [277] and promises that use and performance in the medical field [18,278].

With audacity, hope and confidence in the realization of our scientific desires we, authors, we launch an appeal to the international scientific forum with the aim that the following ideas will be put into practice at the initiative of some standard researchers in the field, “voices heard and heard” and who have the power to flesh them out: the establishment of a federation institution integrating scientific data and products specific to the field;

value categorization of industry-specific achievements;

launching challenges to be developed and completed;

facilitating the free circulation of discoveries, methods, formulas of scientific products within this federation institution;

establishing the board of the federation institution through the input and integration of “consequential brains” in the field;

the creation of a Hub of Ideas under coordination within the federation board with assignment of themes for development on specific teams;

joint effort for an idea launched within the federation institution;

an inventory of functional applications and methods, performing in the specific field;

the creation of a financing system to support and implement ideas specific to the field;

integration of researchers with notable ideas and performance limited funding or access to knowledge by belonging to geographical areas or institutions under represented internationally in the specific field.

Funding

Scientific research funded by the University of Medicine and Pharmacy “Gr. T. Popa” of Iasi, based on contract number 4714.

Conflicts of Interest

The authors declare no conflict of interest. The funders had no role in the design of the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript, or in the decision to publish the results.

Figure 1 Search Framework.

Figure 2 Imaging and exploratory investigations in the process of image interpretation.

Figure 3 Types of images datasets in the medical domain.

Figure 4 Classification of DL models according to the characteristics and tasks for which they were designed. Acronyms: Deep Network of Beliefs (DBN), Deep Network of Distribution and Target, Deep Info Max (DIM), AutoEnconder (AE), Generative Adversarial Network (GAN), Tensor Deep Stacking Network (TDSN), Convolutional Neural Network (CNN), Visual Geometry Group Network (VGG Net), Deep Layers Network (GoogLeNet), Fully Convolutional Network (U-Net), Residual Neural Network (ResNet), Deep Segmentation-Emendation Network (SegNet), Region Proposal Net (RPN,), You Only Look Once (YOLO), Deep Triage (DT), deep learning–based algorithmic framework (DeepSEA), Holistically-Nested Edge Detection (HED), Graph Convolutional Natural Net (GCNN),Recurent Neuronal Network (RNN), Deep Dynamic Neural Network (Deep Care),Gated Recurrent Network (GRN), Recurrsive RNN(RvNNs), Long Short-Term Memory (LSTM), Bidirectional RNN (BRNN), Restricted Boltzmann Machine (RBM).

Figure 5 Knowledge incorporation methods and data types used for DL objectives in the interpretation of medical images.

diagnostics-11-01373-t001_Table 1 Table 1 Medical applications of DL models according to the scope for which they were used [39].

Task	Contribution	Model	
Classification	Benefit from unlabelled data for lung tumour stratification	DBN [40]	
Introduction of a transfer learning approach in rectal cancer prediction	CNN [41]	
Identification of bladder tumour sub-types from histopathological images	ResNet [42]	
Improvement in breast tumour estimation by considering a large set of risk factors	CNN [43]	
Estimation of the cancer grade	CNN [44]	
Estimation of the cancer type	CNN [45,46], ResNet [47]	
Limitation of overfitting	GAN [48], ResNet [49]	
Analysis of the particular characteristics of the heart by using echocardiograms	ResNet [50]	
Improvement in bone image quality	U-Net [51]	
Analysis of the impact of gender on skeletal muscles	CNN [52]	
Automatic estimation of brain diseases risk	AlexNet [53], CNN [54]	
Improvement of accuracy and efficiency in COP diseases	ResNet [55], VGGNet + CNN [56], DBN [57]	
Analysis of interstitial lung diseases	CNN [58]	
Estimation of the normal levels of the pancreas	CNN [59,60]	
Improvement in image quality	CNN [61], CNN + LSTM [62]	
Improvement in accuracy in abdominal ultrasounds	CNN [63]	
Detection	Optimal localization of lung cancer sub-types	CNN [64]	
Low-cost object detection for malaria	YOLO [65]	
Improvement in image accuracy in neoplasia analysis	ResNet [66]	
Segmentation	Analysis of colour contrast and parameter variability issues in pancreatic tumour	U-Net [67]	
Impact of dimension variations on DL model performance in thyroid melanomas	U-Net [68]	
Limitation of the overfitting problem in bone cancer	CNN [69], GAN + U-Net [70]	
Improvement in image accuracy in lung and prostate cancer	U-Net [71,72], GAN [73]	
DL model for multi-step integration and registration error reduction in atrial fibrillation analysis	CNN + LSTM [74]	
Accuracy in the analysis of irregular pelvic hematoma images	U-Net [75]	
Improvement in aortic disease analysis with the introduction of new accuracy measures	U-Net [76]	
Introduction of the transfer learning approach in atrium study	U-Net [49]	
Analysis of the impact of the image quality in osteoarthritis	U-Net [77], RCNN [78]	
Introduction of transfer learning and attention mechanism in the study of the knees	VGGNet + U-Net [79]	
Improvement in image accuracy of the cartilage	U-Net [80], HNN [15], U-Net + GAN [81], RCNN	
Combination of the region-based approach with U-Net for bone diseases	RCC + U-Net [82]	
Limitation of overfitting in White Matter analysis	GAN [83]	
Colour quality improvement in orbital analysis	U-Net [84]	
Segmentation of lung lobe using different types of datasets	U-Net [85]	
Analysis of image effects in neoplasia and catheter detection	U-Net [66], RNN [86]	
Reconstruction	Improvement in the Signal-to-Noise Ratio Multi-data integration	CNN [87]	
Improvement in image quality at high levels in the study of coronary diseases	CNN [88]	
Application of CNNs to computed tomography for chest digital images	CNN [89]	
Introduction of a DAE as a priori model for noise density in magnetic resonance	DAE [90]	
Analysis of perturbation effects	CNN [91]	
Introduction of transfer learning into magnetic resonance	CNN [92]	
Limitation of overfitting	CNN + GAN [93]	
Acronyms: Deep Network of Beliefs (DBN), Generative Adversarial Network (GAN), Tensor Deep Stacking Network (TDSN), Convolutional Neural Network (CNN), Visual Geometry Group Network (VGG Net), Fully Convolutional Network (U-Net), Residual Neural Network (ResNet), You Only Look Once (YOLO), Recurrent Neuronal Network (RNN), Long Short-Term Memory (LSTM).

diagnostics-11-01373-t002_Table 2 Table 2 Objectives and performance of DL models in medical applications classified according to the therapeutic areas.

	Type of Data	Sample	Objective	Model Design	Results	Therapeutic Area	Paper	
Mammography	Mammography images	45,000 images	Diagnosis of breast cancer	CNN	AUC of 0.90	Oncology	[40]	
Mammography	667 benign, 333 malignant	Diagnosis of early breast cancer	Stacked AE	AUC of 0.89	Oncology	[127]	
Mammography images, biopsy result of the lesions	600 images biopsy	Differentiation benign lesions one malignant masses	CNN	AUC of 0.80	Oncology	[125]	
Mammography images	840 mammograms images	Evaluate the risk of coronary disease used breast arterial calcification classifier	CNN	Misclassified cases of 6%	Cardiovascular	[71]	
Digital mammograms	661 digital images	Estimation of breast percentage density	CNN	AUC of 0.981	Oncology	[80]	
Mammography images	Mammograms from 604 women	Segment areas in the breast	CNN	AUC of 0.66	Oncology	[49]	
Digital mammograms images	29,107 mammograms images	Probability of cancer	CNN	AUC of 0.90	Oncology	[87]	
Ultrasound	Image of the heart 2D	400 images with five different heart diseases and 80 normal echocardiogram images	Segment left ventricle images with greater precision	Deep belief networks	Hammoude distance of 0.80	Cardiovascular	[77]	
Ultrasound images	306 malignant tumor images, 136 benign tumors images	Detect and differentiate breast lesions with ultrasound	CNN, AlexNet, U-Net, LeNet	0.91 and 0.89 depending on the data	Oncology	[65]	
Transesophageal ultrasound volume and 3D geometry of the aortic valve images	3795 volumes from the aortic valves from 150 patients	Diagnose, stratification and treatment planning for patients with aortic valve pathologies	Marginal space deep learning	Position error of 1.66 mms and mean corner distance error of 3.29 mms	Cardiovascular	[45]	
Radiography	Radiography images	7821 subjects	CAD for diagnosis of knee osteoarthritis	Deep Siamese	AUC of 0.66	Traumatology	[141]	
Radiography images	420 radiography images	Osteoarthritis diagnosis	CNN	AUC of 0.92	Traumatology	[81]	
Radiographs	112,120 frontal view chest17,202 frontal view chest radiographs with abinary class label for normal vs abnormal	Abnormality detection in chest radiographs	CNN	AUROCs of 0.960 and 0.951. AUROCs of 0.900 and 0.893	Radiology	[78]	
Slide image	Pathology cancer images (hematoxylin and eosin)	5202 images tumorinfiltrating lymphocytes	Study of tumor tissue samples. Localize areas of necrosis and lymphocyte infiltration	Two CNNs	AUC of 0.95	Oncology	[118]	
Giemsa-stained thin blood smear slides cell images	27,558 cell images	Screening system for Malaria	CNN	AUC of 0.94	Infectious Disease	[121]	
Microscopy image patches	249 histologic images	Classification of breast cancer histology microscopy images	CNN and SVM	AUC of 0.77–0.83 for carcinoma/noncarcinoma classification	Oncology	[134]	
Microscopy histopathological images	7909 images of breast cancers	CAD for breast cancer histopathological diagnosis	CNN	AUC of 0.93	Oncology	[135]	
Microscope images	200 female subjects aged from 22 to 64	Cervix cancer screening	Multiscale CNN	Mean and standard deviation of 0.95 and 0.18	Oncology	[88]	
Whole-slide prostate histopathology images	2663 images of prostate histopathology images	Whole-slide histopathology images to outline the malignant regions	CNN	Dice coefficient of 0.72	Oncology	[78]	
Ocular fundus	2D images	243 retina images	Diagnose retinal lesions	CNN	Precision recall curve of 0.86 in microaneurysms and 0.64 in exudates	Ophthalmology	[120]	
2D images	85,000 images	Diabetic retinopathy detection and stage classification	Bayesian CNN	AUC value of 0.99	Ophthalmology	[42]	
Images	6679 images from Kaggle’s Diabetic Retinopathy Detection	Detect retinal hemorrhages	CNN	AUC of 0.894 and 0.972	Ophthalmology	[47]	
Images	168 images with glaucoma and 428 control	Detect and evaluate glaucoma	CNN: ResNet and U-Net	AUC of 0.91 and 0.84 respectively	Ophthalmology	[128]	
Images	90,000 images with their diagnoses	Predict the evolution of diabetic retinopathy	CNN	AUC of 0.95	Ophthalmology	[51]	
Images	7000 colour fundus images	Image quality of diabetic retinopathy	CNN	Accuracy of 100 %	Ophthalmology	[52]	
AREDS (age related eye disease study) image	130,000 fundus images	Diagnosis of Age-related Macular Degeneration	CNN	94.97 sensitivity and 98.32 % specificity	Ophthalmology	[156]	
Fundus images	219,302 from normal participants without hypertension, diabetes mellitus (DM), and any smoking history	Predict age and sex from retinal fundus images	CNN	AUC 0.96	Ophthalmology	[157]	
Dermoscopy	Images	350 images of melanomas and 374 benign nevi	Acral lentiginous melanoma diagnosis	CNN	AUC of over 0.80	Oncology	[129]	
Clinical images	49,567 images	Recognize nails nychomycosis lesions	Region-based-CNN	AUC of 0.98, AUC of 0.95, AUC of 0.93, AUC of 0.82	Dermatology	[130]	
Myocardial perfusion images	1638 patients	Obstructive coronary disease prediction	CNN	Sensitivity value of 0.82 and 0.69 for both use cases	Cardiovascular	[91]	
Arterial labeling	Arterial spin labeling (ASL) perfusion images	140 subjects	Monitoring cerebral arterial perfusion	CNN	AUC of 0.94	Cardiovascular	[44]	
Frames from endoscopy	Frames from endoscopy videos	205 normal and 360 abnormal images	Detection and localization of gastrointestinal anomalies	CNN	AUC of over 0.80	Gastroenterology	[72]	
Tracking dataset multi-instrument Endo-Visceral Surgery and multi-instrument in vivo	Single-instrument Retinal Microsurgery Instrument Tracking dataset, More-instrument Endo-Visceral surgery and multi-instrument in vivo images	940 frames of the training data (4479 frames) and 910 frames for the test data (4495 frames)	Detect the two-dimensional position of different medical instruments in endoscopy and microscopy surge	Convolutional Detection regression network	AUC of 0.94	Robotic Surgery	[76]	
CT/PET-CT/SPECT	Nuclear MRIs 3D	124 double echography	Diagnose possible soft tissue injuries	Deep Resolve, a 3D-CNN model	MSE of 0.008	Traumatology	[53]	
Retinal 3D images obtained by Optical Coherence Tomography	269 patients with AMD, 115 control patients	Retina age-related macular degeneration diagnostic	CNN	AUC of 0	Ophthalmology	[158]	
123I-fluoropropyl carbomethoxyiodophenyl nortropane single-photon emission computed tomography (FP-CIT SPECT) 2D images	431 patient cases	Automatic interpretation system in Parkinson’s disease	CNN	AUC of 0.96	Neurology-
Psychiatry	[84]	
Abdominal CT 3D images	231 abdominal CT	Classify tomography and evaluate the malignity degree in gastro-intestinal stromal tumors (GISTs)	Hybrid system between convolutional networks and radiomics	AUC of 0.882	Oncology	[83]	
CT image patches 2D	14,696 images	Diagnose interstitial lung disease	CNN	AUC of 0.85	Pneumology	[46]	
3D MRI and PET	93 Alzheimer Disease, 204 MCI Mild Cognitive Impairment converters and normal control subjects	Diagnose early Alzheimer disease stages	Multimodal DBM	AUC of 0.75–0.95	Neurology-
Psychiatry	[41]	
MRI	Diffusion-weighted imaging maps using MRI	222 patients. 187 treated with rtPA (recombinant tissue-type plasminogen activator)	Decide Acute Ischemic Stroke patients’ treatment through volume lesions prediction	CNN	AUC of 0.88	Neurology-
Psychiatry	[122]	
Magnetic resonance images	474 patients with schizophrenia and 607 healthy subjects	Schizophrenia detection	Deep discriminant autoencoder network	Accuracy over 0.8	Neurology-
Psychiatry	[124]	
Gadoxetic acid–enhanced 2D MRI	144,180 images from 634 patients	Staging liver fibrosis through MR	CNN	AUC values of 0.84, 0.84, and 0.85 for each stage	Gastroenterology	[64]	
Resting state functional magnetic resonance imaging (rs-fMRI), T1 structural cerebral images and phenotypic information	505 individuals with autism and 520 matched typical controls	Identify different autism spectrum disorders	Denoising AE	Accuracy of 0.70	Neurology-
Psychiatry	[126]	
3D MRI and PET	93 Alzheimer Disease, 204 MCI Mild Cognitive Impairment converters and normal control subjects	CAD for early Alzheimer disease stages	Multimodal DBM	Accuracy of 0.95, 0.85 and 0.75 for the three use cases	Neurology-
Psychiatry	[41]	
CT/PET-CT/SPECT	CT images, MRI images and PET images	6776 images	Classify medical diagnostic images according to the modality they were produced and classify illustrations according to their production attributes	CNN and a synergic signal system	AUC of 0.86	Various	[159]	
CT image 2D	63,890 patients with cancer and 171,345 healthy	Discriminate lung cancer lesions in adenocarcinoma, squamous and small cell carcinoma	CNN	Log-Loss error of 0.66 with a sensitivity of 0.87	Oncology	[160]	
CT 2D images	3059 images from several parts of human body	Speed up CT images collection and rebuild the data	Dense-Net and CNN	RMSE of 0.00048	Various	[142]	
CT images 3D	6960 lung nodule regions, 3480 of which were positive samples and rest were negative samples (nonnodule)	Diagnose lung cancer in low-dosage CT	Eye-tracking sparse attentional model and CNN	Accuracy of 0.97	Oncology	[90]	
CT images 2D and text (reports)	9000 training and 1000 testing images	Processing text from CT reports in order to classify their respective images	CNN	AUC of 0,58, 0,70–0.95	Various	[92]	
Computed tomography (CT)	Three datasets: 224,316, 112,120 and 15,783	Binary classification of posteroanterior chest x-ray	CNN	92% accuracy	Radiology	[161]	
MRI	Clinical characteristics and MRI 3D	135 patients with short-, medium- and long-term survival	Predict the survival of patients with amyotrophic lateral sclerosis	CNN	Accuracy of 0.84	Neurology-
Psychiatry	[67]	
Optical coherence tomography images	52,690 AMD patients’ images and 48,312 control	Differentiate Age-Related Macular Degeneration lesions in optical coherence tomography	Modification of VGG16 CNN	AUC of 0.92, AUC of 0.93 and AUC of 0.97 for the different use cases	Ophthalmology	[68]	
Lung computed axial tomography 2D images and breast ultrasound lesions	520 breast sonograms from
520 patients (275 benign and 245 malignant lesions) and lung CT image data from 1010 patients (700 malignant and 700 benign nodules)	CAD system to classify breast ultrasound lesions and lung CT nodules	Stacked denoising AE	AUC of 0.94	Oncology	[58]	
MRI 2D	444 images from 195 patients with prostate cancer	Prevent errors in diagnosing prostate	CNN	AUC of 0.94	Oncology	[88]	
MRI 2D	MICCAI 2009 left ventricle segmentation challenge database	Determinate limits between the endocardium and epicardium of the left ventricle	RNN with automatc segmentation techniqes	AUC of 1.0 in the best case	Cardiovascular	[132]	
MRI	CT images, MRI images and PET images	6776 images for training and 4166 for tests	Classify medical diagnostic images according to the modality they were produced and classify illustrations according to their production attributes	CNN and a synergic signal system	AUC of 0.86	Various	[159]	
Functional MRI	68 subjects perform 7 activities, and a state of rest	Analyze cerebral cognitive functions	3D CNN, resting state networks	AUC of 0.94	Neurology-
Psychiatry	[140]	
Liver MRIs	522 liver MRI cases with and without contrast for known or suspected liver cirrhosis or focal liver lesion	Screening system for undiagnosed hepatic magnetic resonance
images	CNN	Reduces negative predictive value and leads to greater precision	Gastroenterology	[50]	
MRI images	1064 brain images of autism patients and healthy controls. MRI data from 110 multiple sclerosis patient	Evaluate the quality of multicenter structural brain MRI
images	CNN	AUC 0.90 and 0.71	Radiology	[55]	
Acronyms: AMD age-related Macular Degeneration, CAD Computer Aided Diagnosis, CNN Convolutional Neural Network, MRI Magnetic Resonance Images, PET Photon EmissionTomography, CT Computed Tomography, OCT Optical Coherence Tomography, D dimensions, AUC Area Under the Curve, MSE Mean Squared Error, RMSE Root Mean Square Error, DSC Dice Similarity Coefficient.

diagnostics-11-01373-t003_Table 3 Table 3 Applications in medicine, methods of incorporation of types of data, datasets and their correlation.

Dataset Images	Methods of Incorporating Information	Application in Medicine	
Data doctors focus on			
Training pattern
high-level medical data, curriculum learning	Training modelImages with increasing complexity	diagnosis-classification of breast screening in DCE-RMN [61]

application - the attention-based curriculum, used in CNN, derived from radiology reports [173]

diagnosis of the proximal femoral fracture in X-ray images [18,174]

diagnosing of disease [18,175,176]

	
Diagnostic pattern, low-level medical data, areas of images, characteristics of diseases	General models of diagnosis of doctors	thoracic disease diagnosis [163]

final prediction of the disease [177]

diagnosis chest X-ray [178]

dermoscopic diagnosis of the lesion [63]

achieves mass identification accuracy in the MommiNet network [179]

diagnosis of skin lesions and classification of thoracic disease [180]

	
Area of interest, specific data identified by doctors, attention maps	“Attention maps” model of doctors	glaucoma diagnosis [167]

classification of images of tomography with images of optical coherence of the retina (OCT) [43]

diagnosis of diabetic retinopathy [93]

diagnosis of esophageal fistula to radiotherapy [18,69]

diagnosis of breast cancer [74]

Detection of changes in lesions in melanoma screening [18,75]

	
Dataset Images	Methods of Incorporating Information	Application in Medicine	
	Attention characteristics		
Hand-made characteristics	Characteristics level fusion + Incorporation level fusion	diagnosis-classification of lung nodules on CT images [18,56]

diagnosis of mammary ultrasound images, [181]

	
Incorporation level fusion	diagnosis of skin lesions [7]

diagnosis-classification of mammographic tumor [82]

diagnosis of lung nodules [18,54]

diagnosis of breast cancer [182]

diagnosis-classification of cardiac slices [89]

	
Characteristics level fusion	diagnosis of pulmonary nodules [183]

classification of breast cancer in histological images [146]

diagnosis of glaucoma disease [184]

diagnosis-classification of skin lesions [185]

diagnosis-classification of lung nodules [18,186]

diagnosis of brain tumors [187]

	
Incorporation patch characteristics		
MV-KBC	diagnosis-classification of lung nodules [56]

diagnosis-classification of thyroid disease [188]

	
DSc-GAN	diagnosis of thyroid nodules [18,189]

diagnosis of breast cancer in multi-sequence MRI [190]

	
As labels of CNNs	diagnosis-classification of lung nodules [191]

differentiation (benign-malignant) of lung nodules in CT scans [8]

diagnosis of glioma [192]

	
Other types of
information		
Additional category label, BI-RADS label (malignant/benign)	predicts the sensitive, specific, balanced result merged for images of glaucoma in [193]

	
Additional clinical diagnosis reports (abstract descriptions)	Tie-Net classifies common thoracic disease into chest X-rays [194]

facilitates the interpretation of pathological images of bladder cancer [133]

	
Dataset Images	Methods of Incorporating Information	Applications in Medicine	
Natural Datasets Images			
Natural images
ImageNet 1 and COCO 2	Transfer learning
- fixed feature extracts
- initialization	diagnosis-detection of lymph node [18,195]

diagnosis-detection of polyp and pulmonary embolism [196]

diagnosis-detection of breast tumors [65]

diagnosis-detection of colorectal polyps [197,198]

	
Medical Datasets Images		
Medical images
PET CT, Mammography, X-ray, Retina-Net	Learning with more tasks (multi-task)	PET image applications are incorporated for the diagnosis-detection of lesions in CT images of the liver [25]

diagnosis-detection of liver tumors [199]

diagnosis-detection of breast masses [200]

diagnosis-detection of pulmonary nodules in CT images [18,201]

diagnosis-detection of retinal diseases in the bottom of the retina [202]

diagnosis-detection colitis in CT images [203]

intervertebral disc detection in X-ray images [18,204]

diagnosis-detection architectural distortions in mammograms [18,205]

diagnosis-detection breast tumors in mammograms [18,206]

diagnosis-detection of pulmonary lung nodules in CT [207]

diagnosis-detection of various lesions (e.g., liver damage, lung lesion, bone lesion, abdominal lesion) in CT images [18,208]

diagnosis-detection of malignant lesions of the liver and reduce by 28% false positive average per case [18,25]

diagnosis-detection of breast masses from digital tomosynthesis [200]

	
Dataset Images	Methods of Incorporating Information	Applications in Medicine	
Data doctors focus on			
Training pattern
high-level medical data, curriculum learning	Training model
Images with increasing complexity	diagnosis-detection locates the lesion in chest [173]

diagnosis-detection of pulmonary nodules in thoracic CT [18,165]

diagnosis-detection of cardiac landmarks [166]

	
Diagnostic pattern, low-level medical data, areas of images, characteristics of diseases	General models of diagnosis of doctors	diagnosis-detection of lung lesions based on pneumonia COVID-19 [209]

diagnosis-detection of dense vessels and ischemia [210]

diagnosis-detection of thrombus [211]

diagnosis-detection of hemorrhagic lesions [212]

diagnosis-detection mammographic mass [213]

diagnosis-detection pulmonary nodule in CT images [207]

	
Area of interest, specific data by doctors, “attention maps”	Models explicitly incorporates “attention maps”	diagnosis-detection of thoracic disease [173]

diagnosis-detection of mammograms [18,214,215]

	
Hand-crafted features	Attention features	diagnosis-detection mammographic lesions [125]

diagnosis detection of pulmonary nodules [216]

diagnosis-detection of thyroid nodules, size and shape of the attribute of nodules [18,189]

diagnosis-detection of lymph nodes in oncological imaging [217]

diagnosis-detection of lung lesions [18,218]

	
Dataset Images	Methods of Incorporating Information	Applications in Medicine	
Natural Datasets Images			
Natural images
ImageNet 1, COCO 2, Data Set Sports-1M (1.1 million’s, video-sports) PASCALVOC dataset	Transfer learning
- fixed feature extracts
- initialization	diagnosis-evaluation of brain tumors [18,219]

diagnosis-evaluation of breast tumors [200]

diagnosis-evaluation of liver lesions [220]

diagnosis-evaluation of lesions of the pancreas [221]

diagnosis-segmentation of intimate-media limits [18,196]

diagnosis prenatal segmentation of the ultrasound image [222]

diagnosis-segmentation of the gland in histopathological images [18,117]

diagnosis-segmentation of the proximal femur in 3D MRI [18,223]

diagnosis-segmentation of multiple sclerosis [224]

	
Medical Datasets Images			
Medical images
MRI data, CT angiography, 3DSeg-8 dataset	Learning with more tasks (multi-task)	diagnosis-segmentation of the left/right lung [18,225]

diagnosis of cerebral disease into MRI [18,226,227]

diagnosis-segmentation of heart vessel without annotations used annotated retinal images [228]

diagnosis-segmentation of coronary artery, with high accuracy [18]

	
Data doctors focus on			
Deep learning:
FCN
U-Net
GAN		diagnosis segmentation of brain [18,227]

diagnosis-segmentation of skin lesions [229]

diagnosis-segmentation of vessels [230]

diagnosis-segmentation of anomalies in the retina fundus images [231]

	
Dataset Images	Methods of Incorporating Information	Applications in Medicine	
Data doctors focus on			
Training pattern
high-level medical data, curriculum learning	Training model
Images with increasing complexity
Self-paced learning (SPL)
SPL + active learning	diagnosis-segmentation of CT images with multiple organs [232]

diagnosis-segmentation in 3D pulmonary images [194]

diagnosis-segmentation of liver tumors [18,212]

diagnosis-segmentation of the left ventricle [18,233]

diagnosis-segmenting of the finger bones [18,234]

diagnosis-segmentation of vessels [18,235]

	
Diagnostic pattern
LIDC-IDRI dataset, BraTS 2018 dataset	General models of diagnosis of doctors	diagnosis on uncertain nodules [236]

diagnosis-segmentation of heart [237]

diagnosis-segmentation of the liver [238]

diagnosis-segmentation of raw tumors and clinical target volume [18,239]

	
Area of interest
BRATS2015 dataset,
(ImageNet, video datasets
Used for 3D image segmentation)	The fusion at the feature level + concatenate	diagnosis-segmentation in histopathological images [57]

diagnosis-segmentation of brain [18,240]

diagnosis-segmentation of tumor brain-MRI images [18,241]

diagnosis-segmentation of cellular nuclei [18,242]

	
Specific characteristics
(shape, location, topology)	In the post-processing stage	diagnosis-segmentation identifying locations of breast tumors [18,243]

diagnosis-segmentation anatomically [244]

diagnosis-representation of anatomical cardiac form [245]

	
In the loss function	diagnosis-segmentation of cardiac RM images [246]

diagnostic-segmentation skin lesions [247]

diagnosis-segmentation of kidney [18,248]

diagnosis-segmentation of liver [18,249]

diagnosis-segmentation of cardiac MRI [18,250]

diagnosis-segmentation of cardiac MRI [237]

diagnosis-segmentation of eye [85]

diagnosis-segmentation of brain MRI [18,251]

diagnosis-3D segmentation of the fine renal artery [18,252]

diagnosis-segmentation of cervical cytoplasm’s [18,253]

diagnosis-segmentation of scapula [18,254]

diagnosis-segmentation of liver [18,255]

diagnosis-segmentation of carotid [18,256]

diagnosis-segmentation of head and neck [18,257]

	
Dataset Images	Methods of Incorporating Information	Applications in Medicine	
Data doctors focus on			
Series of measurements	Reconstruction of medical image	magnetic resonance imaging reconstruction by compressed detection [258]

image reconstruction with diffuse optical tomography (DOT) of limited angle breast cancer and limited sources in a strong scattering environment [17]

	
Content-based image (CBIR)
External medical datasets and natural images	Recovery of medical image	brain tumor recovery [259]

X-ray image Recovery [18,260]

image recovery with chest X-ray [261]

image recovery with X-ray thoracic pathology [18,262]

features extracted from health areas can also be injected into the features extracted from the entire image for high recovery accuracy [18,263]

	
Templates from the report of radiologist
Visual characteristics of medical images, IU-RR datasets, text templates	Generating Medical Reports	some templates from the reports of radiologists are used during the process of generating sentences [80,167]

model-agnostic method to learn the short description of the text to explain this decision-making process [18,171]

transfers the visual characteristics of medical images to a graph of anomalies, then retrieves text templates based on anomalies and their attributes for thoracic X-ray images [18,167]

incorporate the pre-built graph (modeled with a CNN graph) on multiple findings of the disease to help generate reports by using the IU-RR dataset [18,172]

	

Publisher’s Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.
==== Refs
References

1. Haskins G. Kruger U. Yan P. Deep Learning in Medical Image Registration: A Survey J. Mach. Vis. Appl. 2020 31 1 8 10.1007/s00138-020-01060-x
2. Prevedello L.M. Halabi S.S. Shih G. Wu C.C. Kohli M.D. Chokshi F.H. Erickson B.J. Kalpathy-Cramer J. Andriole K.P. Flanders A.E. Challenges related to artificial intelligence research in medical imaging and the importance of image analysis competitions Radiol. Artif. Intell. 2019 1 e180031 10.1148/ryai.2019180031 33937783
3. Cheimariotis G.A. Riga M. Toutouzas K. Tousoulis D. Katsaggelos A. Maglaveras N. Deep Learning Method to Detect Plaques in IVOCT Images Future Trends in Biomedical and Health Informatics and Cybersecurity in Medical Devices: Proceedings of the International Conference on Biomedical and Health Informatics, ICBHI 2019 Lin K.-P. Magjarevic R. de Carvalho P. Springer Berlin/Heidelberg, Germany 2019 Volume 74 389 395 10.1007/978-3-030-30636-6_53
4. Halevy A. Norvig P. Pereira F. The Unreasonable Effectiveness of Data IEEE Intell. Syst. 2009 24 8 12 10.1109/MIS.2009.36
5. Lundervold A.S. Lundervold A. An overview of deep learning in medical imaging focusing on MRI Z. Med. Phys. 2019 29 102 127 10.1016/j.zemedi.2018.11.002 30553609
6. Tan J. Huo Y. Liang Z. Li L. Expert knowledge-infused deep learning for automatic lung nodule detection J. Xray Sci. Technol. 2019 27 17 35 10.3233/XST-180426 30452432
7. Majtner T. Yildirim S.Y. Hardeberg J. Combining deep learning and hand-crafted features for skin lesion classification Proceedings of the 2016 Sixth International Conference on Image Processing Theory, Tools and Applications (IPTA) Oulu, Finland 12–15 December 2016 1 6 10.1109/IPTA.2016.7821017
8. Hussein S. Cao K. Song Q. Bagci U. Risk Stratification of Lung Nodules Using 3D CNN-Based Multi-task Learning arXiv 2017 1704.08797
9. Liu W. Anguelov D. Erhan E. Szegedy C. Reed S. Fu C.-F. Berg A.C. SSD: Single Shot MultiBox Detector Proceedings of the Computer Vision—ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, 11–14 October 2016 ECCV 2016 Lecture Notes in Computer Science Leibe B. Matas J. Sebe N. Welling M. Springer Cham, Switzerland 2016 Volume 9905 10.1007/978-3-319-46448-0_2
10. Liao Q. Ding Y. Jiang Z.L. Wang X. Zhang C. Zhang Q. Multi-task deep convolutional neural network for cancer diagnosis Neurocomputing 2019 348 66 73 10.1016/j.neucom.2018.06.084
11. Tran D. Bourdev L. Fergus R. Torresani L. Paluri M. Learning Spatiotemporal Features with 3D Convolutional Networks Proceedings of the IEEE International Conference on Computer Vision (ICCV) Santiago, Chile 7–13 December 2015 4489 4497 10.1109/ICCV.2015.510
12. Chen S. Ma K. Zheng Y. Med3D: Transfer Learning for 3D Medical Image Analysis arXiv 2019 abs/1904.00625
13. Valindria V. Pawlowski N. Rajchl M. Lavdas I. Aboagye E.O. Rockall A.G. Rueckert D. Glocker B. Multi-modal Learning from Unpaired Images: Application to Multi-organ Segmentation in CT and MRI Proceedings of the 2018 IEEE Winter Conference on Applications of Computer Vision (WACV),Lake Tahoe, NV, USA, 12–15 March 2018 IEEE Piscataway, NY, USA 2018 547 556 10.1109/WACV.2018.00066
14. Qin C. Schlemper J. Caballero J. Price A.N. Hajnal J.V. Rueckert D. Convolutional Recurrent Neural Networks for Dynamic MR Image Reconstruction IEEE Trans. Med. Imaging 2019 38 280 290 10.1109/TMI.2018.2863670 30080145
15. Schlemper J. Caballero J. Hajnal J.V. Price A.N. Rueckert D. A Deep Cascade of Convolutional Neural Networks for Dynamic MR Image Reconstruction IEEE Trans. Med. Imaging 2018 37 491 503 10.1109/TMI.2017.2760978 29035212
16. Yang D. Xu D. Zhou S.K. Georgescu B. Chen M. Grbic S. Metaxas D. Comaniciu D. Automatic Liver Segmentation Using an Adversarial Image-to-Image Network Proceedings of the Medical Image Computing and Computer Assisted Intervention—MICCAI 2017, Quebec City, QC, Canada, 11–13 September 2017 MICCAI 2017 Lecture Notes in Computer Science Descoteaux M. Maier-Hein L. Franz A. Jannin P. Collins D. Duchesne S. Springer Cham, Switzerland 2017 Volume 10435 10.1007/978-3-319-66179-7_58
17. Ben Yedder H. Shokoufi M. Cardoen B. Golnaraghi F. Hamarneh G. Limited-Angle Diffuse Optical Tomography Image Reconstruction Using Deep Learning Medical Image Computing and Computer Assisted Intervention—MICCAI 2019; MICCAI 2019 Lecture Notes in Computer Science Shen D. Liu T. Peters T.M. Staib L.H. Essert C. Zhou S. Springer Cham, Switzerland 2019 Volume 11764 10.1007/978-3-030-32239-7_8
18. Xie X. Niu J. Liu X. Chen Z. Tang S. Yu S. A survey on incorporating domain knowledge into deep learning for medical image analysis Med. Image Anal. 2021 69 101985 10.1016/j.media.2021.101985 33588117
19. Dar S.U. Yurt M. Shahdloo M. Ildız M.E. Çukur T. Synergistic Reconstruction and Synthesis via Generative Adversarial Networks for Accelerated Multi-Contrast MRI arXiv 2018 1805.10704v1
20. Huang G. Liu Z. Weinberger K.Q. Densely Connected Convolutional Networks Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Honolulu, HI, USA 21–26 July 2017 2261 2269 10.1109/CVPR.2017.243
21. Ren S. He K. Girshick R. Sun J. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks arXiv 2019 1506.01497v3 10.1109/TPAMI.2016.2577031 27295650
22. He K. Gkioxari G. Dollár P. Girshick R.B. Mask R-CNN Proceedings of the 2017 IEEE International Conference on Computer Vision (ICCV) Venice, Italy 22–29 October 2017 2980 2988 10.1109/ICCV.2017.322
23. Redmon J. Divvala S. Girshick R. Farhadi A. You Only Look Once: Unified, Real-Time Object Detection Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Las Vegas, NV, USA 27–30 June 2016 779 788 10.1109/CVPR.2016.91
24. Lin T. Goyal P. Girshick R. He K. Dollár P. Focal Loss for Dense Object Detection Proceedings of the 2017 IEEE International Conference on Computer Vision (ICCV) Venice, Italy 22–29 October 2017 2999 3007 10.1109/ICCV.2017.324
25. Ben-Cohen A. Klang E. Raskin S.P. Soffer S. Ben-Haim S. Konen E. Amitai M.M. Greenspan H. Cross-modality synthesis from CT to PET using FCN and GAN networks for improved automated lesion detection Eng. Appl. Artif. Intell. 2019 186 194 10.1016/j.engappai.2018.11.013
26. Long J. Shelhamer E. Darrell T. Fully convolutional networks for semantic segmentation Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Boston, MA, USA 7–12 June 2015 3431 3440 10.1109/CVPR.2015.7298965
27. Ronneberger O. Fischer P. Brox T. U-Net: Convolutional Networks for Biomedical Image Segmentation Medical Image Computing and Computer-Assisted Intervention—MICCAI 2015 MICCAI 2015 Lecture Notes in Computer Science Navab N. Hornegger J. Wells W. Frangi A. Springer Cham, Switzerland 2015 Volume 9351 10.1007/978-3-319-24574-4_28
28. Goodfellow I.J. Pouget-Abadie J. Mirza M. Xu B. Warde-Farley D. Ozair S. Courville A. Bengio Y. Generative adversarial nets Proceedings of the 27th International Conference on Neural Information Processing Systems—Volume 2 (NIPS’14), Bangkok, Thailand, 18–22 November 2020 MIT Press Cambridge, MA, USA 2020 2672 2680
29. Gibson E. Giganti F. Hu Y. Bonmati E. Bandula S. Gurusamy K. Davidson B.R. Pereira S.P. Clarkson M.J. Barratt D.C. Towards Image-Guided Pancreas and Biliary Endoscopy: Automatic Multi-organ Segmentation on Abdominal CT with Dense Dilated Networks Proceedings of the Medical Image Computing and Computer Assisted Intervention—MICCAI 2017 MICCAI 2017 Lecture Notes in Computer Science Descoteaux M. Maier-Hein L. Franz A. Jannin P. Collins D. Duchesne S. Springer Cham, Switzerland 2017 Volume 10433 10.1007/978-3-319-66182-7_83
30. Christ P.F. Elshaer M.E.A. Ettlinger F. Tatavarty S. Bickel M. Bilic P. Rempfler M. Armbruster M. Hofmann F. D’Anastasi M. Automatic Liver and Lesion Segmentation in CT Using Cascaded Fully Convolutional Neural Networks and 3D Conditional Random Fields Proceedings of the Medical Image Computing and Computer-Assisted Intervention—MICCAI 2016 MICCAI 2016 Lecture Notes in Computer Science Ourselin S. Joskowicz L. Sabuncu M. Unal G. Wells W. Springer Cham, Switzerland 2016 Volume 9901 10.1007/978-3-319-46723-8_48
31. Kamnitsas K. Ledig C. Newcombe V.F. Simpson J.P. Kane A.D. Menon D.K. Rueckert D. Glocker B. Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation Med. Image Anal. 2017 36 61 78 10.1016/j.media.2016.10.004 27865153
32. Yang X. Yu L. Wu L. Wang Y. Ni D. Qin J. Heng P.-A. Fine-Grained Recurrent Neural Networks for Automatic Prostate Segmentation in Ultrasound Images Proceedings of the AAAI Conference on Artificial Intelligence San Francisco, CA, USA 4–9 February 2017 Volume 31 Available online: https://ojs.aaai.org/index.php/AAAI/article/view/10761 (accessed on 29 July 2021)
33. Zhou Z. Siddiquee M. Tajbakhsh N. Liang J. UNet++: A Nested U-Net Architecture for Medical Image Segmentation Proceedings of the Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support: 4th International Workshop, Québec City, QC, Canada, 14 September 2017 Springer Berlin/Heidelberg, Germany 2018 10.1007/978-3-030-00889-5_1
34. Alom M.Z. Hasan M. Yakopcic C. Taha T. Asari V. Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net) for Medical Image Segmentation arXiv 2018 abs/1802.06955
35. Gordienko Y. Gang P. Hui J. Zeng W. Kochura Y. Alienin O. Rokovyi O. Stirenko S. Deep Learning with Lung Segmentation and Bone Shadow Exclusion Techniques for Chest X-Ray Analysis of Lung Cancer Advances in Computer Science for Engineering and Education, Advances in Intelligent Systems and Computing Springer Cham, Germany 2018 Volume 754 638 647 10.1007/978-3-319-91008-6_63
36. Sathya R. Abraham A. Comparison of Supervised and Unsupervised Learning Algorithms for Pattern Classification IJARAI 2013 2 10.14569/IJARAI.2013.020206
37. Nogales A. García-Tejedor Á.J. Monge D. Vara J.S. Antón C. A survey of deep learning models in medical therapeutic areas Artif. Intell. Med. 2021 112 102020 10.1016/j.artmed.2021.102020 33581832
38. Pesteie M. Abolmaesumi P. Rohling R.N. Adaptive Augmentation of Medical Data Using Independently Conditional Variational Auto-Encoders IEEE Trans. Med. Imaging 2019 38 2807 2820 10.1109/TMI.2019.2914656 31059432
39. Piccialli F. di Somma V. Giampaolo F. Cuomo S. Fortino G. A survey on deep learning in medicine: Why, how and when? Inf. Fusion 2021 66 111 137 10.1016/j.inffus.2020.09.006
40. Kooi T. Litjens G. van Ginneken B. Gubern-Mérida A. Sánchez C.I. Mann R. den Heeten A. Karssemeijer N. Large scale deep learning for computer aided detection of mammographic lesions Med. Image Anal. 2017 35 303 312 10.1016/j.media.2016.07.007 27497072
41. Suk H.I. Lee S.W. Shen D. Hierarchical feature representation and multimodal fusion with deep learning for AD/MCI diagnosis Neuroimage 2014 101 569 582 10.1016/j.neuroimage.2014.06.077 25042445
42. Leibig C. Allken V. Ayhan M.S. Berens P. Wahl S. Leveraging uncertainty information from deep neural networks for disease detection Sci. Rep. 2017 7 17816 10.1038/s41598-017-17876-z 29259224
43. Fang L. Wang C. Li S. Rabbani H. Chen X. Liu Z. Attention to Lesion: Lesion-Aware Convolutional Neural Network for Retinal Optical Coherence Tomography Image Classification IEEE Trans. Med. Imaging 2019 38 1959 1970 10.1109/TMI.2019.2898414 30763240
44. Kim E.K. Kim H.E. Han K. Kang B.J. Sohn Y.M. Woo O.H. Lee C.W. Applying Data-driven Imaging Biomarker in Mammography for Breast Cancer Screening: Preliminary Study Sci. Rep. 2018 8 2762 10.1038/s41598-018-21215-1 29426948
45. Ghesu F.C. Georgescu B. Zheng Y. Hornegger J. Comaniciu D. Marginal Space Deep Learning: Efficient Architecture for Detection in Volumetric Image Data Proceedings of the Medical Image Computing and Computer-Assisted Intervention—MICCAI 2015 Lecture Notes in Computer Science Springer Cham, Switzerland 2015 Volume 9349 10.1007/978-3-319-24553-9_87
46. Anthimopoulos M. Christodoulidis S. Ebner L. Christe A. Mougiakakou S. Lung Pattern Classification for Interstitial Lung Diseases Using a Deep Convolutional Neural Network IEEE Trans. Med. Imaging 2016 35 1207 1216 10.1109/TMI.2016.2535865 26955021
47. Van Grinsven M.J. van Ginneken B. Hoyng C.B. Theelen T. Sanchez C.I. Fast Convolutional Neural Network Training Using Selective Data Sampling: Application to Hemorrhage Detection in Color Fundus Images IEEE Trans. Med. Imaging 2016 35 1273 1284 10.1109/TMI.2016.2526689 26886969
48. Cho K. Van Merriënboer B. Bahdanau D. Bengio Y. On the properties of neural machine translation: Encoder-decoder approaches arXiv 2014 preprint 1409.1259
49. Lee J. Nishikawa R.M. Automated mammographic breast density estimation using a fully convolutional network Med. Phys. 2018 45 1178 1190 10.1002/mp.12763 29363774
50. Esses S.J. Lu X. Zhao T. Shanbhogue K. Dane B. Bruno M. Chandarana H. Automated image quality evaluation of T2-weighted liver MRI utilizing deep learning architecture J. Magn. Reson. Imaging 2018 47 723 728 10.1002/jmri.25779 28577329
51. Quellec G. Charrière K. Boudi Y. Cochener B. Lamard M. Deep image mining for diabetic retinopathy screening Med. Image Anal. 2017 39 178 193 10.1016/j.media.2017.04.012 28511066
52. Saha S.K. Fernando B. Cuadros J. Xiao D. Kanagasingam Y. Automated Quality Assessment of Colour Fundus Images for Diabetic Retinopathy Screening in Telemedicine J. Digit. Imaging 2018 31 869 878 10.1007/s10278-018-0084-9 29704086
53. Chaudhari A.S. Fang Z. Kogan F. Wood J. Stevens K.J. Gibbons E.K. Lee J.H. Gold G.E. Hargreaves B.A. Super-resolution musculoskeletal MRI using deep learning Magn. Reson. Med. 2018 80 2139 2154 10.1002/mrm.27178 29582464
54. Xie Y. Zhang J. Xia Y. Fulham M. Zhang Y. Fusing texture, shape and deep model-learned information at decision level for automated classification of lung nodules on chest, C.T Inf. Fusion 2018 42 102 110 10.1016/j.inffus.2017.10.005
55. Sujit S.J. Coronado I. Kamali A. Narayana P.A. Gabr R.E. Automated image quality evaluation of structural brain MRI using an ensemble of deep learning networks J. Magn. Reson. Imaging 2019 50 1260 1267 10.1002/jmri.26693 30811739
56. Xie Y. Xia Y. Zhang J. Song Y. Feng D. Fulham M. Cai W. Knowledge-based Collaborative Deep Learning for Benign-Malignant Lung Nodule Classification on Chest, C.T IEEE Trans. Med. Imaging 2019 38 991 1004 10.1109/TMI.2018.2876510 30334786
57. Rezaei S. Emami A. Zarrabi H. Rafiei S. Najarian K. Karimi N. Samavi S. Soroushmehr S.R. Gland Segmentation in Histopathology Images Using Deep Networks and Handcrafted Features Proceedings of the 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) Berlin, Germany 23–27 July 2019 1031 1034 10.1109/EMBC.2019.8856776
58. Cheng J.Z. Ni D. Chou Y.H. Qin J. Tiu C.M. Chang Y.C. Huang C.S. Shen D. Chen C.M. Computer-Aided Diagnosis with Deep Learning Architecture: Applications to Breast Lesions in US Images and Pulmonary Nodules in CT Scans Sci. Rep. 2016 6 24454 10.1038/srep24454 27079888
59. Azizi S. Mousavi P. Yan P. Tahmasebi A. Kwak J.T. Xu S. Turkbey B. Choyke P. Pinto P. Wood B. Transfer learning from RF to B-mode temporal enhanced ultrasound features for prostate cancer detection Int. J. Comput. Assist Radiol. Surg. 2017 12 1111 1121 10.1007/s11548-017-1573-x 28349507
60. Han X. Wang J. Zhou W. Chang C. Ying S. Shi J. Deep Doubly Supervised Transfer Network for Diagnosis of Breast Cancer with Imbalanced Ultrasound Imaging Modalities Proceedings of the Medical Image Computing and Computer Assisted Intervention—MICCAI 2020 MICCAI 2020 Lecture Notes in Computer Science Springer Cham, Switzerland 2020 Volume 12266 10.1007/978-3-030-59725-2_14
61. Maicas G. Bradley A.P. Nascimento J.C. Reid I. Carneiro G. Training Medical Image Analysis Systems like Radiologists Proceedings of the Medical Image Computing and Computer Assisted Intervention—MICCAI 2018 MICCAI 2018 Lecture Notes in Computer Science Springer Cham, Switzerland 2018 Volume 11070 10.1007/978-3-030-00928-1_62
62. Zhao R. Chen X. Chen Z. Li S. EGDCL: An Adaptive Curriculum Learning Framework for Unbiased Glaucoma Diagnosis Proceedings of the Computer Vision—ECCV 2020; ECCV 2020 Lecture Notes in Computer Science Vedaldi A. Bischof H. Brox T. Frahm J.M. Springer Cham, Switzerland 2020 Volume 12366 10.1007/978-3-030-58589-1_12
63. Gonzalez-Diaz I. DermaKNet: Incorporating the Knowledge of Dermatologists to Convolutional Neural Networks for Skin Lesion Diagnosis IEEE J. Biomed. Health Inform. 2019 23 547 559 10.1109/JBHI.2018.2806962 29994788
64. Yasaka K. Akai H. Kunimatsu A. Abe O. Kiryu S. Liver Fibrosis: Deep Convolutional Neural Network for Staging by Using Gadoxetic Acid-enhanced Hepatobiliary Phase MR Images Radiology 2018 287 146 155 10.1148/radiol.2017171928 29239710
65. Yap M.H. Pons G. Marti J. Ganau S. Sentis M. Zwiggelaar R. Davison A.K. Marti R. Yap M.H. Pons G. Automated Breast Ultrasound Lesions Detection Using Convolutional Neural Networks IEEE J. Biomed. Health Inform. 2018 22 1218 1226 10.1109/JBHI.2017.2731873 28796627
66. Bar Y. Diamant I. Wolf L. Greenspan H. Deep learning with non-medical training used for chest pathology identification Proceedings of the SPIE Proceedings 9414, Medical Imaging 2015: Computer-Aided Diagnosis, 94140V (20 March 2015) Orlando, FL, USA 21–26 February 2015 10.1117/12.2083124
67. Van der Burgh H.K. Schmidt R. Westeneng H.J. de Reus M.A. van den Berg L.H. van den Heuvel M.P. Deep learning predictions of survival based on MRI in amyotrophic lateral sclerosis Neuroimage Clin. 2016 13 361 369 10.1016/j.nicl.2016.10.008 28070484
68. Lee C.S. Baughman D.M. Lee A.Y. Deep learning is effective for the classification of OCT images of normal versus Age-related Macular Degeneration Ophthalmol. Retina 2017 1 322 327 10.1016/j.oret.2016.12.009 30693348
69. Cui H. Xu Y. Li W. Wang L. Duh H. Collaborative Learning of Cross-channel Clinical Attention for Radiotherapy-Related Esophageal Fistula Prediction from, CT Proceedings of the Medical Image Computing and Computer Assisted Intervention—MICCAI 2020, Lima, Peru, 4–8 October 2020 MICCAI 2020 Lecture Notes in Computer Science Springer Cham, Switzerland 2020 Volume 12261 10.1007/978-3-030-59710-8_21
70. Kipf T.N. Welling M. Semi-Supervised Classification with Graph Convolutional Networks arXiv 2016 609.02907v4
71. Wang J. Ding H. Bidgoli F.A. Zhou B. Iribarren C. Molloi S. Baldi P. Detecting Cardiovascular Disease from Mammograms with Deep Learning IEEE Trans. Med. Imaging 2017 36 1172 1181 10.1109/TMI.2017.2655486 28113340
72. Iakovidis D.K. Georgakopoulos S.V. Vasilakakis M. Koulaouzidis A. Plagianakos V.P. Detecting and Locating Gastrointestinal Anomalies Using Deep Learning and Iterative Cluster Unification IEEE Trans. Med. Imaging 2018 37 2196 2210 10.1109/TMI.2018.2837002 29994763
73. Elman J.L. Finding Structure in Time Cogn. Sci. 1990 14 179 211 10.1207/s15516709cog1402_1
74. Xie X. Niu J. Liu X. Li Q. Wang Y. Han J. Tang S. DG-CNN: Introducing Margin Information into CNN for Breast Cancer Diagnosis in Ultrasound Images J. Comput. Sci. Technol. 2020 1 10.1007/s11390-020-0192-0
75. Zhang B. Wang Z. Gao J. Rutjes C. Nufer K. Tao D. Feng D.D. Menzies S.W. Short-Term Lesion Change Detection for Melanoma Screening with Novel Siamese Neural Network IEEE Trans. Med. Imaging 2021 40 840 851 10.1109/TMI.2020.3037761 33180721
76. Du X. Kurmann T. Chang P.L. Allan M. Ourselin S. Sznitman R. Kelly J.D. Stoyanov D. Articulated Multi-Instrument 2-D Pose Estimation Using Fully Convolutional Networks IEEE Trans. Med. Imaging 2018 37 1276 1287 10.1109/TMI.2017.2787672 29727290
77. Carneiro G. Nascimento J.C. Freitas A. The Segmentation of the Left Ventricle of the Heart from Ultrasound Data Using Deep Learning Architectures and Derivative-Based Search Methods IEEE Trans. Med. Imaging 2012 21 968 982 10.1109/TIP.2011.2169273 21947526
78. Chen C.-M. Huang Y.-S. Fang P.-W. Liang C.-W. Chang R.-F. A computer-aided diagnosis system for differentiation and delineation of malignant regions on whole-slide prostate histopathology image using spatial statistics and multidimensional DenseNet Med. Phys. 2020 47 1021 1033 10.1002/mp.13964 31834623
79. Xue Y. Zhang R. Deng Y. Chen K. Jiang T. A preliminary examination of the diagnostic value of deep learning in hip osteoarthritis PLoS ONE 2017 12 e0178992 10.1371/journal.pone.0178992 28575070
80. Li S. Wei J. Chan H.P. Helvie M.A. Roubidoux M.A. Lu Y. Zhou C. Hadjiiski L.M. Samala R.K. Computer-aided assessment of breast density: Comparison of supervised deep learning and feature-based statistical learning Phys. Med. Biol. 2018 63 025005 10.1088/1361-6560/aa9f87 29210358
81. Zhang C. Wu S. Lu Z. Shen Y. Wang J. Huang P. Lou J. Liu C. Xing L. Zhang J. Hybrid adversarial-discriminative network for leukocyte classification in leukemia Med. Phys. 2020 47 3732 3744 10.1002/mp.14144 32180243
82. Huynh B.Q. Li H. Giger M.L. Digital mammographic tumor classification using transfer learning from deep convolutional neural networks J. Med. Imaging 2016 3 034501 10.1117/1.JMI.3.3.034501 27610399
83. Ning Z. Luo J. Li Y. Han S. Feng Q. Xu Y. Chen W. Chen T. Zhang Y. Pattern Classification for Gastrointestinal Stromal Tumors by Integration of Radiomics and Deep Convolutional Features IEEE J. Biomed. Health Inform. 2019 23 1181 1191 10.1109/JBHI.2018.2841992 29993591
84. Choi H. Ha S. Im H.J. Paek S.H. Lee D.S. Refining diagnosis of Parkinson’s disease with deep learning-based interpretation of dopamine transporter imaging NeuroImage Clin. 2017 16 586 594 10.1016/j.nicl.2017.09.010 28971009
85. Luo B. Shen J. Cheng S. Wang Y. Pantic M. Shape Constrained Network for Eye Segmentation in the Wild Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) Snowmass Village, CO, USA 1–5 March 2020 1952 1960
86. Wimmer G. Hegenbart S. Vecsei A. Uhl A. Convolutional Neural Network Architectures for the Automated Diagnosis of Celiac Disease Computer-Assisted and Robotic Endoscopy CARE 2016 Lecture Notes in Computer Science Springer Berlin/Heidelberg, Germany 2017 Volume 10170 10.1007/978-3-319-54057-3_10
87. Kim K.H. Choi S.H. Park S.H. Improving Arterial Spin Labeling by Using Deep Learning Radiology 2018 287 658 666 10.1148/radiol.2017171154 29267145
88. Song Y. Zhang L. Chen S. Ni D. Lei B. Wang T. Accurate Segmentation of Cervical Cytoplasm and Nuclei Based on Multiscale Convolutional Network and Graph Partitioning IEEE Trans. Biomed. Eng. 2015 62 2421 2433 10.1109/TBME.2015.2430895 25966470
89. Moradi M. Gur Y. Wang H. Prasanna P. Syeda-Mahmood T. A hybrid learning approach for semantic labeling of cardiac CT slices and recognition of body position Proceedings of the 2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI) Prague, Czech Republic 13–16 April 2016 1418 1421 10.1109/ISBI.2016.7493533
90. Khosravan N. Celik H. Turkbey B. Jones E.C. Wood B. Bagci U. A collaborative computer aided diagnosis (C-CAD) system with eye-tracking, sparse attentional model, and deep learning Med. Image Anal. 2019 51 101 115 10.1016/j.media.2018.10.010 30399507
91. Betancur J. Commandeur F. Motlagh M. Sharir T. Einstein A.J. Bokhari S. Fish M.B. Ruddy T.D. Kaufmann P. Sinusas A.J. Deep Learning for Prediction of Obstructive Disease From Fast Myocardial Perfusion SPECT: A Multicenter Study JACC Cardiovasc. Imaging 2018 11 1654 1663 10.1016/j.jcmg.2018.01.020 29550305
92. Shin H.C. Roth H.R. Gao M. Lu L. Xu Z. Nogues I. Yao J. Mollura D. Summers R.M. Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning IEEE Trans. Med. Imaging 2016 35 1285 1298 10.1109/TMI.2016.2528162 26886976
93. Mitsuhara M. Fukui H. Sakashita Y. Ogata T. Hirakawa T. Yamashita T. Fujiyoshi H. Embedding Human Knowledge into Deep Neural Network via Attention Map arXiv 2019 1905.03540v4
94. Jiang F. Jiang Y. Zhi H. Dong Y. Li H. Ma S. Wang Y. Dong Q. Shen H. Wang Y. Artificial intelligence in healthcare: Past, present and future Stroke Vasc. Neurol. 2017 2 230 243 10.1136/svn-2017-000101 29507784
95. Bakator M. Radosav D. Deep Learning and Medical Diagnosis: A Review of Literature Multimodal Technol. Interact. 2018 2 47 10.3390/mti2030047
96. Hecht-Nielsen R. Neurocomputing: Picking the human brain IEEE Spectr. 1988 25 36 41 10.1109/6.4520
97. Krizhevsky A. Sutskever I. Hinton G.E. ImageNet Classification with Deep Convolutional Neural Networks Advances in Neural Information Processing Systems 25 Pereira F. Burges C.J.C. Bottou L. Weinberger K.Q. MIT press Cambridge, MA, USA 2012 1097 1105
98. Arasu A. Garcia-Molina H. Extracting Structured Data from Web Pages Proceedings of the 2003 ACM SIGMOD International Conference on Management of Data San Diego, CA, USA 9–12 June 2003 337 348 10.1145/872757.872799
99. Vizcarra J. Place R. Tong L. Gutman D. Wang M.D. Fusion in Breast Cancer Histology Classification ACM BCB 2019 2019 485 493 10.1145/3307339.3342166 32637941
100. Velicer W.F. Molenaar P.C. Time Series Analysis for Psychological Research Handbook of Psychology 2nd ed. Weiner I. Schinka J.A. Velicer W.F. Wiley Hoboken, NJ, USA 2012 10.1002/9781118133880.hop202022
101. LeCun Y. Boser B. Denker J.S. Henderson D. Howard R.E. Hubbard W. Jackel L.D. Backpropagation Applied to Handwritten Zip Code Recognition Neural Comput. 1989 1 541 551 10.1162/neco.1989.1.4.541
102. Ursuleanu T.F. Luca A.R. Gheorghe L. Grigorovici R. Iancu S. Hlusneac M. Preda C. Grigorovici A. Unified Analysis Specific to the Medical Field in the Interpretation of Medical Images through the Use of Deep Learning E-Health Telecommun. Syst. Netw. 2021 10 41 74 10.4236/etsn.2021.102003
103. Pandey B. Pandey D.K. Mishra B.P. Rhmann W. A comprehensive survey of deep learning in the field of medical imaging and medical natural language processing: Challenges and research directions J. King Saud Univ. Comput. Inf. Sci. 2021 10.1016/j.jksuci.2021.01.007
104. Alzubaidi L. Zhang J. Humaidi A.J. Al-Dujaili A. Duan Y. Al-Shamma O. Santamaría J. Fadhel M.A. Al-Amidie M. Farhan L. Review of deep learning: Concepts, CNN architectures, challenges, applications, future directions J. Big Data 2021 8 53 10.1186/s40537-021-00444-8 33816053
105. Wang X. Liang G. Zhang Y. Blanton H. Bessinger Z. Jacobs N. Inconsistent Performance of Deep Learning Models on Mammogram Classification J. Am. Coll. Radiol. 2020 17 796 803 10.1016/j.jacr.2020.01.006 32068005
106. McKinney S.M. Sieniek M. Godbole V. Godwin J. Antropova N. Ashrafian H. Back T. Chesus M. Corrado G.S. Darzi A. International evaluation of an AI system for breast cancer screening Nat. Cell Biol. 2020 577 89 94 10.1038/s41586-019-1799-6
107. Bai J. Posner R. Wang T. Yang C. Nabavi S. Applying deep learning in digital breast tomosynthesis for automatic breast cancer detection: A review Med. Image Anal. 2021 71 102049 10.1016/j.media.2021.102049 33901993
108. Simonyan K. Zisserman A. Very Deep Convolutional Networks for Large-Scale Image Recognition arXiv 2014 1409.1556v6
109. León J. Escobar J.J. Ortiz A. Ortega J. González J. Martín-Smith P. Gan J.Q. Damas M. Deep learning for EEG-based Motor Imagery classification: Accuracy-cost trade-off PLoS ONE 2020 15 e0234178 10.1371/journal.pone.0234178 32525885
110. Hochreiter S. Schmidhuber J. Long short-term memory Neural Comput. 1997 9 1735 1780 10.1162/neco.1997.9.8.1735 9377276
111. Saravanan S. Juliet S. Deep Medical Image Reconstruction with Autoencoders using Deep Boltzmann Machine Training EAI Endorsed Trans. Pervasive Health Technol. 2020 6 e2 10.4108/eai.24-9-2020.166360
112. Gondara L. Medical Image Denoising Using Convolutional Denoising Autoencoders Proceedings of the 2016 IEEE 16th International Conference on Data Mining Workshops (ICDMW) Barcelona, Spain 12–15 December 2016 241 246 10.1109/ICDMW.2016.0041
113. Zhou B. Khosla A. Lapedriza A. Torralba A. Oliva A. Places: An Image Database for Deep Scene Understanding arXiv 2016 1610.02055v1 10.1167/17.10.296
114. Nowling R.J. Bukowy J. McGarry S.D. Nencka A.S. Blasko O. Urbain J. Lowman A. Barrington A. Banerjee A. Iczkowski K.A. Classification before Segmentation: Improved U-Net Prostate Segmentation Proceedings of the 2019 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI) Chicago, IL, USA 19–22 May 2019 1 4 10.1109/BHI.2019.8834494.z
115. Yu E.M. Iglesias J.E. Dalca A.V. Sabuncu M.R. An Auto-Encoder Strategy for Adaptive Image Segmentation Proceedings of the Third Conference on Medical Imaging with Deep Learning (PMLR) Montreal, QC, Canada 6–8 July 2020 Volume 121 881 891
116. Uzunova H. Schultz S. Handels H. Ehrhardt J. Unsupervised pathology detection in medical images using conditional variational autoencoders Int. J. CARS 2019 14 451 461 10.1007/s11548-018-1898-0
117. Chen M. Shi X. Zhang Y. Wu D. Guizani M. Deep Features Learning for Medical Image Analysis with Convolutional Autoencoder Neural Network IEEE Trans. Big Data 2017 1 10.1109/TBDATA.2017.2717439
118. Saltz J. Gupta R. Hou L. Kurc T. Singh P. Nguyen V. Samaras D. Shroyer K.R. Zhao T. Batiste R. Spatial Organization and Molecular Correlation of Tumor-Infiltrating Lymphocytes Using Deep Learning on Pathology Images Cell Rep. 2018 23 181 193.e7 10.1016/j.celrep.2018.03.086 29617659
119. Rumelhart D. Hinton G. Williams R. Learning representations by back-propagating errors Nature 1986 323 533 536 10.1038/323533a0
120. Lam C. Yu C. Huang L. Rubin D. Retinal Lesion Detection with Deep Learning Using Image Patches Investig. Opthalmol. Vis. Sci. 2018 59 590 596 10.1167/iovs.17-22721
121. Rajaraman S. Antani S. Poostchi M. Silamut K. Hossain A. Maude R. Jaeger S. Thoma G.R. Pre-trained convolutional neural networks as feature extractors toward improved malaria parasite detection in thin blood smear images PeerJ 2018 6 e4568 10.7717/peerj.4568 29682411
122. Nielsen A. Hansen M.B. Tietze A. Mouridsen K. Prediction of Tissue Outcome and Assessment of Treatment Effect in Acute Ischemic Stroke Using Deep Learning Stroke 2018 49 1394 1401 10.1161/STROKEAHA.117.019740 29720437
123. Lee H.C. Ryu H.G. Chung E.J. Jung C.W. Prediction of Bispectral Index during Target-controlled Infusion of Propofol and Remifentanil: A Deep Learning Approach Anesthesiology 2018 128 492 501 10.1097/ALN.0000000000001892 28953500
124. Zeng L.L. Wang H. Hu P. Yang B. Pu W. Shen H. Chen X. Liu Z. Yin H. Tan Q. Multi-Site Diagnostic Classification of Schizophrenia Using Discriminant Deep Learning with Functional Connectivity MRI EBioMedicine 2018 30 74 85 10.1016/j.ebiom.2018.03.017 29622496
125. Kooi T. Van Ginneken B. Karssemeijer N. den Heeten A. Discriminating solitary cysts from soft tissue lesions in mammography using a pretrained deep convolutional neural network Med. Phys. 2017 44 1017 1027 10.1002/mp.12110 28094850
126. Heinsfeld A.S. Franco A.R. Craddock R.C. Buchweitz A. Meneguzzi F. Identification of autism spectrum disorder using deep learning and the ABIDE dataset NeuroImage Clin. 2018 17 16 23 10.1016/j.nicl.2017.08.017 29034163
127. Wang J. Yang X. Cai H. Tan W. Jin C. Li L. Discrimination of Breast Cancer with Microcalcifications on Mammography by Deep Learning Sci. Rep. 2016 6 27327 10.1038/srep27327 27273294
128. Fu H. Cheng J. Xu Y. Zhang C. Wong D.W.K. Liu J. Cao X. Disc-Aware Ensemble Network for Glaucoma Screening From Fundus Image IEEE Trans. Med. Imaging 2018 37 2493 2501 10.1109/TMI.2018.2837012 29994764
129. Yu C. Yang S. Kim W. Jung J. Chung K.-Y. Lee S.W. Oh B. Correction: Acral melanoma detection using a convolutional neural network for dermoscopy images PLoS ONE 2018 13 e0196621 10.1371/journal.pone.0196621 29689095
130. Han S.S. Park G.H. Lim W. Kim M.S. Na J.I. Park I. Chang S.E. Deep neural networks show an equivalent and often superior performance to dermatologists in onychomycosis diagnosis: Automatic construction of onychomycosis datasets by region-based convolutional deep neural network PLoS ONE 2018 13 e0191493 10.1371/journal.pone.0191493 29352285
131. Hsieh Y.J. Tseng H.C. Chin C.L. Shao Y.H. Tsai T.Y. Based on DICOM RT Structure and Multiple Loss Function Deep Learning Algorithm in Organ Segmentation of Head and Neck Image Proceedings of the Future Trends in Biomedical and Health Informatics and Cybersecurity in Medical Devices: Proceedings of the International Conference on Biomedical and Health Informatics, ICBHI 2019, Taipei, Taiwan, 17–20 April 2019 Springer Berlin/Heidelberg, Germany 2020 Volume 74 428 435 10.1007/978-3-030-30636-6_58
132. Ngo T.A. Lu Z. Carneiro G. Combining deep learning and level set for the automated segmentation of the left ventricle of the heart from cardiac cine magnetic resonance Med. Image Anal. 2017 35 159 171 10.1016/j.media.2016.05.009 27423113
133. Hinton G. Vinyals O. Dean J. Distilling the knowledge in a neural network arXiv 2015 1503.02531
134. Araújo T. Aresta G. Castro E.M. Rouco J. Aguiar P. Eloy C. Polónia A. Campilho A. Classification of breast cancer histology images using Convolutional Neural Networks PLoS ONE 2017 12 e0177544 10.1371/journal.pone.0177544 28570557
135. Han Z. Wei B. Zheng Y. Yin Y. Li K. Li S. Breast Cancer Multi-classification from Histopathological Images with Structured Deep Learning Model Sci. Rep. 2017 7 4172 10.1038/s41598-017-04075-z 28646155
136. Zhang X. Yu F.X. Chang S. Wang S. Deep Transfer Network: Unsupervised Domain Adaptation arXiv 2015 1503.00591v1
137. Hutchinson B. Deng L. Yu D. Tensor deep stacking networks IEEE Trans. Pattern Anal. Mach. Intell. 2012 35 1944 1957 10.1109/TPAMI.2012.268 23267198
138. Hjelm R.D. Fedorov A. Lavoie-Marchildon S. Grewal K. Bachman P. Trischler A. Bengio Y. Learning deep representations by mutual information estimation and maximization arXiv 2018 1808.06670
139. Alom M.Z. Yakopcic C. Nasrin M.S. Taha T.M. Asari V.K. Breast Cancer Classification from Histopathological Images with Inception Recurrent Residual Convolutional Neural Network J. Digit. Imaging 2019 32 605 617 10.1007/s10278-019-00182-7 30756265
140. Zhao Y. Dong Q. Zhang S. Zhang W. Chen H. Jiang X. Guo L. Hu X. Han J. Liu T. Automatic Recognition of fMRI-Derived Functional Networks Using 3-D Convolutional Neural Networks IEEE Trans. Biomed. Eng. 2018 65 1975 1984 10.1109/TBME.2017.2715281 28641239
141. Tiulpin A. Thevenot J. Rahtu E. Lehenkari P. Saarakkala S. Automatic Knee Osteoarthritis Diagnosis from Plain Radiographs: A Deep Learning-Based Approach Sci. Rep. 2018 8 1727 10.1038/s41598-018-20132-7 29379060
142. Zhang Z. Liang X. Dong X. Xie Y. Cao G. A Sparse-View CT Reconstruction Method Based on Combination of DenseNet and Deconvolution IEEE Trans. Med. Imaging 2018 37 1407 1417 10.1109/TMI.2018.2823338 29870369
143. Luca A.R. Ursuleanu T.F. Gheorghe L. Grigorovici1 R. Iancu S. Hlusneac M. Preda C. Grigorovici A. Designing a High-Performance Deep Learning Theoretical Model for Biomedical Image Segmentation by Using Key Elements of the Latest U-Net-Based Architectures J. Comput. Commun. 2021 9 8 20 10.4236/jcc.2021.97002
144. Huang C.H. Wu H.Y. Lin Y.L. HarDNet-MSEG: A Simple Encoder-Decoder Polyp Segmentation Neural Network that Achieves Over 0.9 Mean Dice and 86 FPS arXiv 2021 2101.07172
145. Haryanto T. Wasito I. Suhartanto H. Convolutional Neural Network (CNN) for gland images classification Proceedings of the 2017 11th International Conference on Information & Communication Technology and System (ICTS) Surabaya, Indonesia 31 October 2017 55 60 10.1109/ICTS.2017.8265646
146. Cao H. Bernard S. Heutte L. Sabourin R. Improve the performance of transfer learning without fine-tuning using dissimilarity-based multi-view learning for breast cancer histology images Image Analysis and Recognition Springer Cham, Switzerland 2018 779 787 10.1007/978-3-319-93000-8_88
147. Luo X. Mori K. Peters T.M. Advanced Endoscopic Navigation: Surgical Big Data, Methodology, and Applications Annu. Rev. Biomed. Eng. 2018 20 221 251 10.1146/annurev-bioeng-062117-120917 29505729
148. Xiao C. Choi E. Sun J. Opportunities and challenges in developing deep learning models using electronic health records data: A systematic review J. Am. Med. Inform. Assoc. 2018 25 1419 1428 10.1093/jamia/ocy068 29893864
149. Shickel B. Tighe P.J. Bihorac A. Rashidi P. Deep EHR: A Survey of Recent Advances in Deep Learning Techniques for Electronic Health Record (EHR) Analysis IEEE J. Biomed. Heal. Inform. 2018 22 1589 1604 10.1109/JBHI.2017.2767063 29989977
150. Karkra S. Singh P. Kaur K. Convolution Neural Network: A Shallow Dive in to Deep Neural Net Technology Int. J. Recent Technol. Eng. 2019 8 487 495 10.35940/ijrte.b1092.0782s719
151. Ranschaert E.R. Morozov S. Algra P.R. Artificial Intelligence in Medical Imaging: Opportunities, Applications and Risks Springer Berlin, Germany 2019 10.1007/978-3-319-94878-2
152. Tsang G. Xie X. Zhou S.M. Harnessing the Power of Machine Learning in Dementia Informatics Research: Issues, Opportunities, and Challenges IEEE Rev. Biomed. Eng. 2019 13 113 129 10.1109/RBME.2019.2904488 30872241
153. Haryanto T. Suhartanto H. Murni A. Kusmardi K. Strategies to Improve Performance of Convolutional Neural Network on Histopathological Images Classification Proceedings of the 2019 International Conference on Advanced Computer Science and information Systems (ICACSIS) Bali, Indonesia 12–13 October 2019 125 132 10.1109/ICACSIS47736.2019.8979740
154. Das A. Nair M.S. Peter S.D. Computer-Aided Histopathological Image Analysis Techniques for Automated Nuclear Atypia Scoring of Breast Cancer: A Review J. Digit. Imaging 2020 33 1 31 10.1007/s10278-019-00295-z 32076923
155. Pattanaik P. Mittal M. Khan M.Z. Panda S. Malaria detection using deep residual networks with mobile microscopy J. King Saud Univ. Comput. Inf. Sci. 2020 10.1016/j.jksuci.2020.07.003
156. Das A. Rad P. Choo K.-K.R. Nouhi B. Lish J. Martel J. Distributed machine learning cloud teleophthalmology IoT for predicting AMD disease progression Futur. Gener. Comput. Syst. 2019 93 486 498 10.1016/j.future.2018.10.050
157. Kim Y.D. Noh K.J. Byun S.J. Lee S. Kim T. Sunwoo L. Lee K.J. Kang S.-H. Park K.H. Park S.J. Effects of Hypertension, Diabetes, and Smoking on Age and Sex Prediction from Retinal Fundus Images Sci. Rep. 2020 10 4623 10.1038/s41598-020-61519-9 32165702
158. Apostolopoulos S. Ciller C. De Zanet S. Wolf S. Sznitman R. RetiNet: Automatic AMD identification in OCT volumetric data Invest. Ophthalmol. Vis. Sci. 2017 58 387
159. Zhang J. Xia Y. Wu Q. Xie Y. Classification of Medical Images and Illustrations in the Biomedical Literature Using Synergic Deep Learning arXiv 2017 1706.09092
160. Serj M.F. Lavi B. Hoff G. Valls D.P. A Deep Convolutional Neural Network for Lung Cancer Diagnostic arXiv 2018 1804.08170
161. Jang R. Kim N. Jang M. Lee K.H. Lee S.M. Na Noh H. Seo J.B. Assessment of the Robustness of Convolutional Neural Networks in Labeling Noise by Using Chest X-Ray Images from Multiple Centers JMIR Med. Inform. 2020 8 e18089 10.2196/18089 32749222
162. Bengio Y. Louradour J. Collobert R. Weston J. Curriculum learning Proceedings of the 26th Annual International Conference on Machine Learning—ICML 2009 Montreal, QC, Canada 14–18 June 2009 41 48 10.1145/1553374.1553380
163. Guan Q. Huang Y. Zhong Z. Zheng Z. Zheng L. Yang Y. Diagnose like a Radiologist: Attention Guided Convolutional Neural Network for Thorax Disease Classification arXiv 2018 1801.09927v1
164. Xia X. Gong J. Hao W. Yang T. Lin Y. Wang S. Peng W. Comparison and Fusion of Deep Learning and Radiomics Features of Ground-Glass Nodules to Predict the Invasiveness Risk of Stage-I Lung Adenocarcinomas in CT Scan Front. Oncol. 2020 10 418 10.3389/fonc.2020.00418 32296645
165. Jesson A. Guizard N. Ghalehjegh S.H. Goblot D. Soudan F. Chapados N. CASED: Curriculum Adaptive Sampling for Extreme Data Imbalance Proceedings of the Medical Image Computing and Computer Assisted Intervention—MICCAI 2017 MICCAI 2017 Lecture Notes in Computer Science Springer Berlin/Heidelberg, Germany 2017 Volume 10435 10.1007/978-3-319-66179-7_73
166. Astudillo P. Mortier P. De Beule M. Wyffels F. Curriculum Deep Reinforcement Learning with Different Exploration Strategies: A Feasibility Study on Cardiac Landmark Detection Proceedings of the 13th International Joint Conference on Biomedical Engineering Systems and Technologies—Bioimaging Valetta, Malta 24–26 February 2020 37 45 10.5220/0008948900370045
167. Li C.Y. Liang X. Hu Z. Xing E.P. Knowledge-Driven Encode, Retrieve, Paraphrase for Medical Image Report Generation Proc. Conf. AAAI Artif. Intell. 2019 33 6666 6673 10.1609/aaai.v33i01.33016666
168. Ghafoorian M. Mehrtash A. Kapur T. Karssemeijer N. Marchiori E. Pesteie M. Guttmann C.R.G. De Leeuw F.-E. Tempany C.M. Van Ginneken B. Transfer Learning for Domain Adaptation in MRI: Application in Brain Lesion Segmentation Proceedings of the Medical Image Computing and Computer Assisted Intervention—MICCAI 2017: 20th International Conference, Quebec City, QC, Canada, 11–13 September 2017 Lecture Notes in Computer Science Springer Berlin/Heidelberg, Germany 2017 Volume 10435 10.1007/978-3-319-66179-7_59
169. Jing B. Xie P. Xing E. On the Automatic Generation of Medical Imaging Reports arXiv 2017 1711.08195
170. Liu G. Hsu T.-M.H. McDermott M. Boag W. Weng W.-H. Szolovits P. Ghassemi M. Clinically Accurate Chest X-Ray Report Generation arXiv 2019 1904.02633v2
171. Gale W. Oakden-Rayner L. Carneiro G. Bradley A.P. Palmer L.J. Producing radiologist-quality reports for interpretable artificial intelligence arXiv 2018 1806.00340v1
172. Zhang Y. Wei Y. Wu Q. Zhao P. Niu S. Huang J. Tan M. Collaborative Unsupervised Domain Adaptation for Medical Image Diagnosis IEEE Trans. Image Process. 2020 29 7834 7844 10.1109/TIP.2020.3006377
173. Tang Y. Wang X. Harrison A.P. Lu L. Xiao J. Summers R.M. Attention-Guided Curriculum Learning for Weakly Supervised Classification and Localization of Thoracic Diseases on Chest Radiographs Proceedings of the Machine Learning in Medical Imaging, MLMI 2018 Lecture Notes in Computer Science Springer Berlin/Heidelberg, Germany 2018 Volume 11046 10.1007/978-3-030-00919-9_29
174. Jiménez-Sánchez A. Mateus D. Kirchhoff S. Kirchhoff C. Biberthaler P. Navab N. Ballester M.A.G. Piella G. Medical-based Deep Curriculum Learning for Improved Fracture Classification Medical Image Computing and Computer Assisted Intervention—MICCAI 2019 MICCAI 2019 Lecture Notes in Computer Science Springer Berlin/Heidelberg, Germany 2019 Volume 11769 10.1007/978-3-030-32226-7_77
175. Jiménez-Sánchez A. Mateus D. Kirchhoff S. Kirchhoff C. Biberthaler P. Navab N. Ballester M.A. Piella G. Curriculum learning for annotation-efficient medical image analysis: Scheduling data with prior knowledge and uncertainty arXiv 2007 2007.16102v1
176. Wei J. Suriawinata A. Ren B. Liu X. Lisovsky M. Vaickus L. Brown C. Baker M. Nasir-Moin M. Tomita N. Learn Like a Pathologist: Curriculum Learning by Annotator Agreement for Histopathology Image Classification Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) Waikola, HI, USA 5–9 January 2021 2473 2483 10.1109/WACV48630.2021.00252
177. Wang K. Zhang X. Huang S. Chen F. Zhang X. Huangfu L. Learning to Recognize Thoracic Disease in Chest X-Rays With Knowledge-Guided Deep Zoom Neural Networks IEEE Access 2020 8 159790 159805 10.1109/ACCESS.2020.3020579
178. Huang X. Fang Y. Lu M. Yan F. Yang J. Xu Y. Dual-Ray Net: Automatic Diagnosis of Thoracic Diseases Using Frontal and Lateral Chest X-rays J. Med. Imaging Heal. Inform. 2020 10 348 355 10.1166/jmihi.2020.2901
179. Yang Z. Cao Z. Zhang Y. Han M. Xiao J. Huang L. Wu S. Ma J. Chang P. MommiNet: Mammographic Multi-view Mass Identification Networks Proceedings of the Medical Image Computing and Computer Assisted Intervention—MICCAI 2020 MICCAI 2020 Lecture Notes in Computer Science Springer Berlin/Heidelberg, Germany 2020 Volume 12266 10.1007/978-3-030-59725-2_20
180. Liu Q. Yu L. Luo L. Dou Q. Heng P.A. Semi-Supervised Medical Image Classification With Relation-Driven Self-Ensembling Model IEEE Trans. Med. Imaging 2020 39 3429 3440 10.1109/TMI.2020.2995518 32746096
181. Hsu S.-M. Kuo W.-H. Kuo F.-C. Liao Y.-Y. Breast tumor classification using different features of quantitative ultrasound parametric images Int. J. Comput. Assist. Radiol. Surg. 2019 14 623 633 10.1007/s11548-018-01908-8 30617720
182. Antropova N. Huynh B.Q. Giger M.L. A deep feature fusion methodology for breast cancer diagnosis demonstrated on three imaging modality datasets Med. Phys. 2017 44 5162 5171 10.1002/mp.12453 28681390
183. Xie Y. Zhang J. Liu S. Cai W. Xia Y. Lung nodule classification by jointly using visual descriptors and deep features Medical Computer Vision and Bayesian and Graphical Models for Biomedical Imaging Springer Cham, Germany 2016 116 125 10.1007/978-3-319-61188-4_11
184. Chai Y. Liu H. Xu J. Glaucoma diagnosis based on both hidden features and domain knowledge through deep learning models Knowledge-Based Syst. 2018 161 147 156 10.1016/j.knosys.2018.07.043
185. Hagerty J.R. Stanley R.J. Almubarak H.A. Lama N. Kasmi R. Guo P. Drugge R.J. Rabinovitz H.S. Oliviero M. Stoecker W.V. Deep Learning and Handcrafted Method Fusion: Higher Diagnostic Accuracy for Melanoma Dermoscopy Images IEEE J. Biomed. Heal. Inform. 2019 23 1385 1391 10.1109/JBHI.2019.2891049
186. Buty M. Xu Z. Gao M. Bagci U. Wu A. Mollura D.J. Characterization of Lung Nodule Malignancy Using Hybrid Shape and Appearance Features International Conference on Medical Image Computing and Computer-Assisted Intervention Springer Cham, Switzerland 2016 662 670 10.1007/978-3-319-46720-7_77
187. Saba T. Mohamed A.S. El-Affendi M. Amin J. Sharif M. Brain tumor detection using fusion of hand crafted and deep learning features Cogn. Syst. Res. 2020 59 221 230 10.1016/j.cogsys.2019.09.007
188. Yang J. Dvornek N.C. Zhang F. Chapiro J. Lin M. Duncan J.S. Unsupervised domain adaptation via disentangled representations: Application to cross-modality liver segmentation International Conference on Medical Image Computing and Computer-Assisted Intervention Springer Cham, Germany 2019 255 263 10.1007/978-3-030-32245-8_29
189. Liu T. Guo Q. Lian C. Ren X. Liang S. Yu J. Niu L. Sun W. Shen D. Automated detection and classification of thyroid nodules in ultrasound images using clinical-knowledge-guided convolutional neural networks Med. Image Anal. 2019 58 101555 10.1016/j.media.2019.101555 31520984
190. Feng H. Cao J. Wang H. Xie Y. Yang D. Feng J. Chen B. A knowledge-driven feature learning and integration method for breast cancer diagnosis on multi-sequence MRI Magn. Reson. Imaging 2020 69 40 48 10.1016/j.mri.2020.03.001 32173583
191. Chen S. Qin J. Ji X. Lei B. Wang T. Ni D. Cheng J.-Z. Automatic Scoring of Multiple Semantic Attributes With Multi-Task Feature Leverage: A Study on Pulmonary Nodules in CT Images IEEE Trans. Med. Imaging 2017 36 802 814 10.1109/TMI.2016.2629462 28113928
192. Murthy V. Hou L. Samaras D. Kurc T.M. Saltz J.H. Center-focusing multi-task CNN with injected features for classification of glioma nuclear images Proceedings of the 2017 IEEE Winter Conference on Applications of Computer Vision (WACV) Santa Rosa, CA, USA 24–31 March 2017 834 841 10.1109/WACV.2017.98
193. Yu S. Zhou H.Y. Ma K. Bian C. Chu C. Liu H. Zheng Y. Difficulty-Aware Glaucoma Classification with Multi-rater Consensus Modeling International Conference on Medical Image Computing and Computer-Assisted Intervention Springer Cham, Germany 2020 741 750 10.1007/978-3-030-59710-8_72
194. Wang W. Lu Y. Wu B. Chen T. Chen D.Z. Wu J. Deep active self-paced learning for accurate pulmonary nodule segmentation International Conference on Medical Image Computing and Computer-Assisted Intervention Springer Cham, Switzerland 2018 723 731 10.1007/978-3-030-00934-2_80
195. Roth H.R. Lu L. Seff A. Cherry K.M. Hoffman J. Wang S. Liu J. Turkbey E. Summers R.M. A new 2.5 D representation for lymph node detection using random sets of deep convolutional neural network observations International Conference on Medical Image Computing and Computer-Assisted Intervention Springer Cham, Switzerland 2014 520 527
196. Tajbakhsh N. Shin J.Y. Gurudu S.R. Hurst R.T. Kendall C.B. Gotway M.B. Liang J. Convolutional Neural Networks for Medical Image Analysis: Full Training or Fine Tuning? IEEE Trans. Med. Imaging 2016 35 1299 1312 10.1109/TMI.2016.2535302 26978662
197. Näppi J.J. Hironaka T. Regge D. Yoshida H. Deep transfer learning of virtual endoluminal views for the detection of polyps in CT colonography Medical Imaging 2016: Computer-Aided Diagnosis International Society for Optics and Photonics Bellingham, WA, USA 2016 Volume 9785 97852B 10.1117/12.2217260
198. Zhang R. Zheng Y. Mak T.W.C. Yu R. Wong S.H. Lau J.Y.W. Poon C.C.Y. Automatic Detection and Classification of Colorectal Polyps by Transferring Low-Level CNN Features From Nonmedical Domain IEEE J. Biomed. Heal. Inform. 2017 21 41 47 10.1109/JBHI.2016.2635662
199. Zhao J. Li D. Kassam Z. Howey J. Chong J. Chen B. Li S. Tripartite-GAN: Synthesizing liver contrast-enhanced MRI to improve tumor detection Med. Image Anal. 2020 63 101667 10.1016/j.media.2020.101667 32375101
200. Zhang J. Saha A. Zhu Z. Mazurowski M.A. Hierarchical Convolutional Neural Networks for Segmentation of Breast Tumors in MRI With Application to Radiogenomics IEEE Trans. Med. Imaging 2019 38 435 447 10.1109/TMI.2018.2865671 30130181
201. Setio A.A.A. Ciompi F. Litjens G. Gerke P. Jacobs C. van Riel S.J. Wille M.M.W. Naqibullah M. Sanchez C.I. van Ginneken B. Pulmonary Nodule Detection in CT Images: False Positive Reduction Using Multi-View Convolutional Networks IEEE Trans. Med. Imaging 2016 35 1160 1169 10.1109/TMI.2016.2536809 26955024
202. Gulshan V. Peng L. Coram M. Stumpe M.C. Wu D. Narayanaswamy A. Venugopalan S. Widner K. Madams T. Cuadros J. Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs JAMA 2016 316 2402 2410 10.1001/jama.2016.17216 27898976
203. Liu J. Wang D. Lu L. Wei Z. Kim L. Turkbey E.B. Sahiner B. Petrick N.A. Summers R.M. Detection and diagnosis of colitis on computed tomography using deep convolutional neural networks Med. Phys. 2017 44 4630 4642 10.1002/mp.12399 28594460
204. Ruhan S. Owens W. Wiegand R. Studin M. Capoferri D. Barooha K. Greaux A. Rattray R. Hutton A. Cintineo J. Intervertebral disc detection in X-ray images using faster R-CNN Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. 2017 2017 564 567 10.1109/EMBC.2017.8036887 29059935
205. Ben-Ari R. Akselrod-Ballin A. Karlinsky L. Hashoul S. Domain specific convolutional neural nets for detection of architectural distortion in mammograms Proceedings of the 2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017) Melbourne, VIC, Australia 18–21 April 2017 552 556 10.1109/isbi.2017.7950581
206. Platania R. Shams S. Yang S. Zhang J. Lee K. Park S.J. Automated breast cancer diagnosis using deep learning and region of interest detection (BC-Droid) Proceedings of the 8th ACM international conference on bioinformatics, computational biology, and health informatics Boston, MA, USA 20–23 August 2017 536 543 10.1145/3107411.3107484
207. Li N. Liu H. Qiu B. Guo W. Zhao S. Li K. He J. Detection and attention: Diagnosing pulmonary lung cancer from CT by imitating physicians arXiv 2017 1712.05114v1
208. Cai G. Chen J. Wu Z. Tang H. Liu Y. Wang S. Su S. One stage lesion detection based on 3D context convolutional neural networks Comput. Electr. Eng. 2019 79 106449 10.1016/j.compeleceng.2019.106449
209. Ni Q. Sun Z.Y. Qi L. Chen W. Yang Y. Wang L. Zhang X. Yang L. Fang Y. Xing Z. A deep learning approach to characterize 2019 coronavirus disease (COVID-19) pneumonia in chest CT images Eur. Radiol. 2020 30 6517 6527 10.1007/s00330-020-07044-9 32617690
210. Lisowska A. Beveridge E. Muir K. Poole I. Thrombus detection in ct brain scans using a convolutional neural network Proceedings of the 10th International Joint Conference on Biomedical Engineering Systems and Technologies—BIOIMAGING Porto, Portugal 21–23 February 2017 Volume 3 24 33 10.5220/0006114600240033
211. Lisowska A. O’Neil A. Dilys V. Daykin M. Beveridge E. Muir K. Mclaughlin S. Poole I. Context-aware convolutional neural networks for stroke sign detection in non-contrast CT scans Proceedings of the Annual Conference on Medical Image Understanding and Analysis, Edinburgh, UK, 11–13 July 2017 Springer Cham, Switzerland 2017 494 505
212. Li H. Liu X. Boumaraf S. Liu W. Gong X. Ma X. A New Three-stage Curriculum Learning Approach for Deep Network Based Liver Tumor Segmentation 2020 International Joint Conference on Neural Networks (IJCNN), Glasgow, UK, 19–24 July 2020 IEEE Piscataway, NJ, USA 2020 1 6 10.1109/IJCNN48605.2020.9206789
213. Li X. Qin G. He Q. Sun L. Zeng H. He Z. Chen W. Zhen X. Zhou L. Digital breast tomosynthesis versus digital mammography: Integration of image modalities enhances deep learning-based breast mass classification Eur. Radiol. 2020 30 778 788 10.1007/s00330-019-06457-5 31691121
214. Bakalo R. Ben-Ari R. Goldberger J. Classification and Detection in Mammograms with Weak Supervision via Dual Branch Deep Neural Net Proceedings of the 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019), Venice, Italy, 8–11 April 2019 IEEE Piscataway, NJ, USA 2019 1905 1909 10.1109/ISBI.2019.8759458
215. Liang G. Wang X. Zhang Y. Jacobs N. Weakly-Supervised Self-Training for Breast Cancer Localization Proceedings of the 2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), Montreal, QC, Canada, 20–24 July 2020 IEEE Piscataway, NJ, USA 2019 1124 1127 10.1109/EMBC44109.2020.9176617
216. Fu L. Ma J. Ren Y. Han Y.S. Zhao J. Automatic detection of lung nodules: False positive reduction using convolution neural networks and handcrafted features Medical Imaging 2017: Computer-Aided Diagnosis International Society for Optics and Photonics Bellingham, WA, USA 2017 Volume 10134 101340A 10.1117/12.2253995
217. Chao C.H. Zhu Z. Guo D. Yan K. Ho T.Y. Cai J. Harrison A.P. Ye X. Xiao J. Yuille A. Lymph Node Gross Tumor Volume Detection in Oncology Imaging via Relationship Learning Using Graph Neural Network Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention Springer Cham, Switzerland 2020 772 782 10.1007/978-3-030-59728-3_75
218. Sóñora-Mengan A. Gonidakis P. Jansen B. García-Naranjo J. Vandemeulebroucke J. Evaluating several ways to combine handcrafted features-based system with a deep learning system using the LUNA16 Challenge framework Medical Imaging 2020: Computer-Aided Diagnosis International Society for Optics and Photonics Bellingham, WA, USA 2020 Volume 11314 10.1117/12.2549778
219. Havaei M. Davy A. Warde-Farley D. Biard A. Courville A. Bengio Y. Pal C. Jodoin P.-M. Larochelle H. Brain tumor segmentation with Deep Neural Networks Med. Image Anal. 2017 35 18 31 10.1016/j.media.2016.05.004 27310171
220. Christ P.F. Ettlinger F. Grün F. Elshaera M.E.A. Lipkova J. Schlecht S. Ahmaddy F. Tatavarty S. Bickel M. Bilic P. Automatic liver and tumor segmentation of CT and MRI volumes using cascaded fully convolutional neural networks arXiv 2017 1702.05970v2
221. Roth H.R. Farag A. Lu L. Turkbey E.B. Summers R.M. Deep convolutional networks for pancreas segmentation in CT imaging Medical Imaging 2015: Image Processing International Society for Optics and Photonics Bellingham, WA, USA 2015 Volume 9413 94131G 10.1117/12.2081420
222. Wu L. Xin Y. Li S. Wang T. Heng P.A. Ni D. Cascaded fully convolutional networks for automatic prenatal ultrasound image segmentation Proceedings of the 2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017), Melbourne, VIC, Australia, 18–21 April 2017 IEEE Piscataway, NJ, USA 2017 663 666 10.1109/ISBI.2017.7950607
223. Zeng G. Yang X. Li J. Yu L. Heng P.A. Zheng G. 3D U-net with multi-level deep supervision: Fully automatic segmentation of proximal femur in 3D MR images International Workshop on Machine Learning in Medical Imaging Springer Cham, Switzerland 2017 274 282 10.1007/978-3-319-67389-9_32
224. Valverde S. Salem M. Cabezas M. Pareto D. Vilanova J.C. Ramió-Torrentà L. Rovira À. Salvi J. Oliver A. Llado X. One-shot domain adaptation in multiple sclerosis lesion segmentation using convolutional neural networks NeuroImage Clin. 2019 21 101638 10.1016/j.nicl.2018.101638 30555005
225. Chen C. Dou Q. Chen H. Heng P.A. Semantic-aware generative adversarial nets for unsupervised domain adaptation in chest x-ray segmentation International Workshop on Machine Learning in Medical Imaging Springer Cham, Switzerland 2018 143 151 10.1007/978-3-030-00919-9_17
226. Hu M. Maillard M. Zhang Y. Ciceri T. La Barbera G. Bloch I. Gori P. Knowledge distillation from multi-modal to mono-modal segmentation networks International Conference on Medical Image Computing and Computer-Assisted Intervention Springer Cham, Germany 2020 772 781 10.1007/978-3-030-59710-8_75
227. Kamnitsas K. Baumgartner C. Ledig C. Newcombe V. Simpson J. Kane A. Menon D. Nori A. Criminisi A. Rueckert D. Unsupervised domain adaptation in brain lesion segmentation with adversarial networks International Conference on Information Processing in Medical Imaging Springer Cham, Switzerland 2017 597 609 10.1007/978-3-319-59050-9_47
228. Yu F. Zhao J. Gong Y. Wang Z. Li Y. Yang F. Dong B. Li Q. Zhang L. Annotation-free cardiac vessel segmentation via knowledge transfer from retinal images International Conference on Medical Image Computing and Computer-Assisted Intervention Springer Cham, Germany 2019 714 722 10.1007/978-3-030-32245-8_79
229. Izadi S. Mirikharaji Z. Kawahara J. Hamarneh G. Generative adversarial networks to segment skin lesions Proceedings of the 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018) Washington, DC, USA 4–7 April 2018 881 884 10.1109/ISBI.2018.8363712
230. Lahiri A. Ayush K. Kumar Biswas P. Mitra P. Generative adversarial learning for reducing manual annotation in semantic segmentation on large scale miscroscopy images: Automated vessel segmentation in retinal fundus image as test case Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops Honolulu, HI, USA 21–26 July 2017 42 48 10.1109/cvprw.2017.110
231. Schlegl T. Seeböck P. Waldstein S.M. Schmidt-Erfurth U. Langs G. Unsupervised anomaly detection with generative adversarial networks to guide marker discovery International Conference on Information Processing in Medical Imaging Springer Cham, Switzerland 2017 146 157 10.1007/978-3-319-59050-9_12
232. Berger L. Eoin H. Cardoso M.J. Ourselin S. An adaptive sampling scheme to efficiently train fully convolutional networks for semantic segmentation Medical Image Understanding and Analysis Springer Cham, Switzerland 2018 277 286 10.1007/978-3-319-95921-4_26
233. Kervadec H. Dolz J. Granger É. Ayed I.B. Curriculum semi-supervised segmentation International Conference on Medical Image Computing and Computer-Assisted Intervention Springer Cham, Germany 2019 568 575 10.1007/978-3-030-32245-8_63
234. Zhao Z. Zhang X. Chen C. Li W. Peng S. Wang J. Yang X. Zhang L. Zeng Z. Semi-supervised self-taught deep learning for finger bones segmentation Proceedings of the 2019 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI) Chicago, IL, USA 19–22 May 2019 1 4 10.1109/BHI.2019.8834460
235. Zhang J. Wang G. Xie H. Zhang S. Huang N. Zhang S. Gu L. Weakly supervised vessel segmentation in X-ray angiograms by self-paced learning from noisy labels with suggestive annotation Neurocomputing 2020 417 114 127 10.1016/j.neucom.2020.06.122
236. Wu B. Zhou Z. Wang J. Wang Y. Joint learning for pulmonary nodule segmentation, attributes and malignancy prediction Proceedings of the 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018) Washington, DC, USA 4–7 April 2018 1109 1113 10.1109/ISBI.2018.8363765
237. Chen C. Biffi C. Tarroni G. Petersen S. Bai W. Rueckert D. Learning Shape Priors for Robust Cardiac MR Segmentation from Multi-view Images Proceedings of the Medical Image Computing and Computer Assisted Intervention—MICCAI 2019 MICCAI 2019 Lecture Notes in Computer Science Springer Berlin/Heidelberg, Germany 2019 Volume 11765 10.1007/978-3-030-32245-8_58
238. Hatamizadeh A. Terzopoulos D. Myronenko A. End-to-end boundary aware networks for medical image segmentation International Workshop on Machine Learning in Medical Imaging Springer Cham, Switzerland 2019 187 194 10.1007/978-3-030-32692-0_22
239. Jin D. Guo D. Ho T.-Y. Harrison A.P. Xiao J. Tseng C.-K. Lu L. DeepTarget: Gross tumor and clinical target volume segmentation in esophageal cancer radiotherapy Med. Image Anal. 2021 68 101909 10.1016/j.media.2020.101909 33341494
240. Kushibar K. Valverde S. González-Villà S. Bernal J. Cabezas M. Oliver A. Lladó X. Automated sub-cortical brain structure segmentation combining spatial and deep convolutional features Med. Image Anal. 2018 48 177 186 10.1016/j.media.2018.06.006 29935442
241. Khan H. Shah P.M. Shah M.A. Islam S.U. Rodrigues J. Cascading handcrafted features and Convolutional Neural Network for IoT-enabled brain tumor segmentation Comput. Commun. 2020 153 196 207 10.1016/j.comcom.2020.01.013
242. Narotamo H. Sanches J.M. Silveira M. Combining Deep Learning with Handcrafted Features for Cell Nuclei Segmentation Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. 2020 2020 1428 1431 10.1109/EMBC44109.2020.9175258 33018258
243. Huang K. Cheng H.D. Zhang Y. Zhang B. Xing P. Ning C. Medical knowledge constrained semantic breast ultrasound image segmentation Proceedings of the 2018 24th International Conference on Pattern Recognition (ICPR) Beijing, China 20–24 August 2018 1193 1198 10.1109/ICPR.2018.8545272
244. Painchaud N. Skandarani Y. Judge T. Bernard O. Lalande A. Jodoin P.-M. Cardiac Segmentation With Strong Anatomical Guarantees IEEE Trans. Med. Imaging 2020 39 3703 3713 10.1109/TMI.2020.3003240 32746116
245. Painchaud N. Skandarani Y. Judge T. Bernard O. Lalande A. Jodoin P.M. Cardiac MRI segmentation with strong anatomical guarantees Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention Springer Cham, Germany 2019 632 640 10.1007/978-3-030-32245-8_70
246. Yue Q. Luo X. Ye Q. Xu L. Zhuang X. Cardiac segmentation from LGE MRI using deep neural network incorporating shape and spatial priors Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention Springer Cham, Germany 2019 559 567 10.1007/978-3-030-32245-8_62
247. Mirikharaji Z. Hamarneh G. Star shape prior in fully convolutional networks for skin lesion segmentation Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention Springer Cham, Germany 2018 737 745 10.1007/978-3-030-00937-3_84
248. Ravishankar H. Venkataramani R. Thiruvenkadam S. Sudhakar P. Vaidya V. Learning and incorporating shape models for semantic segmentation International Conference on Medical Image Computing and Computer-Assisted Intervention Springer Cham, Germany 2017 203 211 10.1007/978-3-319-66182-7_24
249. Zheng H. Lin L. Hu H. Zhang Q. Chen Q. Iwamoto Y. Han X. Chen Y.W. Tong R. Wu J. Semi-supervised segmentation of liver using adversarial learning with deep atlas prior International Conference on Medical Image Computing and Computer-Assisted Intervention Springer Cham, Germany 2019 148 156 10.1007/978-3-030-32226-7_17
250. Oktay O. Ferrante E. Kamnitsas K. Heinrich M.P. Bai W. Caballero J. Cook S.A. De Marvao A. Dawes T. O’Regan D.P. Anatomically Constrained Neural Networks (ACNNs): Application to Cardiac Image Enhancement and Segmentation IEEE Trans. Med. Imaging 2018 37 384 395 10.1109/TMI.2017.2743464 28961105
251. Dalca A.V. Guttag J. Sabuncu M.R. Anatomical priors in convolutional networks for unsupervised biomedical segmentation Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Salt Lake City, UT, USA 18–23 June 2018 9290 9299 10.1109/CVPR.2018.00968
252. He Y. Yang G. Chen Y. Kong Y. Wu J. Tang L. Zhu X. Dillenseger J.L. Shao P. Zhang S. Dpa-densebiasnet: Semi-supervised 3d fine renal artery segmentation with dense biased network and deep priori anatomy International Conference on Medical Image Computing and Computer-Assisted Interventio Springer Cham, Switzerland 2019 139 147 10.1007/978-3-030-32226-7_16
253. Song Y. Zhu L. Lei B. Sheng B. Dou Q. Qin J. Choi K.S. Shape Mask Generator: Learning to Refine Shape Priors for Segmenting Overlapping Cervical Cytoplasms International Conference on Medical Image Computing and Computer-Assisted Intervention Springer Cham, Switzerland 2020 639 649 10.1007/978-3-030-59719-1_62
254. Boutillon A. Borotikar B. Burdin V. Conze P.H. Combining shape priors with conditional adversarial networks for improved scapula segmentation in MR images Proceedings of the 2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI) Iowa City, IA, USA 3–7 April 2020 1164 1167 10.1109/ISBI45749.2020.9098360
255. Pham D.D. Dovletov G. Pauli J. Liver Segmentation in CT with MRI Data: Zero-Shot Domain Adaptation by Contour Extraction and Shape Priors Proceedings of the 2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI) Iowa City, IA, USA 3–7 April 2020 1538 1542 10.1109/ISBI45749.2020.9098615
256. Engin M. Lange R. Nemes A. Monajemi S. Mohammadzadeh M. Goh C.K. Tu T.M. Tan B.Y. Paliwal P. Yeo L.L. Agan: An anatomy corrector conditional generative adversarial network International Conference on Medical Image Computing and Computer-Assisted Intervention Springer Cham, Switzerland 2020 708 717 10.1007/978-3-030-59713-9_68
257. Gao Y. Huang R. Yang Y. Zhang J. Shao K. Tao C. Chen Y. Metaxas D.N. Li H. Chen M. FocusNetv2: Imbalanced large and small organ segmentation with adversarial shape constraint for head and neck CT images Med. Image Anal. 2021 67 101831 10.1016/j.media.2020.101831 33129144
258. Yang G. Yu S. Dong H. Slabaugh G.G. Dragotti P.L. Ye X. Liu F. Arridge S.R. Keegan J. Guo Y. DAGAN: Deep De-Aliasing Generative Adversarial Networks for Fast Compressed Sensing MRI Reconstruction IEEE Trans. Med. Imaging 2018 37 1310 1321 10.1109/TMI.2017.2785879 29870361
259. Swati Z.N.K. Zhao Q. Kabir M. Ali F. Ali Z. Ahmed S. Lu J. Content-Based Brain Tumor Retrieval for MR Images Using Transfer Learning IEEE Access 2019 7 17809 17822 10.1109/ACCESS.2019.2892455
260. Khatami A. Babaie M. Tizhoosh H. Khosravi A. Nguyen T. Nahavandi S. A sequential search-space shrinking using CNN transfer learning and a Radon projection pool for medical image retrieval Expert Syst. Appl. 2018 100 224 233 10.1016/j.eswa.2018.01.056
261. Anavi Y. Kogan I. Gelbart E. Geva O. Greenspan H. A comparative study for chest radiograph image retrieval using binary texture and deep learning classification Proceedings of the 2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) Milan, Italy 25–29 August 2015 2940 2943 10.1109/EMBC.2015.7319008
262. Anavi Y. Kogan I. Gelbart E. Geva O. Greenspan H. Visualizing and enhancing a deep learning framework using patients age and gender for chest x-ray image retrieval Medical Imaging 2016: Computer-Aided Diagnosis International Society for Optics and Photonics Bellingham, WA, USA 2020 Volume 9785 978510 10.1117/12.2217587
263. Ahmad J. Sajjad M. Mehmood I. Baik S.W. SiNC: Saliency-injected neural codes for representation and efficient retrieval of medical radiographs PLoS ONE 2017 12 e0181707 10.1371/journal.pone.0181707 28771497
264. Ursuleanu T.F. Luca A.R. Gheorghe L. Grigorovici R. Iancu S. Hlusneac M. Preda C. Grigorovici A. The Use of Artificial Intelligence on Segmental Volumes, Constructed from MRI and CT Images, in the Diagnosis and Staging of Cervical Cancers and Thyroid Cancers: A Study Protocol for a Randomized Controlled Trial J. Biomed. Sci. Eng. 2021 14 300 304 10.4236/jbise.2021.146025
265. Luca A. Ursuleanu T. Gheorghe L. Grigorovici R. Iancu S. Hlusneac M. Preda C. Grigorovici A. The Use of Artificial Intelligence on Colposcopy Images, in the Diagnosis and Staging of Cervical Precancers: A Study Protocol for a Randomized Controlled Trial J. Biomed. Sci. Eng. 2021 14 266 270 10.4236/jbise.2021.146022
266. Goodfellow I. Pouget-Abadie J. Mirza M. Xu B. Warde-Farley D. Ozair S. Courville A. Bengio Y. Generative Adversarial Networks Adv. Neural Inf. Process. Syst. 2014 3 10.1145/3422622
267. Ching T. Himmelstein D.S. Beaulieu-Jones B.K. Kalinin A.A. Do B.T. Way G.P. Ferrero E. Agapow P.-M. Zietz M. Hoffman M.M. Opportunities and obstacles for deep learning in biology and medicine J. R. Soc. Interface 2018 15 20170387 10.1098/rsif.2017.0387 29618526
268. Long M. Zhu H. Wang J. Jordan M.I. Unsupervised domain adaptation with residual transfer networks arXiv 2016 1602.04433v2
269. Tzeng E. Hoffman J. Saenko K. Darrell T. Adversarial discriminative domain adaptation Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition Honolulu, HI, USA 21–26 July 2017 7167 7176 10.1109/CVPR.2017.316
270. Luo Y. Zheng L. Guan T. Yu J. Yang Y. Taking a closer look at domain shift: Category-level adversaries for semantics consistent domain adaptation Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Long Beach, CA, USA 16–17 June 2019 2507 2516 10.1109/CVPR.2019.00261
271. Tsai Y.H. Hung W.C. Schulter S. Sohn K. Yang M.H. Chandraker M. Learning to adapt structured output space for semantic segmentation Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Salt Lake City, UT, USA 18–23 June 2018 7472 7481 10.1109/CVPR.2018.00780
272. Jiang J. Hu Y.-C. Tyagi N. Zhang P. Rimner A. Mageras G.S. Deasy J.O. Veeraraghavan H. Tumor-Aware, Adversarial Domain Adaptation from CT to MRI for Lung Cancer Segmentation Med. Image Comput. Comput. Assist Interv. 2018 11071 777 785 10.1007/978-3-030-00934-2_86 30294726
273. Liu J. Li W. Zhao N. Cao K. Yin Y. Song Q. Chen H. Gong X. Integrate domain knowledge in training CNN for ultrasonography breast cancer diagnosis Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention Springer Cham, Switzerland 2018 868 875 10.1007/978-3-030-00934-2_96
274. Wang Z. Zhang J. Feng J. Chen Z. Knowledge graph and text jointly embedding Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) Doha, Qatar 25–29 October 2014 1591 1601 10.3115/v1/D14-1167
275. Alzubaidi L. Fadhel M.A. Al-Shamma O. Zhang J. Santamaría J. Duan Y. Oleiwi S.R. Towards a Better Understanding of Transfer Learning for Medical Imaging: A Case Study Appl. Sci. 2020 10 4523 10.3390/app10134523
276. Alzubaidi L. Al-Amidie M. Al-Asadi A. Humaidi A. Al-Shamma O. Fadhel M. Zhang J. Santamaría J. Duan Y. Novel Transfer Learning Approach for Medical Imaging with Limited Labeled Data Cancers 2021 13 1590 10.3390/cancers13071590 33808207
277. Wistuba M. Rawat A. Pedapati T. A survey on neural architecture search arXiv 2019 1905.01392v2
278. Guo D. Jin D. Zhu Z. Ho T.Y. Harrison A.P. Chao C.H. Xiao J. Lu L. Organ at risk segmentation for head and neck cancer using stratified learning and neural architecture search Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Seattle, WA, USA 14–19 June 2020 4223 4232 10.1109/CVPR42600.2020.00428

