
==== Front
Psychol Bull
Psychol Bull
Psychological Bulletin
0033-2909
1939-1455
American Psychological Association

bul_147_11_1215
10.1037/bul0000348
2022-40433-004
Articles
Sleep Deprivation and Memory: Meta-Analytic Reviews of Studies on Sleep Deprivation Before and After Learning
Johnson Blair T. Editor
http://orcid.org/0000-0003-3515-5566
Newbury Chloe R. *1
http://orcid.org/0000-0002-8629-8690
Crowley Rebecca 1
http://orcid.org/0000-0002-3070-7555
Rastle Kathleen 1
http://orcid.org/0000-0003-1929-3598
Tamminen Jakke *1
1 Department of Psychology, Royal Holloway, University of London
This work was funded by Economic and Social Research Council grant ES/P001874/1 awarded to Kathleen Rastle and Jakke Tamminen.

Chloe R. Newbury and Rebecca Crowley contributed equally to this work.

The data and analysis scripts are available at osf.io/5gjvs/.

* Correspondence concerning this article should be addressed to Chloe R. Newbury or Jakke Tamminen, Department of Psychology, Royal Holloway, University of London, Egham TW20 0EX, United Kingdom chloe.newbury@rhul.ac.uk or jakke.tamminen@rhul.ac.uk
11 2021
147 11 12151240
8 9 2020
24 10 2021
11 12 2021
© 2021 The Author(s)
2021
The Author(s)
https://creativecommons.org/licenses/by/3.0/ This article has been published under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. Copyright for this article is retained by the author(s). Author(s) grant(s) the American Psychological Association the exclusive right to publish the article and identify itself as the original publisher.
Research suggests that sleep deprivation both before and after encoding has a detrimental effect on memory for newly learned material. However, there is as yet no quantitative analyses of the size of these effects. We conducted two meta-analyses of studies published between 1970 and 2020 that investigated effects of total, acute sleep deprivation on memory (i.e., at least one full night of sleep deprivation): one for deprivation occurring before learning and one for deprivation occurring after learning. The impact of sleep deprivation after learning on memory was associated with Hedges’ g = 0.277, 95% CI [0.177, 0.377]. Whether testing took place immediately after deprivation or after recovery sleep moderated the effect, with significantly larger effects observed in immediate tests. Procedural memory tasks also showed significantly larger effects than declarative memory tasks. The impact of sleep deprivation before learning was associated with Hedges’ g = 0.621, 95% CI [0.473, 0.769]. Egger’s tests for funnel plot asymmetry suggested significant publication bias in both meta-analyses. Statistical power was very low in most of the analyzed studies. Highly powered, preregistered replications are needed to estimate the underlying effect sizes more precisely.

Public Significance Statement

The health risks associated with lack of sleep are well known, but the consequences of missing one or more nights of sleep for learning and memory are less well appreciated. In two meta-analyses pooling studies across 5 decades of research, we found that total sleep deprivation before learning as well as after learning had a detrimental impact on memory for the newly learned materials. These data suggest sleep supports learning and memory in two ways: It prepares the brain for learning over the next day, and it helps strengthen new memories learned during the previous day.

sleep
sleep deprivation
learning
memory
meta-analysis
==== Body
pmcThere is a growing body of evidence suggesting a critical role of sleep in learning and memory (Diekelmann & Born, 2010). On the one hand, offline memory consolidation during sleep benefits both declarative and procedural memories acquired during preceding wake (Klinzing et al., 2019). On the other hand, memory encoding capacity has been argued to saturate gradually during wake, with sleep restoring this capacity (Cirelli & Tononi, in press; Tononi & Cirelli, 2012). These theoretical advances have been accompanied by practical societal concerns regarding the prevalence of poor sleep, especially for students (Twenge et al., 2017) and shift workers (Vidya et al., 2019). The proposed importance of sleep for memory processes has been supported by many studies showing detrimental effects of total sleep deprivation on the learning and retrieval of new information. Yet, the effect sizes associated with the total sleep deprivation impairment are variable, and some studies have failed to find significant effects altogether (e.g., Diekelmann et al., 2008). Therefore, we used a meta-analytic approach to estimate the effect size associated with the impact of sleep deprivation, both when the deprivation occurs before learning and when it occurs after learning.

Impact of Total Sleep Deprivation After Learning and Potential Moderators of the Effect

The active systems consolidation theory suggests that sleep after learning strengthens new memories (e.g., Klinzing et al., 2019; Kumaran et al., 2016; McClelland et al., 1995). Information learned during wakefulness is initially encoded rapidly in the hippocampus, where memories are stored separately from existing memory stores. Repeated reactivation of these new memories, primarily during slow-wave sleep (SWS), supports the strengthening of memory representations and leads to the integration of these memories in the neocortex. Such neocortical representations are less liable to disruption and form interrelated semantic networks with existing memories, yielding memory representations that allow abstraction, generalization, and discovery of statistical patterns across discrete memories (Lewis & Durrant, 2011; Lewis et al., 2018; Stickgold & Walker, 2013). Notably, since the mechanisms outlined in this theory relate only to hippocampal-dependent memory consolidation (Inostroza & Born, 2013), these mechanisms may primarily support the consolidation of declarative (or explicit) memory.

Effects of sleep on nondeclarative memory have also been observed; for example, sleep enhances motor skills such as finger-tapping sequence learning (Korman et al., 2007; Walker et al., 2002; see King et al., 2017 for a review). However, this beneficial effect of sleep on procedural memories may be evident only when learning is intentional (explicit memory), rather than unintentional (implicit memory). Robertson et al. (2004) found that awareness of learning a finger-tapping task led to a sleep benefit, whereas improvements in implicit learning performance, when participants had little awareness of the task, were similar regardless of whether the retention interval contained sleep or wakefulness. Thus, there are suggestions that the mechanisms involved in the consolidation of hippocampal-dependent declarative memories may also facilitate the consolidation of some procedural tasks that rely on explicit learning and thus show some hippocampal-dependency (Schönauer et al., 2014; Walker et al., 2005).

However, this latter theory does not take into account observations that some procedural tasks that do not rely on explicit learning or an intact hippocampus still show superior performance after sleep. Stickgold et al. (2000) found that a period of sleep after learning a visual discrimination task benefited later performance, and Schönauer et al. (2015) found that improvements in performance on a mirror-tracing task were only observed after a period of offline consolidation. Recent studies in both animals (Sawangjit et al., 2018) and humans (Schapiro et al., 2019) have suggested that the hippocampus may be involved in the sleep-dependent consolidation of memories that do not rely on the hippocampus during encoding. For example, Schapiro et al. (2019) trained amnesic patients with hippocampal damage on the motor sequence task, a classic procedural memory task typically considered to be non-hippocampus-dependent. The patients were able to learn the task equally well compared to matched controls, suggesting that the hippocampus is not required for learning of the task. However, while the controls showed the expected overnight consolidation benefit, the patients did not, leading the authors to conclude that the hippocampus may be involved in the consolidation of procedural tasks that do not require it for initial learning.

As reviewed above, theories of memory consolidation predict that depriving participants of sleep after learning should impair memory for the information encoded before sleep deprivation, relative to control conditions where participants are allowed to sleep normally after learning. In our first meta-analysis, we analyze the current research into both declarative and procedural memories to estimate the size of this sleep deprivation after learning effect. We focus on the literature using manipulations of total sleep deprivation, as this is the strongest and most direct manipulation to test theories of sleep-associated memory consolidation. In doing so, we exclude from our analyses studies of sleep restriction. In standard sleep restriction studies, participants are allowed to sleep for a shorter duration than they would do otherwise, and the manipulation typically continues for multiple nights. This chronic sleep restriction can have a detrimental impact on learning and memory (e.g., Cousins et al., 2018) although not always (e.g., Voderholzer et al., 2011). In selective sleep restriction studies, participants are only deprived of the first half of the night, rich in SWS, or the second half of the night, rich in rapid eye movement (REM) sleep (e.g., Plihal & Born, 1997). These studies can reveal important information about the precise brain mechanisms underlying benefits of sleep on memory. There are two theoretically motivated reasons for excluding both types of sleep restriction from our meta-analyses. Standard sleep restriction studies still allow participants to sleep for several hours each night, and it may be sufficient for sleep-associated memory consolidation to occur. Thus, these manipulations do not provide a strong test of the relevant theories, and their inclusion might lead us to underestimate the effect size associated with sleep deprivation. Selective sleep restriction studies on the other hand are designed to address the more fine-grained question of which specific sleep stages are the most beneficial for memory. Different theories make different predictions in this regard: For example, the active systems consolidation theory emphasizes the role of SWS (Klinzing et al., 2019); the theory of Lewis et al. (2018) emphasizes REM (at least for learning involving creative thought); and the sequential theory of Giuditta (2014) proposes that an interaction between SWS and REM is key. However, all current theories make the common prediction that sleep should benefit memory more than wake. We do not attempt to adjudicate between the competing theories and therefore restrict our analysis to studies using total sleep deprivation where a clear prediction is made by all theories.

Where possible we use moderators to establish whether the effect size is modulated by variables that have been hypothesized to be important. For example, it is not clear whether sleep deprivation after learning impacts declarative and procedural memories similarly. If the neural and cognitive mechanisms associated with the consolidation of declarative and procedural memories differ, one may observe different effect sizes in studies targeting the two memory types. To test this hypothesis, we entered declarative versus procedural memory type as a moderator in our meta-analysis.

Some studies have tested the effects of sleep deprivation after one or more nights of recovery sleep while others have tested immediately after a night of sleep deprivation with no intervening recovery sleep. The primary reason for allowing recovery sleep before testing is that sleep deprivation has well-established impacts on attention (e.g., Lim & Dinges, 2008; Vargas et al., 2017) that may compromise performance in an immediate memory test and make it difficult to distinguish between effects of sleep deprivation due to fatigue and effects due to disruption to memory consolidation processes. Using recovery sleep to rule out potential effects of fatigue at test assumes that the first night of sleep following learning is of critical importance in memory consolidation and that consolidation may not occur in subsequent sleep periods or has a weaker impact after the first missed sleep opportunity. Although we are not aware of any studies that have explicitly tested this assumption, for example, by systematically manipulating the number of nights of sleep following learning, some support has been derived from studies such as that of Gais et al. (2007) who observed effects of one night of sleep deprivation after two recovery nights and even 6 months later.

Recent studies have cast doubt on the privileged status of the first night of sleep, however. Schönauer et al. (2015) found only a short-term cost of sleep deprivation after learning for hippocampal-dependent memories, with sleep deprivation after learning impairing retrieval of word pairs after one night of deprivation, but no difference in retrieval between the sleep and sleep deprivation conditions after two nights of recovery sleep. They suggested that for such hippocampal-dependent memories, the hippocampus may act as a temporary buffer, storing memories until the first sleep opportunity, even if that opportunity is delayed. Thus, sleep deprivation after learning would only have a detrimental effect on memory performance if there is no sleep opportunity before testing. In contrast, they found that procedural memories that do not rely on the hippocampus suffered a more long-term effect of sleep deprivation, supporting previous evidence that the first night of sleep is crucial for improving performance on procedural tasks (Stickgold et al., 2000). Therefore, for procedural memories, the loss of the first night of sleep may be critical. Given the mixed evidence in the literature on the impact of recovery sleep, we entered the presence or absence of recovery sleep as a moderator in the meta-analysis. If the first night of sleep after learning is of critical importance, on the one hand, we should see a sleep deprivation impairment both in studies that test immediately after deprivation and in studies that test after recovery sleep. If, on the other hand, consolidation processes can be delayed, we should see a sleep deprivation impairment only in studies that test immediately (i.e., they provide no opportunity for delayed consolidation). The latter scenario is also consistent with the possibility that the sleep deprivation impairment is due entirely to fatigue at test (although see Schönauer et al., 2015, for data suggesting fatigue does not impair memory recall).

Some studies of recognition memory have failed to find a beneficial effect of sleep on memory performance leading to a debate about whether sleep has no or only limited impact on recognition memory (e.g., Drosopoulos et al., 2005; Hu et al., 2006; Morgan et al., 2019; Rauchs et al., 2004; Stepan et al., 2017). The difference between recall and recognition tasks is particularly stark in the literature using the Deese–Roediger–McDermott (DRM) paradigm of false memory formation. Here, studies using recognition tasks have reported that sleep may reduce false memories (Fenn et al., 2009; Lo et al., 2014), whereas studies using recall tasks have reported that sleep may increase false memories (Diekelmann et al., 2010; McKeon et al., 2012; Pardilla-Delgado & Payne, 2017; Payne et al., 2009). Consequently, a recent meta-analysis of sleep studies using the DRM paradigm concluded that the impact of sleep on false memory is restricted to recall tasks (Newbury & Monaghan, 2019). This meta-analysis also found that the sleep benefit for studied words (i.e., veridical memory) was dramatically larger in recall tasks than in recognition tasks (g = 0.407 vs. g = 0.005). The discrepancy between recall and recognition tasks might be explained by dual-process accounts, which suggest that recognition memory has both an explicit recollection element as well as an implicit familiarity element (e.g., Jacoby, 1991; Yonelinas, 2002), and these two elements may rely on different neural structures, with only recollection depending on the hippocampus. Support for this account has come from findings that sleep only facilitates recognition memory based on recollection, not familiarity (e.g., Drosopoulos et al., 2005). On the other hand, studies that have directly compared memory for emotionally negative and neutral stimuli appear to suggest that sleep benefits recognition memory for emotional stimuli but not for neutral stimuli (Alger et al., 2018; Hu et al., 2006; Payne et al., 2008, 2015; see Kim & Payne, 2020 for a review) suggesting that sleep’s impact on recognition memory may be modulated by emotionality. Given the inconsistency in the existing literature on the extent to which sleep after learning benefits recognition memory tasks, it is important to quantify and compare the size of the sleep benefit across recognition and recall tasks. Thus, we entered memory type as a moderator in our meta-analysis.

Sleep has previously been found to improve emotional episodic memories more than neutral memories, with some studies suggesting a specific role of REM sleep in the consolidation of emotional memories (e.g., Groch et al., 2015; Payne & Kensinger, 2010; Wagner et al., 2001; see Kim & Payne, 2020 for a review). Two recent meta-analyses investigated the preferential role of sleep in emotional memory consolidation. Schäfer et al. (2020) found that sleep improved both emotional and neutral memory equally, with no evidence for preferential impact on emotional memory; in fact, the difference between emotional and neutral memory was larger after wake than sleep. However, Schäfer et al. (2020) did find that when their analysis was restricted to experiments that contrasted SWS and REM sleep, sleep that consisted primarily of REM did show a preferential consolidation effect for emotional memory, although the number of studies included in this analysis was small. Lipinska et al. (2019) also found no meta-analytic evidence in favor of sleep’s preferential impact on emotional memory. However, they did find that the preferential effect was larger in recall tasks compared to recognition tasks and in studies that controlled for initial learning. In the current meta-analysis, we shed new light on these issues by focussing on sleep deprivation manipulations. To investigate whether the effect of sleep deprivation on memory performance is modulated by emotionality of the to-be-remembered stimuli, we entered emotionality as a moderator in our meta-analysis.

Impact of Total Sleep Deprivation Before Learning and Potential Moderators of the Effect

Recent research has also proposed a role for sleep before learning. According to the synaptic homeostasis hypothesis (Cirelli & Tononi, in press; Tononi & Cirelli, 2003, 2012), learning occurs during wake when a neuron detects a statistical regularity in its input and begins to fire in response to this regular input. In other words, successful learning requires neurons to be able to fire selectively in response to statistically regular patterns observed in the environment. To do so, strength of the synapses carrying these inputs must be increased. However, the neuron now faces the plasticity-selectivity dilemma. As an increasing number of input lines become strengthened, a larger range of input patterns can make the neuron fire, reducing the neuron’s ability to fire selectively. This loss of selectivity corresponds to reduced ability to encode new information. During sleep, the brain spontaneously activates both new information encoded during previous wake and information encoded in the past. Over the course of this activation, those synapses that are activated most strongly and consistently during wake survive, while at the same time, those synapses that were less activated are weakened. This weakening occurs primarily during the transitions between intracellular up and down states experienced during SWS. This competitive down-selection of weaker synapses restores memory encoding ability.

The restorative function of sleep is supported by evidence showing decreased episodic learning ability across a 6-hr retention interval in which participants remained awake, whereas encoding capacity was restored after a daytime nap (Mander et al., 2011). Further, neuroimaging evidence suggests sleep deprivation prior to learning is associated with disrupted encoding-related functional activity in the bilateral posterior hippocampus (Yoo et al., 2007; for similar findings, see Alberca-Reina et al., 2015; Drummond & Brown, 2001; Van Der Werf et al., 2009). Thus, sleep deprivation before learning may be detrimental specifically for the encoding of hippocampal-dependent declarative memories. Our second meta-analysis seeks to estimate the effect size associated with this impairment. As only two studies have looked at the impact of sleep deprivation on procedural learning when it occurs after deprivation, we were not able to assess the potential moderating effect of declarative versus procedural memory. We were also not able to use emotionality as a moderator here due to the low number of relevant studies. Yet, there are several studies that have used recall tasks and recognition memory tasks, so we were able to evaluate the moderating effects of recall versus recognition, as in the first meta-analysis.

The Present Meta-Analyses

Despite the breadth of evidence for an effect of total sleep deprivation both before and after learning on memory performance, there is no comprehensive review and analysis of the strength of the effect of sleep deprivation on long-term memory. Previous reviews and meta-analyses investigating a role of sleep deprivation have focused on tasks that are likely more susceptible to fatigue. Pilcher and Huffcutt (1996) conducted a meta-analytic review of the effect of sleep deprivation on cognitive and motor task performance in 19 primary studies and found that sleep deprivation had a significant impact on performance. Still, this meta-analysis does not address long-term memory performance. Similarly, Lim and Dinges (2010) found an effect of sleep deprivation on a range of cognitive tasks including attention, working memory, and short-term memory, though the size of the effect varied depending on the task (e.g., a nonsignificant effect on reasoning accuracy, but a large effect on attention). Finally, Harrison and Horne (2000b) in a review found that sleep deprivation impacted decision-making ability. The tasks studied in these reviews are often repetitive and monotonous (e.g., the Psychomotor Vigilance Task; Dinges & Powell, 1985, the go/no go paradigm, and tests of serial addition), and they tend to probe lower-level functions that are particularly susceptible to fatigue, such as reaction times and processing speed. Therefore, the conditions of these studies are arguably better suited to finding adverse effects of sleep deprivation on performance than studies looking at higher-level learning and long-term memory. Thus, a review of the effects of sleep deprivation on such high-level, long-term memory is required.

Taking a meta-analytic approach will permit not only a quantitative assessment of the size of the main effect of sleep deprivation and its moderators but also an investigation of methodological quality within this literature including the statistical power of studies proposing to find a sleep deprivation effect. Variety in sample selection and methodological designs used within this literature raises the possibility of variations in methodological quality. Such variations could lead to biases in the meta-analysis by overestimating or underestimating the effect size (Higgins et al., 2011). Thus, we developed a checklist to assess multiple aspects of methodological quality, including questions specifically relevant to the assessment of sleep effects (e.g., excluding participants with sleep disorders), questions on study design (e.g., within-subject vs. between-subjects design, and random allocation to conditions), and questions on data analysis (e.g., preregistration and a priori power analyses). We used similar questions to other meta-analyses in the sleep literature (Lim & Dinges, 2010; Lo, Groeger, et al., 2016; Schäfer et al., 2020) and examined methodological quality as a continuous moderator in the analysis. The full methodological quality checklist is provided in Supplemental Appendix A.

It has been suggested that psychological science more broadly is currently suffering from a replication crisis due to low power, publication bias, selection biases, and analysis errors (Nosek et al., 2015). Low power limits potential to detect genuine effects but also results in Type I errors and exaggerated effect sizes (Ioannidis, 2005; Pollard & Richardson, 1987). Szucs and Ioannidis (2017) conducted an analysis of almost 4,000 cognitive neuroscience and psychology papers and found that the overall mean power to detect small, medium, and large effects was 17%, 49%, and 71%, respectively, with even lower power in the subfield of cognitive neuroscience. Given the convention that power to detect an effect size should be at least 80% (Di Stefano, 2003), it is clear that a large number of studies within psychology are underpowered (see Button et al., 2013; for further evidence of low statistical power within neuroscience). In the sleep literature, sample sizes tend to be low, potentially due to the resource intensity of conducting these experiments. Thus, we investigated whether the low power seen more broadly in psychological science and neuroscience is also evident in the sleep deprivation literature. For each individual effect size entered into the meta-analysis, we calculated the study’s power (defined as power to detect our meta-analytic effect size) and investigated whether there is an association between a study’s power and the effect size observed in the study.

Method

Search Strategy

For study selection, we generated the Boolean search term “Sleep AND (deprivation OR restriction OR loss) AND (learning OR memory OR conditioning)” and conducted a search in the electronic databases EBSCOhost (included PsycARTICLES, PsycEXTRA, PsycINFO, and PsycTESTS) and PubMED on July 29th, 2020. This search yielded 2,213 empirical articles published between January 01, 1970 and July 29, 2020 in peer-reviewed journals in English using human participants.

In line with best practice guidelines (Rothstein et al., 2005; Siddaway et al., 2019), we ran several searches on July 13th, 2020, using the same search terms as above, to identify gray literature in an attempt to mitigate against publication bias. These searches yielded a total of 553 items. Specifically, we widened our search criteria in EBSCOhost and PubMED to include unpublished dissertations and theses, conference materials, and preprints; we searched the bioRxiv and PsyArXiv repositories for preprints; and we searched the ProQuest and OpenGrey (a European database in which national libraries submit unpublished studies) databases for unpublished dissertations and theses, conference materials, and for research grants and fellowship awards. Additionally, we contacted all authors who had published data included in our initial screening results to ask for unpublished data that fit our inclusion criteria, and this yielded one preprint article. We also had one in-press article during the search period that fits our inclusion criteria (Tamminen et al., 2020) and was therefore included in our search results. In sum, we identified both published and unpublished data with search strategies spanning (a) peer-reviewed published articles, (b) in-press articles, (c) preprints uploaded to repositories, (d) unpublished dissertations and theses, (e) conference materials, and (f) research grants and fellowship awards.

We scanned the abstracts and full texts of all articles according to our inclusion and exclusion criteria, and separated them into articles that investigated the effect of sleep deprivation after learning, and those that investigated sleep deprivation before learning. Figure 1 displays a screening process flowchart showing that after exclusions were removed, 130 effect sizes (extracted from 45 reports) were included in the sleep deprivation after learning meta-analysis and 55 effect sizes (extracted from 31 reports) were included in the sleep deprivation before learning meta-analysis. The number of effect sizes included in each meta-analysis is greater than the number of full-text articles that fit our inclusion criteria. The reason for this is that several studies measured performance differences between a sleep deprivation and sleep control group using multiple tasks, multiple conditions (e.g., stimulus valence or procedural instructions), and across multiple time points. Effect sizes were calculated for each of these data sets within an article because each variation represents a different, yet correlated, measurement of the impact of sleep deprivation on memory. However, there were some studies that used multiple outcome measures to assess performance in a single task (e.g., accuracy and reaction time). Given that multiple outcome measures within the same task are different ways of assessing the same manipulation, we chose only one outcome measure for calculating an effect size in these instances, according to the following hierarchy from most to least preferred outcome measure: accuracy as measured by retention performance (i.e., performance change from training to test), accuracy at test only, reaction time measured by retention performance (i.e., performance change from training to test), and reaction time at test only. Further, in recognition tasks, if both signal detection analyses and analyses based on proportion correct were reported, we chose to include the signal detection measure only. For example, if a study reported both d-prime and reaction times in a recognition memory task (e.g., Tamminen et al., 2020), we only used the d-prime data.

A list of studies included in the two meta-analyses and their key properties can be found in Supplemental Appendix B (studies investigating sleep deprivation after learning) and Supplemental Appendix C (studies investigating sleep deprivation before learning), as well as at osf.io/5gjvs/.

Inclusion/Exclusion Criteria

To select relevant studies, we applied the following inclusion/exclusion criteria.a Participants had to be healthy adults aged 18 years and older.

b Studies must have included, as a primary independent variable, a manipulation of sleep deprivation that was a minimum of one night of total sleep deprivation with an appropriate sleep control condition consisting of one normal night of sleep. Residency studies (studies conducted in a medical setting) were excluded due to the lack of control over whether total sleep deprivation occurred (sleep deprivation is often reported despite naps having occurred on shift; e.g., Bartel et al., 2004; Guyette et al., 2013). Additionally, studies using sleep restriction protocols, which involve multiple nights of limited sleep duration rather than one or more nights of no sleep, were excluded because the neural and cognitive effects of sleep restriction may differ from those caused by total sleep deprivation (Banks & Dinges, 2007; Lowe et al., 2017).

c Studies must have included, as a primary dependent variable, at least one measure of learning or long-term memory where the task was described in sufficient detail to ascertain which cognitive function it assessed.

d For the meta-analysis investigating sleep deprivation after learning, the cognitive task must have had a single encoding phase and a retrieval phase(s) that were temporally separated by either a period of sleep deprivation or an equivalent period of sleep. For the meta-analysis investigating sleep deprivation before learning, the single encoding phase and the retrieval phase(s) must have been temporally separated by a retention interval that had a minimum duration of at least 1 min, rather than being part of the same task session. The reason for this criterion is that our meta-analyses aimed to investigate effects of sleep deprivation on learning and long-term memory. The inclusion of studies with temporally indistinct encoding and retrieval phases would have included short-term and working memory tasks that form a separate body of literature (Lim & Dinges, 2010), the analysis of which was beyond the scope of these meta-analyses.

e In cases in which studies assessed the effects of other interventions (e.g., caffeine; Kilpeläinen et al., 2010) in ameliorating sleep deprivation effects, studies were included only if data could be obtained from the control sleep deprivation and control sleep groups. This criterion was included because the goal of the current meta-analyses was to assess effects of sleep deprivation in the absence of alertness-promoting strategies.

f Studies must have reported sufficient statistical detail to calculate effect sizes (means, SD, F, and t). When statistical details were not reported in the text, we either contacted corresponding authors to request relevant data or we extracted the data needed from published figures in the article using WebPlotDigitizer (Rohatgi, 2019).

Methodological Quality

Through our survey of the literature, it became clear that sleep deprivation studies differ considerably in various aspects of methodological rigor (e.g., lack of control over adherence to sleep manipulations in the sleep deprivation and sleep control groups; Fischer et al., 2002 vs. complete control; Chatburn et al., 2017). For this reason, we assessed the methodological quality of each study entered into our meta-analyses and included this in our moderator analyses.

To assess methodological quality, we developed a 22-item checklist based on criteria for standard sleep deprivation experiments (e.g., preexperimental sleep monitored using actigraphy and exclusion of sleep disorders) and more general experimental psychology experiments (e.g., a priori power analysis and study design). For each item on the checklist, studies were scored with either a zero or a one according to whether they satisfied the criterion. To transform the total methodological quality score for each study into a risk of bias that reflects a rank of all the studies on a common scale, we normalized the total scores by dividing each study’s total methodological quality score by the maximum total methodological quality score that was achieved among all studies (Stone et al., 2020). Lower values imply lower ranked studies (minimum score of 0) and higher values imply higher ranked studies (maximum score of 1) relative to the best study. The full methodological quality checklist can be found in Supplemental Appendix A.

Given that the checklist items form a multidimensional scale, the items were clustered according to the Downs and Black’s (1998) instrument for assessing methodological quality, which assesses five types of bias: “reporting,” “internal validity—bias,” “internal validity—confounding,” “power,” and “external validity.” The “reporting” cluster determines whether sufficient information is provided to make an unbiased assessment of study findings. In our methodological quality checklist, the items in this cluster referred to the reporting of exclusion criteria for participant characteristics (e.g., “Did the study exclude participants with a history of sleep disorders?”). The “internal validity—bias” cluster assesses whether biases were present in the intervention or outcome measure that would favor one experimental group [e.g., “Was interference for the sleep deprivation group low (nondemanding activities given and monitored in the lab)?”]. The “internal validity—confounding” cluster assesses whether biases were present in the selection and allocation of participants (e.g., “For within-group studies, was the order of deprivation and control conditions counterbalanced?”). The “power” cluster assesses whether a study used a priori power analyses to avoid Type II errors (e.g., “Did the study report an a priori power analysis with power set at 80% or higher and an α at .05 or lower?”). The Downs and Black’s (1998) “external validity” cluster determines the extent to which findings can be generalized to the population from which a sample was taken (e.g., “Were the staff, places, and facilities where the patients were treated, representative of the treatment the majority of patients receive?”; Downs & Black, 1998, p. 383). Since the items in this cluster were designed for clinical intervention studies with nontypical populations, we dropped the external validity cluster from our checklist. In line with Cochrane Collaboration recommendations (Higgins et al., 2011), the four clusters in our methodological quality checklist (hereon referred to as reporting, bias, confounding, and power) were then included in moderator analyses. The percentage of studies that passed on each item of the quality checklist for both Meta-Analysis 1 and Meta-Analysis 2 can be found in Supplemental Appendix D. Total methodological quality scores for each study, as well as the item-level ratings, can be found at osf.io/5gjvs/.

Effect Size Calculation

Information on study means, standard deviation, and effect sizes for each item, as well as formulas used to calculate effect sizes, can be found at osf.io/5gjvs/. We report the standardized mean difference in task performance between a sleep deprivation and sleep control group, with positive values indicating that sleep deprivation influenced learning and memory such that performance was significantly worsened compared to a sleep control group. For studies with independent samples (between-subjects designs), we computed Cohen’s d s based on the means and variance reported in each study for the sleep and sleep deprivation group. For within-subject designs, in which participants took part in both the sleep deprivation and sleep control conditions, we calculated Cohen’s d av , as recommended by Lakens (2013).

Data Analysis

Overall Meta-Analytic Effect Size

All analysis code can be found at osf.io/5gjvs/. To analyze whether there was an overall meta-analytic effect of sleep deprivation versus overnight sleep on memory performance, we fitted a multilevel random-effects model using the R package metafor (Viechtbauer, 2010). A random-effects model allows for inconsistencies between effect sizes from varying study designs, assuming systematic variability between effect sizes in addition to random sampling error. A random-effects model therefore provides more conservative effect size estimates than a fixed-effect model (Borenstein et al., 2010). A multilevel model allows for the inclusion of both within-study effect sizes and between-study effect sizes (Assink & Wibbelink, 2016). Many experiments included in the meta-analysis report multiple dependent effect sizes, such as results from multiple test sessions, multiple within-group experimental conditions (e.g., performance on emotional vs. neutral stimuli), or multiple outcomes (e.g., a procedural and declarative memory task). Including multiple dependent effect sizes from the same experiment violates the assumption of data independence assumed in a typical random-effects model. A multilevel meta-analysis accounts for such dependencies by modeling both within-study and between-study effects. Thus, we were able to model variance accounted for by (a) random error, (b) within-study differences among effect sizes within the same experiment, and (c) between-study differences across different experiments.

Heterogeneity

To investigate whether moderating variables may influence the size of the effect of sleep deprivation, we examined heterogeneity within the data set using the Q test (Cochran, 1954). The Q test indicates whether there is heterogeneity within the data set and is calculated by the weighted sum of the squared deviations of individual study effect estimates and the overall effect across studies. Significant heterogeneity suggests that some of the variance within the data set may not be due to random sampling error, and thus moderating variables may influence the effect. Since we were interested in both the within-study and between-study variance, we ran two separate one-sided log-likelihood-ratio tests. As such, the fit of the overall multilevel model was compared to the fit of a model with only within-study variance and to a model with only between-study variance. This allowed us to determine whether it was necessary to account for both within- and between-study variances within our model.

Assink and Wibbelink (2016) suggest that such log-likelihood ratio tests may be subject to the issues of statistical power when the data set comprises a small number of effect sizes. Low statistical power may lead to nonsignificant effects of heterogeneity when in fact there is variance within or between studies. To account for this, it is recommended to also calculate the I 2 statistic, which indicates the percentage of variation across studies that is due to heterogeneity and that which is due to random sampling error (Higgins & Thompson, 2002). Hunter and Schmidt (2004) suggest the 75% rule, such that if less than 75% of overall variance is attributed to sampling error, then moderating variables on the overall effect size should still be examined. Using the formula of Cheung (2014), we calculated the percentage of variance that can be attributed to each level of our model.

However, although I 2 reports the proportion of variation in observed effect sizes, it does not provide us with absolute values that tell us the variance in true effects (Borenstein et al., 2017). Thus, as recommended by Borenstein et al. (2011), we report the τ2, which provide an estimate of the true effect size, and we report prediction intervals, which indicate that 95% of the time, effect sizes will fall within the range of those prediction intervals.

Publication Bias

To assess publication bias, we first examined a contour enhanced funnel plot. Funnel plots show each effect size plotted against its standard error, with contour lines corresponding to different levels of statistical significance. If studies are missing almost exclusively from the white area of nonsignificance, then there may be publication bias. If studies are missing from areas of statistical significance, the bias is likely due to other causes such as poor methodological quality, true heterogeneity, chance, or the bias may be artifactual (Johnson, 2021; Sterne et al., 2011). We also conducted a variation of Egger’s regression test for funnel plot asymmetry (Egger et al., 1997) that can be conducted with multilevel meta-analyses.

Results

Meta-Analysis 1: Sleep Deprivation After Learning

This meta-analysis summarizes research from 45 reports investigating effects of sleep deprivation after learning (130 effect sizes) published in English between 1994 and 2020 across a total of 1,616 participants. All reports used healthy adult populations and deprived participants of one night of sleep postlearning. Notably, two reports from this meta-analysis also report data that are relevant to the sleep deprivation before learning meta-analysis (Fischer et al., 2002; Tamminen et al., 2020). See Table 1 for central tendencies and frequency data for moderator and descriptive variables of studies included. The table shows that this literature is heavily biased toward young adults, severely limiting conclusions that can be drawn about older age groups. The literature predominantly uses between-groups designs rather than the statistically more powerful within-group designs, partly explaining and exacerbating the low power highlighted later in our analysis. Recognition memory and recall memory tasks are the most often employed measures of memory, and most of the literature probes declarative memory rather than procedural memory. We return to these memory type distinctions in our moderator analyses. Most studies used human observation to ensure participants in the sleep deprivation condition did not sleep during the night, but few ensured that they did not sleep during the day to the same standard. Low compliance during the day could possibly dilute the effect size. Finally, most but not all studies allowed recovery sleep after deprivation. We return to this in the moderator analyses.

Overall Meta-Analytic Effect Size

The overall effect size for the mean difference in memory performance between the sleep deprivation and sleep control group, measured by Hedges’ g, was 0.277 (SE = 0.050), indicating a small-to-medium effect according to Cohen’s categorization, and a significant difference from zero, 95% CI [0.177, 0.377], p < .001. Figure 2 displays a forest plot of the effect sizes. See Supplemental Appendix B for a summary of all studies included in the meta-analysis.

Some of the variance within the data set could not be explained by random error, highlighted by overall significant heterogeneity, Q(129) = 244.891, p < .001. An analysis of heterogeneity of between-study variance (Level 2) revealed a significant difference between a full and a reduced model (p < .001), suggesting significant variability between studies. An analysis of heterogeneity of within-study variance (Level 3) also revealed a significant difference between a full model and a reduced model (p < .001), suggesting significant variability between within-study effect sizes. We further calculated the I 2 statistic, which indicates the percentage of variance that could be attributed to each level of the model. Using the formula from Cheung (2014), approximately 52% of variance can be attributed to sampling error, 14% to within-study variance, and 34% to between-study variance. Next, we calculated τ2, which provides a measure of the variance of the true effects; τ2 = .026 for within-study variance, and τ2 = .061 for between-study variance. Prediction intervals indicated that 95% of effect sizes would fall in the range of −0.316 and 0.870.

Based on the significant heterogeneity between studies, the large prediction intervals, as well as the 75% rule, such that moderators should be explored if less than 75% of the variance can be attributed to random sampling error (Hunter & Schmidt, 2004), we therefore explored the effect of potential moderating variables on the direction of the effect.

Publication Bias

Figure 3 shows a funnel plot of the effect sizes. Visual inspection of the funnel plot indicates that effect sizes are not evenly distributed across the funnel plot, raising the potential for publication bias in which studies reporting a positive effect are more likely to be published. Egger’s regression test reveals significant funnel plot asymmetry (z = 2.297, p = .022), supporting this assessment of the funnel plot. Further visual inspection of the funnel plot reveals two potential outlier effect sizes in the area of high statistical significance; these potential outliers are characterized by large effect sizes and large standard error (therefore smaller sample sizes). These large effect sizes on the right-hand side of the plot suggest that there may be a bias in this literature toward publishing significant effects, regardless of the precision with which the study effect size can be estimated. However, the presence of multiple studies in the area of nonsignificance suggests other biases may also contribute to the asymmetry.

Because Egger’s test indicates the presence of publication bias, we sought to quantify the impact of this bias on the estimated effect size. We conducted a trim-and-fill analysis (Duval & Tweedie, 2000), which calculates potential missing effect sizes to create a symmetric funnel plot and then provides an adjusted overall meta-analytic effect size based on this funnel plot symmetry. Although this is a well-used method to assess publication bias, it assumes that effect sizes are independent of each other. The current meta-analysis uses a multilevel approach, with dependencies between some effect sizes. The adjusted effect size should therefore be considered a preliminary estimate. The trim-and-fill method estimated 12 missing studies from the left-hand side of the funnel plot. With these effect sizes included, the adjusted overall meta-analytic effect size was smaller than the original effect size of g = 0.277, although it was still significantly greater than zero, Hedges’ g = 0.166, SE = 0.041, 95% CI [0.086, 0.247], p < .001.

Outlier Analysis

We explored whether outliers and influential cases may have significantly influenced the meta-analytic effect size. To identify the presence of outliers, we identified any effect sizes with studentized residuals greater than or smaller than three, which identified one effect size as an outlier (Albouy, Sterpenich, et al., 2013). However, an outlier may not necessarily influence the size of the overall effect (Viechtbauer & Cheung, 2010). Therefore, based on suggestions by Viechtbauer and Cheung, we conducted influential case analyses, to identify any effect sizes that exerted a significant influence on the size of the overall meta-analytic effect. We measured Cook’s distance to examine the influence of deleting each study on the overall size of the effect, and DFBETAs to examine the effect of deleting each study on individual parameter estimates. Cook’s analysis identified a further one effect size that was found to be an influential case (Darsaud et al., 2011, Know judgements). Removal of the outlier and influential case reduced the overall meta-analytic effect size to 0.271 (from 0.277). Since moderator analyses examine smaller subsets of effect sizes, we removed these two specific effect sizes from all moderator analyses conducted.

Moderator Analysis

We introduced four categorical moderating variables and analyzed the effect of each moderator separately on the size of the effect of sleep deprivation on learning and memory: (a) whether it was a declarative (k = 108) or procedural (k = 20) memory task, (b) for declarative tasks, whether task type was recall (k = 42) or recognition (k = 59), (c) whether participants received one or more recovery nights of sleep (k = 83) or no recovery sleep (k = 45), and (d) for those studies that investigated emotionality, whether the stimuli were emotional (k = 31) or neutral (k = 20). Supplemental Appendix B shows the classification of each study on these dimensions.

Whether participants received a recovery night of sleep before the test session as a moderator had a significant effect, Q(1) = 10.496, p < .001. Thus, we ran separate effect size analyses for those studies where participants had a night of recovery sleep and those that did not. For those studies that had one or more nights of recovery sleep, there was a small effect of sleep deprivation on learning and memory, Hedges’ g = 0.176 (SE = 0.058), which is significantly different from zero, 95% CI [0.060, 0.292], p = .003; Q(82) = 133.766, p < .001. For those studies that did not have a night of recovery sleep, the effect size was larger, Hedges’ g = 0.410, SE = 0.044, 95% CI [0.320, 0.499], p < .001; Q(44) = 50.042, p = .246.

Whether the task probed declarative or procedural memory also had a significant moderating effect, Q(1) = 5.301, p = .021. We therefore ran separate effect size analyses for those studies that implemented a declarative memory task and those that implemented a procedural memory task. For those studies with a declarative memory task, there was a small effect of sleep deprivation on learning and memory, Hedges’ g = 0.218 (SE = 0.055), which is significantly different from zero, 95% CI [0.109, 0.327], p < .001; Q(107) = 174.802, p < .001. For those studies with a procedural memory task, the effect size was larger, Hedges’ g = 0.449, SE = 0.083, 95% CI [0.276, 0.623], p < .001; Q(19) = 24.794, p = .167.

Since we found a significant moderating effect of both recovery sleep and task type (declarative or procedural), we ran a further analysis to investigate whether there was an interaction between the two significant moderators. The analysis revealed no significant interaction between recovery sleep and memory type, Q(1) = 0.804, p = .370, suggesting that whether participants received recovery sleep or not affected declarative and procedural memory task performance in a similar way. Whether studies used a recall or recognition task did not have a significant effect on the size of the effect of sleep deprivation on learning and memory. Studies using a recall task had a mean effect size of Hedges’ g = 0.209, SE = 0.082, 95% CI [0.045, 0.374], p = .014; Q(41) = 76.317, p < .001, and studies with a recognition task had an overall effect size of Hedges’ g = 0.175, SE = 0.077, 95% CI [0.021, 0.330], p = .027; Q(58) = 91.950, p = .003. Effect sizes associated with emotional and neutral stimuli were also not significantly different, with an overall effect size of Hedges’ g = 0.251, SE = 0.080, 95% CI [0.084, 0.417], p = .005; Q(19) = 25.789, p = .136, for studies using neutral stimuli, and an overall effect size of Hedges’ g = 0.207, SE = 0.085, 95% CI [0.033, 0.380], p = .021; Q(30) = 41.888, p = .073, for emotional stimuli.

We then introduced four continuous moderating variables and analyzed the effect of each moderator separately on the size of the effect of sleep deprivation on learning and memory: (a) methodological quality reporting cluster, (b) methodological quality bias cluster, (c) methodological quality confounding cluster, and (d) statistical power to find the mean effect size established in the meta-analysis (g = 0.277). Since methodological quality was divided into clusters in our methodological quality checklist, we introduced these clusters (reporting, bias, and confounding) as moderators. We did not include the power cluster as a moderator, since the majority of studies did not calculate power and thus scored zero on this cluster, with only one study (contributing eight effect sizes) providing a power analysis. For each of the methodological quality clusters, we created a meta-analytic scatter plot using the metafor package (Viechtbauer, 2010), showing the Hedges’ g of each individual study plotted against each moderator (see Figure 4). The figure shows that an effect size of zero falls within the 95% confidence interval in the reporting cluster for studies scoring 0.8 or higher, suggesting that these studies show no effect of sleep deprivation while the lower scoring studies do. Consistent with this observation, the reporting cluster was a significant moderator, Q(1) = 9.214, p = .002. Visual inspection of the plot for the confounding cluster suggests that studies with scores of 0.3 or lower on this cluster may not show an effect of sleep deprivation. However, this cluster did not show a statistically significant moderating effect, perhaps because there were no studies that scored below 0.3 on this cluster. Bias did not show a significant moderating effect either.

To assess the achieved statistical power of each individual experiment to detect the mean meta-analytic effect size, we conducted a post hoc power analysis in G*Power (Faul et al., 2007). For each study, we calculated the power to detect the mean meta-analytic effect size (g = 0.277), as well as the power to detect the 95% upper and lower confidence intervals of the effect size. The distribution of the mean power and lower and upper confidence interval bounds of the power estimate are plotted in Figure 5. We found the mean power to find the average meta-analytic effect to be 13.98% (SD = 4.60%, range = 7.2%–30.2%). The moderator analysis revealed no significant effect of power on the size of the meta-analytic effect. All moderator analyses are reported in Table 2.

Meta-Analysis 2: Sleep Deprivation Before Learning

This meta-analysis summarizes research from 31 reports investigating effects of sleep deprivation before learning (55 effect sizes) published in English between 1989 and 2020 across a total of 927 participants. All reports used healthy adult populations and deprived participants of one night of sleep prior to learning. Notably, two reports from this meta-analysis also include data that are relevant to the sleep deprivation after learning meta-analysis (Fischer et al., 2002; Tamminen et al., 2020). See Table 3 for central tendencies and frequency data for moderator and descriptive variables of reports included. Again, the literature mostly involves young adults, leaving a gap in our understanding of how the effects of interest change with age. The discrepancy between use of between- and within-group designs is lower here than in the first meta-analysis, and recognition memory and recall memory tasks are roughly equally represented. However, nearly all studies look at declarative memory, suggesting that more work on procedural memory is needed. While most studies ensured compliance with the sleep deprivation manipulation with direct observation at night, few did so during the preceding day, potentially diluting the impact of sleep deprivation.

Overall Sleep Deprivation Effect Size

The overall effect size for the mean difference in memory performance between the sleep deprivation and sleep control group, measured by Hedges’ g, was 0.621 (SE = 0.074), indicating medium to large effect according to Cohen’s categorization, and a significant difference from zero, 95% CI [0.473, 0.769], p < .001. Figure 6 provides a forest plot of the effect sizes. See Supplemental Appendix C for a summary of all studies included in the meta-analysis.

Some of the variance within the data set could not be explained by random error, highlighted by overall significant heterogeneity, Q(54) = 118.166, p < .001. An analysis of heterogeneity of between-study variance (Level 2) also revealed a significant difference between a full and a reduced model (p < .001), suggesting significant variability between studies. An analysis of heterogeneity of within-study variance (Level 3) revealed a significant difference between a full model and a reduced model (p < .001), suggesting significant variability between within-study effect sizes. The I 2 statistic indicates that approximately 41% of variance can be attributed to sampling error, 9% to within-study variance, and 50% to between-study variance. τ2 = .096 for between-study variance, and τ2 = .017 for within-study variance, and prediction intervals indicated that 95% of effect sizes would fall in the range of −0.069 and 1.312. Based on this evidence for heterogeneity, we explored the effect of potential moderating variables on the direction of the effect.

Publication Bias

Figure 7 shows a contour enhanced funnel plot of effect sizes. Similar to Meta-Analysis 1, visual inspection of the funnel plot indicates that effect sizes are not evenly distributed across the funnel plot, raising the potential for publication bias. Egger’s regression test supports this conclusion, indicating significant funnel plot asymmetry (z = 3.363, p < .001). Further inspection of the funnel plot indicates that the majority of effect sizes are clustered toward the right side of the funnel plot. While many of these studies fall in the area of nonsignificance, there appear to be studies missing from the left-hand side of the plot. It is possible these missing studies are due to researchers being unable to publish findings that contradict their hypotheses, and that the bias indicated by Egger’s test may therefore be due to publication bias rather than other types of bias.

Because Egger’s test indicates the presence of publication bias, we conducted a trim-and-fill analysis (Duval & Tweedie, 2000), in the same way as in the first meta-analysis. The trim-and-fill method estimated seven missing studies from the left-hand side of the funnel plot. With these effect sizes included, the adjusted overall meta-analytic effect size was smaller than the original effect size of g = 0.621, although it was still significantly greater than zero, Hedges’ g = 0.463, SE = 0.070, 95% CI [0.326, 0.601], p < .001.

Outlier Analysis

In the same way as the first meta-analysis, we explored whether any outliers and influential cases significantly influenced the size of the effect. We identified any effect sizes with studentized residuals greater than or smaller than three (k = 1; Tempesta et al., 2016, Recognition Task). Following recommendations by Viechtbauer and Cheung (2010), influential case analysis (Cook’s distance and DFBETAs) identified two further effect sizes that may have had a significant influence on the results (Poh & Chee, 2017; Yoo et al., 2007). Removal of the one outlier and two influential cases reduced the overall meta-analytic effect size to 0.525 (from 0.621). We removed these three specific outliers and influential cases from all moderator analyses.

Moderator Analysis

We introduced the categorical moderating variable task type, recall (k = 26) versus recognition (k = 20). We excluded studies that used a different task type, including a recency discrimination task (k = 3), a prototype learning task (k = 2), and a finger-tapping task (k = 1). Analysis of the moderator recall versus recognition revealed that the type of task used did not moderate the size of the effect, Q(1) = 0.028, p = .868. There were only two studies of procedural memory (Fischer et al., 2002; McWhirter et al., 2015) and only five entries where the participants were given a night of recovery sleep (two further entries did not report whether recovery sleep was given). Likewise, only two studies investigated the effects of sleep deprivation on emotional memory (Kaida et al., 2015; Tempesta et al., 2016). Thus, there was insufficient variability within the data set to assess whether one or more nights of recovery sleep, the type of memory (declarative, procedural), and emotionality moderated the size of the sleep deprivation effect.

We tested the influence of the three continuous moderating variables assessing methodological quality (reporting, bias, and confounding), as well as statistical power to detect the meta-analytic effect size, on the size of the sleep deprivation effect. No methodological quality cluster had a significant moderating effect. For each of the methodological quality clusters, we created a meta-analytic scatter plot (metafor package; Viechtbauer, 2010; see Figure 8). We did not include the power cluster as a moderator, since the majority of studies did not calculate power and thus scored zero on this cluster, with only two studies (contributing a total of 10 effect sizes) providing a power analysis.

We then investigated whether statistical power to find the meta-analytic effect moderated the size of the effect of sleep deprivation on memory. In the same way as in the first meta-analysis, for each study, we calculated the power to find the mean meta-analytic effect size, as well as the power to detect the upper and lower confidence interval bounds around the mean. The distribution of power to detect the three estimates is plotted in Figure 9. We found the mean power to find the meta-analytic effect to be larger than in the first meta-analysis (M = 54.77%, SD = 20.81%, range = 21.22%–98.06%). The moderator analysis revealed that power to find the mean meta-analytic effect size did not moderate the effect of sleep deprivation on memory, Q(1) = 3.179, p = .075. All moderator analyses are reported in Table 4.

Discussion

The two meta-analyses presented here aimed to quantify the size of the effect of sleep deprivation after learning and before learning on memory performance. Based on previous evidence for an effect of sleep on both declarative and procedural memories (Klinzing et al., 2019), we predicted that sleep deprivation would have a detrimental effect on learning and memory. We found that sleep deprivation after learning was associated with a mean effect size of g = 0.277. The effect size is positive, indicating that sleep deprivation has a detrimental rather than facilitatory impact on memory, as predicted by theory. Furthermore, the 95% confidence intervals around the mean do not cross zero, indicating that the effect size is statistically significantly higher than zero. For sleep deprivation before learning, we found an average effect size of g = 0.621. The effect size is positive, indicating that sleep deprivation before learning impairs rather than facilitates memory, as predicted by theory (e.g., Cirelli & Tononi, in press; Tononi & Cirelli, 2012). The 95% confidence intervals around the mean do not cross zero, again indicating that the effect size is statistically significantly higher than zero. Following Cohen’s guidelines for categorizing effect sizes a small (0.20), medium (0.50), and large (0.8), the effect sizes above would correspond to small-to-medium and medium. However, given that these cutoff points are wholly arbitrary and were only ever intended to be used as a last resort, many now argue that effect sizes should be interpreted in the context of typical effect sizes observed in the relevant literature (Correll et al., 2020; Funder & Ozer, 2019). According to Brysbaert (2019), an effect size of d = 0.40 represents an average effect size in experimental psychology and has practical and theoretical relevance. Putting our meta-analytic effect sizes into this context, it appears that sleep deprivation before learning has an effect size somewhat larger than the average effect size in experimental psychology, while sleep deprivation after learning has a somewhat smaller than average effect size, although the latter varies as a function of both recovery sleep and memory type (declarative vs. procedural), as discussed in detail below.

Theory-Based Mediators

Despite the wide range of literature examining an effect of sleep deprivation on memory performance, this is, to our knowledge, the first time that the size of this effect has been formally quantified. A benefit of meta-analyses is that they allow for the investigation of potential moderating factors that may differentially influence the size of the meta-analytic effect. For deprivation after learning, we were able to investigate whether the first night of sleep is essential for the consolidation of newly acquired memories or whether a later sleep opportunity can compensate for the first night of sleep deprivation. We found that studies where memory was tested immediately after one night of sleep deprivation and before recovery sleep showed a significant sleep deprivation associated memory deficit (g = 0.410). Critically, those studies that had one or more nights of recovery sleep prior to retrieval also showed a small but statistically significant memory deficit (g = 0.176). Thus, memory impairments caused by sleep deprivation during the first postencoding night were still present but less severe when recovery sleep occurred before testing. On the one hand, this finding suggests that the first night of sleep after learning is important as its disruption is still felt even after recovery sleep. On the other hand, it also suggests that recovery sleep can to some extent mitigate the disruption of the first night of sleep by reducing the effect size by about 50%. While these data are consistent with theories arguing that, for hippocampal-dependent memories at least, the hippocampus may act as a buffer, retaining newly learned information until an offline consolidation opportunity is available (Schönauer et al., 2015), the idea that consolidation processes can be spread over multiple nights of sleep is yet to be explicitly tested.

It is also difficult to establish the extent to which the smaller effect of sleep deprivation after recovery sleep on memory is due to the occurrence of a delayed consolidation opportunity or due to effects of fatigue being diminished. Recent work has suggested that fatigue at time of test might have little or no detrimental impact on tasks assessing long-term memory. Schönauer et al. (2015) found that sleep deprivation before a recall task did not impair memory for previously encoded and consolidated word pairs. Furthermore, despite a difference in the size of the effect of sleep deprivation, it is important to note that we still see a significant detrimental effect of sleep deprivation after learning even when a later sleep opportunity is permitted, albeit a smaller effect. An account based on fatigue alone is insufficient to explain this finding. Another potential alternative explanation for the decrease in effect size after recovery sleep could be based on interference. When tested after one night of sleep or sleep deprivation, participants in the sleep group will have experienced little interference from subsequent cognitive activity after learning. A large difference between the groups at this point could be due to sleep protecting new memories from interference rather than due to active consolidation processes. After one or more nights of recovery sleep, both groups will have experienced some degree of interference, and this could explain the reduction in the effect size. Further research is needed to adjudicate between these different accounts that could both contribute to the effect sizes we have observed.

For deprivation after learning, we also found that whether the task type was declarative or procedural had an effect on the size of the deprivation effect. Although both declarative and procedural tasks elicited a significant effect, a moderator analysis indicated that those studies implementing procedural memory tasks had significantly larger effect sizes on average (g = .449) than declarative tasks (g = .218). That both declarative and procedural memory tasks showed detrimental effects of sleep deprivation was unsurprising, given that a benefit of sleep has been observed for both declarative memories (e.g., Gais & Born, 2004; Talamini et al., 2008; Wagner et al., 2006) and procedural memories (Korman et al., 2007; Schönauer et al., 2014; Walker et al., 2005). Our findings are also consistent with recent studies showing that sleep is beneficial even in tasks that do not require the hippocampus at learning (e.g., Schapiro et al., 2019). Although the current meta-analysis indicates a detrimental effect of sleep deprivation after learning on both declarative and procedural memories, the exact mechanisms that drive these effects are still debated, and thus it is unclear why procedural memories may show larger sleep deprivation effects. According to active systems consolidation theory, hippocampal-dependent declarative memories benefit from repeated reactivation of newly learned memories during sleep, supporting the strengthening of memory representations in the neocortex (Born & Wilhelm, 2012; Walker & Stickgold, 2006). However, procedural memories that rely on implicit learning are unlikely to be dependent on such hippocampal–neocortical representations. It has been theorized that such implicit memories require more immediate offline consolidation to see a beneficial effect of sleep (Schönauer et al., 2015; Stickgold et al., 2000). Thus, it may be that without an immediate sleep opportunity, the detrimental effects of sleep deprivation have a larger impact on procedural memory consolidation, whereas declarative memory consolidation is less impacted by the lack of an immediate sleep opportunity. However, we found no significant interaction between recovery sleep and task type, suggesting that for both declarative and procedural tasks, lack of an immediate sleep opportunity increased the size of the effect of sleep deprivation. Thus, recovery sleep had a similar impact on both procedural and declarative task performance, and procedural tasks elicited larger effect sizes than declarative tasks, regardless of whether recovery sleep occurred.

For deprivation after learning, we found no effect of emotional versus neutral memory on the size of the meta-analytic effect. Although some studies do suggest a preferential effect of sleep for emotional memories (e.g., Payne & Kensinger, 2010; Wagner et al., 2001), our findings join two recent meta-analyses that report no overall preferential effect of sleep on emotional memory consolidation (Lipinska et al., 2019; Schäfer et al., 2020). These existing meta-analyses focussed on emotional memory and were able to uncover mediators that may reveal boundary conditions for the preferential effect; however, the number of studies in this domain is still low and more research is needed to establish the reliability of the effect.

For both deprivation after learning and deprivation before learning, we found no effect of the recall versus recognition moderator on the size of the meta-analytic effect. This is in contrast to some previous studies investigating the beneficial role of sleep on memory that have found a differential effect of recall versus recognition testing, and in contrast to the meta-analysis of Newbury and Monaghan (2019), which looked at sleep studies using the DRM paradigm. Although performance on recall tasks repeatedly benefits from sleep, performance on recognition tasks has sometimes been found to show little or no offline consolidation benefit (Ashton et al., 2018; Diekelmann et al., 2009; Drosopoulos et al., 2005; Gais et al., 2006; Hu et al., 2006). It is posited that, although recall tasks rely on explicit, hippocampal-dependent memory, recognition tasks could include both an explicit recollection and implicit familiarity element (Jacoby, 1991), only the former of which benefits from sleep-associated consolidation. Thus, the mechanisms by which these two types of memories are consolidated may be different. Despite this, the present meta-analyses provide no evidence to suggest that performance on recall and recognition tasks are differentially affected by sleep deprivation either before or after sleep. Whether this finding extends to sleep paradigms other than total sleep deprivation remains to be established.

The null effects from our moderator analyses should be treated with caution, however, as we may not have adequate statistical power to detect smaller moderator effect sizes. Hempel et al. (2013) suggest that power to detect moderator effects is dependent on a combination of the amount of residual heterogeneity within the data set, the number of studies in the data set, the number of participants in the included studies, and the ratio of studies in the conditions compared against each other. Based on power simulations, Hempel et al. (2013) provide estimations of the approximate number of studies and participants required to detect categorical moderator effects of different effect sizes. We used data from these simulations to retrospectively assess the power of our moderator analyses to detect an effect. Since Hempel et al.’s simulations are not based on multilevel meta-analyses, the below estimates should be treated with caution when applied to our analyses and only considered as indicative.

For our deprivation after learning analysis, residual heterogeneity was τ2 = .026 for within-study variance, and τ2 = .061 for between-study variance. Therefore, based on a τ2 of between 0 and 0.1, the simulations suggest that the moderator recall versus recognition was powered to detect an effect of around 0.2–0.3 (based on 100 trials, 20 participants per study, at 80% power). The emotionality moderator was powered to detect only large moderator effects of 0.3–0.4 (based on 50 trials, 20 participants per study, 80% power). For the deprivation before learning analysis, residual heterogeneity was τ2 = .096 for between-study variance, and τ2 = .017 for within-study variance. The simulations suggest that the moderator analysis of recall versus recognition was powered to detect only a large effect size of between 0.3 and 0.4 (based on 50 trials, 20 participants per study, at 80% power). Therefore, it appears that our moderator analyses were not sufficiently powered to detect small moderator effects and the null findings in these analyses should be considered preliminary. These analyses need to be repeated as more evidence accumulates over time.

There are other moderators that would be valuable to account for to increase the precision of our meta-analytic effect size, but that we could not include in our analyses due to the small number of studies available. For example, some studies included in the meta-analysis involved manipulations that the authors expected to reverse or eradicate the detrimental effect of sleep deprivation. Kolibius et al. (2021) predicted that large amounts of encoded information (640 word pairs) would increase forgetting in the sleep group compared to a sleep-deprived group. Similarly, Feld et al. (2016) hypothesized that those in a high memory load condition (360 word pairs) should no longer show a sleep benefit compared to a sleep-deprived condition. Vargas et al. (2019) examined memory for emotionally negative and neutral objects and backgrounds, but only predicted an impact of sleep deprivation on neutral objects. It is possible that the inclusion of studies such as these (or conditions within those studies where no sleep deprivation effect is predicted) may have artificially reduced our meta-analytic effect size. A mediator analysis would be the appropriate solution to establish whether this was the case, but the small number of relevant studies prevents this for now.

Quality-Based Moderators

The meta-analyses in this article suggest that there is a detrimental effect of sleep deprivation on learning and memory, and it is observed across a range of methodologies. However, our meta-analyses identified a number of potential limitations of the available data sets in this domain. Methodological quality scores ranged from 4 to 19 out of 22 in the studies investigating deprivation after learning; and they ranged from 7 to 19 in the studies investigating deprivation before learning.

We must be cautious in the way that we interpret the effects of methodological quality on the size of the effect of sleep deprivation. Valentine (2009) argues that methodological scales of this nature frequently lack operational specificity (e.g., that each item deserves equal weight) and include questions that are unclear. In an attempt to increase the validity of our methodological quality checklist, we designed our checklist based on the Downs and Black checklist (1998), with modified questions relevant to sleep studies. For the first meta-analysis, we found a significant mediating effect of the reporting cluster of our methodological quality checklist on the size of the sleep deprivation effect, Figure 4 shows that studies scoring highest on this cluster show no effect of sleep deprivation while the lower scoring studies do. The items in the reporting cluster are predominantly concerned with the number and nature of exclusion and inclusion criteria used in the study. It therefore appears that the studies showing higher effect sizes may have employed fewer such criteria. However, some of the scores on this cluster may be underestimated due to incomplete reporting. For example, studies stating that they only recruited healthy participants may have used other sleep-related inclusion and exclusion criteria, such as excluding participants who were taking medication that affects sleep or those who had recently traveled between time zones, without reporting these and may have scored higher on this cluster had these criteria been reported. We found no mediating effect of any cluster of methodological quality on the size of the effect of sleep deprivation for the second meta-analysis. Given that only one cluster of the quality score influenced the size of the effect in the first meta-analysis, and no clusters had a significant effect in the second meta-analysis, our effect size estimates are unlikely to be substantially biased by variation in methodological quality.

Taking a broader qualitative view of our quality checklist, we note that only one of the analyzed studies was preregistered, and only three justified their sample size with an a priori power analysis. Given that preregistration has become a mainstream practice only in the past few years (Nosek & Lindsay, 2018), and that an a priori power analysis is part of the preregistration process, the low numbers here are unsurprising and are likely in line with the current broader field of experimental psychology. The key quality measures on study design were met by the clear majority of studies (e.g., equal group sizes, random allocation to groups or counterbalancing of conditions).

Power-Based Moderators

In the current meta-analyses, we calculated statistical power to find the meta-analytic effect size for each experiment and assessed whether statistical power significantly influenced the size of the effect of sleep deprivation. For sleep deprivation after learning, mean statistical power to find the meta-analytic effect size was just 14%; for sleep deprivation before learning, it was higher though still far less than optimal at 55%. Given that power is a function of the effect size, sample size, and the statistical test being employed, the difference in obtained power across the two research questions is understandable: As the effect size decreases, power to detect it decreases if sample size is held constant. Overall, these figures are closely in line with the broader field: For example, Szucs and Ioannidis (2017) found that within psychology and cognitive neuroscience, mean power to detect small, medium, and large effects (in Cohen’s terms) was 17%, 49%, and 71%, respectively.

Given the current convention that statistical power to find an effect is at 80% or higher (Di Stefano, 2003), it is evident that the majority of the studies in these meta-analyses are underpowered. This is problematic as it increases the uncertainty around our meta-analytical effect sizes. To better understand the consequences of the uncertainty introduced by low power in the studies included in our meta-analyses, we investigated whether statistical power to find the mean meta-analytic effect size influenced the size of the sleep deprivation effect by entering obtained power as a moderator. For example, it might be the case that it is only low-powered studies that show an impact of sleep deprivation, while high-powered studies might show no impact. Such a pattern would suggest that our meta-analytic effect size might be overestimated as a consequence of low power. The opposite pattern would suggest that our effect size has been underestimated due to low power. For deprivation after learning, we found no moderating impact of statistical power on the size of the effect. In other words, both low- and high-powered studies yielded similar effect sizes. However, the validity of this analysis is reduced by the fact that there were no studies in this meta-analysis where power exceeded 33%, and therefore we have no way of knowing what effect sizes could be expected when power is higher. For deprivation before learning, we found a broader range of power extending from about 20% to over 90%. However, once again we found no statistically significant moderating impact of power on the size of the effect.

To gain a more precise estimate of the true effect size, future studies should use the current meta-analytic effect size as a guide in determining sample sizes that will yield high power. Studies planning to look at sleep deprivation after learning and running a two-tailed t-test for a between-subjects design with a sleep versus sleep deprivation manipulation would require a sample size of approximately 410 to have 80% power to detect the meta-analytic effect size. For a within-subjects design, the sample size required would be 105. For studies examining deprivation before learning, a two-tailed t-test with a between-subjects design would require a sample size of 82, whereas a within-subjects design would require a much smaller sample size of 23, to have 80% power to detect the meta-analytic effect size. The above numbers are rough indications only, and lower or higher sample sizes may be appropriate depending on the specific design of the experiment and the statistical analysis approach (Brysbaert, 2019; Lakens & Caldwell, 2021).

It is clear that there is a significant discrepancy between the high-power sample sizes we have estimated above and the sample sizes found in the majority of the studies included in the current meta-analyses. This discrepancy is important as there are severe limitations to the strength of conclusions that can be drawn from underpowered individual studies (see, e.g., Brysbaert, 2019, for a detailed discussion). Fraley and Vazire (2014) described three limitations: (a) underpowered studies are less likely than properly powered studies to detect a true effect; (b) underpowered studies are more likely to yield false-positive findings than properly powered studies; and (c) underpowered studies are less likely than properly powered studies to produce replicable findings. Wilson et al. (2020) further demonstrate that underpowered studies are likely to yield inflated effect sizes. Therefore, the results of any single underpowered study should be treated with caution, and a meta-analytic approach such as ours may be the more useful approach for extracting information from these studies. Yet, small-scale studies are not always completely uninformative; we return to this debate in the Conclusions section.

Publication Bias

Conducting a meta-analysis allows for an estimation of publication bias within the literature. Publication bias is evident when there are a large number of published studies in the direction of the hypothesis, with few nonsignificant published studies (Rosenthal, 1979). This can lead to overestimation of the size of the effect. We found statistically significant evidence of publication bias in both meta-analyses. Adjusting the deprivation after learning effect size for publication bias using the trim-and-fill method changed the effect size from 0.277 to 0.166, and changed the deprivation before learning effect size from 0.621 to 0.463, although these adjusted effect size should be treated with caution given that the trim-and-fill method was not designed for a multilevel approach. Nonetheless, both estimates remained significantly different from zero after the adjustment. To allow for more accurate effect size estimates in future meta-analyses, we suggest researchers in this field should adopt registered reports as an effective way of ensuring all results find their way into published literature.

Limitations

We focused specifically on the effects of total (overnight) sleep deprivation, and thus future meta-analyses are needed to establish whether the effect size is similar in studies using sleep restriction. We chose to concentrate on studies using total sleep deprivation because depriving a participant of all sleep is a stronger test of the hypothesis that sleep benefits memory than depriving them of a single stage of sleep or restricting their sleep for some hours over a period of time, as discussed in the Introduction section. An alternative approach could have been to include restriction studies and to conduct a moderator analysis to establish whether they lead to similar effect sizes as total deprivation. However, many sleep restriction studies in the literature are field studies that lack the rigorous controls we include in our inclusion criteria (e.g., lack of control over hours slept, Deary & Tait, 1987; inappropriate sleep control condition, Piérard et al., 2004), and therefore the number of eligible restriction studies would have been smaller than the number of total deprivation studies. As discussed earlier, such imbalance in number of studies can make moderator analyses insensitive (Hempel et al., 2013).

Our search focused solely on English language reports, thus risking a mono-language bias (Johnson, 2021). This restricts our ability to generalize the results of our meta-analyses to non-English language literature. In particular, by using English language sources only, there is the possibility that our search missed much of the gray literature such as PhD theses and conference abstracts written in other languages. The use of solely English language sources limits our understanding of any possible cross-cultural differences in effects of sleep on memory. Indeed, there are many cross-cultural differences in sleep habits (e.g., Cheung et al., 2021), and although we are not aware of any studies that have systematically compared sleep-associated memory consolidation effects across cultures, our reliance on English language literature means that we would not have captured such differences if they do exist.

We acknowledge that our inclusion criteria restrict our ability to draw conclusions beyond healthy, typical populations. We excluded studies that included participants under the age of 18 and studies that involved participants suffering from sleep disorders or psychiatric disorders. There is growing interest in understanding how sleep-associated memory consolidation in these groups might differ from healthy adults, however (e.g., Hoedlmoser, 2020; Manoach & Stickgold, 2019), and future meta-analyses addressing these questions will be valuable both for theoretical development and practical reasons. Finally, we note that there were 17 studies that we were unable to include in the analyses as the required statistical information was not reported (see Figure 1); unfortunately, the authors of these papers were unable to provide with the necessary data when contacted. Nonetheless, these studies made up a small proportion of the studies we identified as eligible and would be unlikely to change the conclusions we have drawn.

Conclusions

To conclude, the two meta-analyses presented here provide a comprehensive analysis of the impact of sleep deprivation after learning and before learning. The results of the first meta-analysis suggest that depriving participants of the first night of sleep after encoding new information results in lower performance at test, supporting the theories of sleep-associated memory consolidation (e.g., Diekelmann & Born, 2010; McClelland et al., 1995). This effect was larger before than after recovery sleep and larger in procedural memory tasks compared to declarative memory tasks. The results of the second meta-analysis suggest that sleep-deprived participants are able to encode less information than rested controls, supporting the theories that propose that sleep restores memory encoding capacity (e.g., Saletin & Walker, 2012; Tononi & Cirelli, 2012).

We found that levels of statistical power tended to be low, particularly in those studies looking at sleep deprivation after learning in which there was a small estimated effect size. Given that underpowered studies are ubiquitous across disciplines that use human participants (Dumas-Mallet et al., 2017), new ways of interpreting low-powered studies are emerging. One particularly insightful interpretation has recently been offered by Wilson et al. (2020). In short, Wilson and colleagues draw a distinction between “original science” and “replication science.” Original science is roughly science as practiced today, in that it uses Null Hypothesis Significance Testing combined with study designs whose power falls far short of the gold standard of high-N studies. Original science in this formulation serves an important and inexpensive screening function to identify effects that may be true and would therefore benefit from further, more costly examination of replication science. Replication science consists of high-N, highly powered, and costly direct replications of the key studies from original science, vital for verifying the preliminary results of original science. Applying this framework to the literature targeted in our meta-analyses, we propose that there is now sufficient evidence from original science to warrant a move to replication science in this field. No highly powered, preregistered direct replications looking at the role of sleep deprivation in learning and memory have been conducted thus far. The meta-analytic estimates of the relevant effect sizes provided here will facilitate the design of such urgently needed studies, while also allowing better informed sample size choice for continuing original science efforts.

Supplementary Material

10.1037/bul0000348.supp

Table 1 Features of Included Sleep Deprivation After Learning Interventions (k = 130)

Study feature	k	M ± SD	Mdn	Mode	Range	
a Ten effect sizes had 6 months of recovery sleep and were excluded from the table as outliers. One study reported one to six nights of recovery sleep and was excluded from the table due to lack of precision. b Statistical power to detect the meta-analytic effect size of Hedges’ g = 0.277, with α at .05.	
Publication date	130	NA	2012	2015	1994–2020	
Sample size	130	31.84 ± 13.15	28	28	6–78	
Age	54	22.15 ± 1.41	22.30	23.30	18.10–24.30	
% Females	95	56.37 ± 19.04	56.25	50.00	0.00–85.71	
Study design	130					
 Between-groups	104	NA	NA	NA	NA	
 Within-group	26	NA	NA	NA	NA	
Paradigm	130					
 Motor skill	15	NA	NA	NA	NA	
 Recognition	60	NA	NA	NA	NA	
 Recall	42	NA	NA	NA	NA	
 Route learning	4	NA	NA	NA	NA	
 Temporal order	2	NA	NA	NA	NA	
 Mere exposure effect	1	NA	NA	NA	NA	
 Categorization	6	NA	NA	NA	NA	
Stimuli	130					
 Words	36	NA	NA	NA	NA	
 Scenes	30	NA	NA	NA	NA	
 Images	47	NA	NA	NA	NA	
 Sequence	15	NA	NA	NA	NA	
 Instruction	1	NA	NA	NA	NA	
 Trajectory	1	NA	NA	NA	NA	
Emotionality of stimuli	130					
 Neutral	20	NA	NA	NA	NA	
 Emotional	31	NA	NA	NA	NA	
 Not reported	79	NA	NA	NA	NA	
Memory type	130					
 Procedural	21	NA	NA	NA	NA	
 Declarative	109	NA	NA	NA	NA	
Sleep deprivation compliance check	130					
 Human observation of night	107	NA	NA	NA	NA	
 Human observation of day and night	12	NA	NA	NA	NA	
 No human observation	11	NA	NA	NA	NA	
Recovery sleep	130					
 Yes	85	NA	NA	NA	NA	
 No	45	NA	NA	NA	NA	
Nights recovery sleep	74a	3.18 ± 3.02	2.00	2.00	1–13	
Statistical power to detect meta-analytic effect sizeb	130	13.95% ± 5.00	13%	11%	7%–30%	
Quality—reporting	130	0.56 ± 0.21	0.50	0.50	0.00–1.00	
Quality—bias	130	0.74 ± 0.19	0.71	0.71	0.29–1.00	
Quality—confounding	130	0.77 ± 0.15	0.83	0.83	0.33–1.00	

Table 2 Effect of Each Moderator on the Overall Meta-Analytic Effect of Sleep Deprivation After Learning on Memory Performance

Moderator	Variable type	df	Heterogeneity (Q)	p	
* p < .05.	
Recovery sleep (yes vs. no)	Categorical	1	10.496	<.001*	
Task type (declarative vs. procedural)	Categorical	1	5.301	.021*	
Recall versus recognition	Categorical	1	0.115	.734	
Emotionality (emotional vs. neutral)	Categorical	1	0.169	.681	
Quality—reporting cluster	Continuous	1	9.337	.002*	
Quality—bias cluster	Continuous	1	0.989	.320	
Quality—confounding cluster	Continuous	1	0.049	.825	
Power	Continuous	1	0.611	.434	
Recovery sleep × Task type	Categorical	1	0.804	.370	

Table 3 Features of Included Sleep Deprivation Before Learning Interventions (k = 55)

Study feature	k	M	Mdn	Mode	Range	
a One study using recovery sleep only had a 90-min nap opportunity as recovery sleep and was excluded from the table as an outlier. b Statistical power to detect the meta-analytic effect size of Hedges’ g = 0.621, with α at .05.	
Publication date	55	NA	2010	2000/2020	1989–2020	
Sample size	55	30.75 ± 13.82	26	26	12–58	
Age	27	24.55 ± 5.89	22.19	20.70	19.50–47.83	
% Female	42	47.78 ± 22.16	50.00	50.00	00.00–74.36	
Study design	55					
 Between-groups	34	NA	NA	NA	NA	
 Within-group	21	NA	NA	NA	NA	
Paradigm	55					
 Recognition	23	NA	NA	NA	NA	
 Cued recall	14	NA	NA	NA	NA	
 Free recall	12	NA	NA	NA	NA	
 Texture discrimination	1	NA	NA	NA	NA	
 Recency discrimination	2	NA	NA	NA	NA	
 Finger tapping	1	NA	NA	NA	NA	
 Categorization	2	NA	NA	NA	NA	
Stimuli	55					
 Words	24	NA	NA	NA	NA	
 Images	23	NA	NA	NA	NA	
 Prose	3	NA	NA	NA	NA	
 Numbers	1	NA	NA	NA	NA	
 Instruction	4	NA	NA	NA	NA	
Memory type	55					
 Procedural	2	NA	NA	NA	NA	
 Declarative	53	NA	NA	NA	NA	
Sleep deprivation compliance	55					
Human observation of night	42	NA	NA	NA	NA	
 Human observation of day and night	10	NA	NA	NA	NA	
 No human observation	3	NA	NA	NA	NA	
Recovery sleep	55					
 Yes	13	NA	NA	NA	NA	
 No	42	NA	NA	NA	NA	
Nights recovery sleep	12a	6.04	2.00	2.00	2–13	
Statistical power to detect meta-analytic effect sizeb	55	54.77 ± 20.79	54	86	21–98	
Quality—reporting	55	0.61 ± 0.28	0.50	0.50	0.00–1.00	
Quality—bias	55	0.71 ± 0.23	0.71	0.86	0.14–1.00	
Quality—confounding	55	0.81 ± 0.16	0.83	0.83	0.50–1.00	

Table 4 Effect of Each Moderator on the Overall Meta-Analytic Effect of Sleep Deprivation Before Learning on Memory Performance

Moderator	Variable type	df	Heterogeneity (Q)	p	
Recall versus recognition	Categorical	1	0.261	.610	
Quality—reporting cluster	Continuous	1	0.868	.351	
Quality—bias cluster	Continuous	1	0.064	.800	
Quality—confounding cluster	Continuous	1	0.867	.352	
Power	Continuous	1	3.110	.078	

Figure 1 Flowchart Displaying Literature Search Process for the Deprivation After Learning and Deprivation Before Learning Meta-Analyses

Figure 2 Forest Plot Containing Effect Sizes and 95% Confidence Intervals for the Difference in Performance Between a Sleep Deprivation and Sleep Control Group on Memory

Note. Effect sizes to the right indicate an effect of sleep deprivation after learning such that memory was significantly worse than in a sleep control group.

Figure 3 Contour Enhanced Funnel Plot Showing the Hedges’ g Effect Size on the x-Axis, and the Standard Error of Hedges’ g Effect Size on the y-Axis

Figure 4 Meta-Analytic Scatter Plot With Methodological Quality of the Reporting, Bias, and Confounding Clusters Plotted Against Individual Study Effect Size for Meta-Analysis 1

Note. The size of each point is proportional to the weight the study received in the analysis, with larger size indicating larger weight. The solid regression lines represent the effect size predicted by the meta-regression model as a function of each cluster score, with corresponding 95% confidence intervals.

Figure 5 Distribution of Power to Find the Mean Meta-Analytic Effect Size (Green), the Lower Bound of the 95% Confidence Interval Around the Mean (Pink), and the Upper Bound of the 95% Confidence Interval Around the Mean (Blue)

Note. See the online article for the color version of this figure.

Figure 6 Forest Plot Containing Effect Sizes and 95% Confidence Intervals for the Difference in Performance Between a Sleep Deprivation and Sleep Control Group on Memory

Note. Effect sizes to the right indicate an effect of sleep deprivation before learning such that memory was significantly worsened compared to a sleep control group.

Figure 7 Contour Enhanced Funnel Plot Showing the Hedges’ g Effect Size on x-Axis, and Standard Error of Hedges’ g Effect Size on the y-Axis

Figure 8 Meta-Analytic Scatter Plot With Methodological Quality Clusters of Reporting, Bias, and Confounding, Plotted Against Individual Study Effect Size for Meta-Analysis 2

Note. The size of each point is proportional to the weight the study received in the analysis, with larger size indicating larger weight. The solid regression lines represent the effect size predicted by the meta-regression model as a function of each cluster score, with corresponding 95% confidence intervals.

Figure 9 Distribution of Power to Find the Mean Meta-Analytic Effect Size (Green), the Lower Bound of the 95% Confidence Interval Around the Mean (Pink), and the Upper Bound of the 95% Confidence Interval Around the Mean (Blue)

Note. See the online article for the color version of this figure.
==== Refs
References

References marked with *1 indicate studies included in the first meta-analysis (sleep deprivation after learning) and references marked with *2 indicate studies included in the second meta-analysis (sleep deprivation before learning).

Alberca-Reina E. , Cantero J. L. , & Atienza M. (2015). Impact of sleep loss before learning on cortical dynamics during memory retrieval. NeuroImage, 123 , 51–62. 10.1016/j.neuroimage.2015.08.033 26302671
*1 Albouy G. , Sterpenich V. , Vandewalle G. , Darsaud A. , Gais S. , Rauchs G. , Desseilles M. , Boly M. , Dang-Vu T. , Balteau E. , Degueldre C. , Phillips C. , & Degueldre C. (2013). Interaction between hippocampal and striatal systems predicts subsequent consolidation of motor sequence memory. PLOS ONE, 8 (3 ). Article e59490. 10.1371/journal.pone.0059490 23533626
*1 Albouy G. , Vandewalle G. , Sterpenich V. , Rauchs G. , Desseilles M. , Balteau E. , Degueldre C. , Phillips C. , Luxen A. , & Maquet P. (2013). Sleep stabilizes visuomotor adaptation memory: A functional magnetic resonance imaging study. Journal of Sleep Research, 22 (2 ), 144–154. 10.1111/j.1365-2869.2012.01059.x 23121320
Alger S. E. , Kensinger E. A. , & Payne J. D. (2018). Preferential consolidation of emotionally salient information during a nap is preserved in middle age. Neurobiology of Aging, 68 , 34–47. 10.1016/j.neurobiolaging.2018.03.030 29704647
*1 Ashton J. , Harrington M. O. , Langthorne D. , Ngo H. V. , & Cairney S. A. (2020). Sleep deprivation induces fragmented memory loss. Learning and Memory. 27 (4 ), 130–135. 10.1101/lm.050757.119 32179655
Ashton J. E. , Cairney S. A. , & Gaskell M. G. (2018). No effect of targeted memory reactivation during slow-wave sleep on emotional recognition memory. Journal of Sleep Research, 27 (1 ), 129–137. 10.1111/jsr.12542 28493346
Assink M. , & Wibbelink C. J. (2016). Fitting three-level meta-analytic models in R: A step-by-step tutorial. The Quantitative Methods for Psychology, 12 (3 ), 154–174. 10.20982/tqmp.12.3.p154
*1 Atienza M. , & Cantero J. L. (2008). Modulatory effects of emotion and sleep on recollection and familiarity. Journal of Sleep Research, 17 (3 ), 285–294. 10.1111/j.1365-2869.2008.00661.x 18503512
Banks S. , & Dinges D. F. (2007). Behavioral and physiological consequences of sleep restriction. Journal of Clinical Sleep Medicine, 3 (5 ), 519–528. 10.5664/jcsm.26918 17803017
Bartel P. , Offermeier W. , Smith F. , & Becker P. (2004). Attention and working memory in resident anaesthetists after night duty: Group and individual effects. Occupational and Environmental Medicine, 61 (2 ), 167–170. 10.1136/oem.2002.006197 14739384
*2 Basner M. , Savitt A. , Moore T. M. , Port A. M. , McGuire S. , Ecker A. J. , Nasrini J. , Mollicone D. J. , Mott C. M. , McCann T. , Dinges D. F. , & Gur R. V. (2015). Development and validation of the cognition test battery for spaceflight. Aerospace Medicine and Human Performance, 86 (11 ), 942–952. 10.3357/AMHP.4343.2015 26564759
*2 Bensimon G. , Benoit D. , Lacomblez L. , Weiller E. , Warot D. , Weil J. S. , & Puech A. J. (1991). Antagonism by modafinil of the psychomotor and cognitive impairment induced by sleep-deprivation in 12 healthy volunteers. European Psychiatry, 6 (2 ), 93–97. 10.1017/S0924933800000201
*2 Blagrove M. , Cole-Morgan D. , & Lambe H. (1994). Interrogative suggestibility: The effects of sleep deprivation and relationship with field dependence. Applied Cognitive Psychology, 8 (2 ), 169–179. 10.1002/acp.2350080207
Borenstein M. , Hedges L. V. , Higgins J. P. , & Rothstein H. R. (2010). A basic introduction to fixed-effect and random-effects models for meta-analysis. Research Synthesis Methods, 1 (2 ), 97–111. 10.1002/jrsm.12 26061376
Borenstein M. , Hedges L. V. , Higgins J. P. , & Rothstein H. R. (2011). Introduction to meta-analysis. Wiley.
Borenstein M. , Higgins J. P. , Hedges L. V. , & Rothstein H. R. (2017). Basics of meta-analysis: I2 is not an absolute measure of heterogeneity. Research Synthesis Methods, 8 (1 ), 5–18. 10.1002/jrsm.1230 28058794
Born J. , & Wilhelm I. (2012). System consolidation of memory during sleep. Psychological Research, 76 (2 ), 192–203. 10.1007/s00426-011-0335-6 21541757
*1 Borragán G. , Urbain C. , Schmitz R. , Mary A. , & Peigneux P. (2015). Sleep and memory consolidation: Motor performance and proactive interference effects in sequence learning. Brain and Cognition, 95 , 54–61. 10.1016/j.bandc.2015.01.011 25682352
*2 Boyle J. , Stanley N. , James L. M. , Wright N. , Johnsen S. , Arbon E. L. , & Dijk D. J. (2012). Acute sleep deprivation: The effects of the AMPAKINE compound CX717 on human cognitive performance, alertness and recovery sleep. Journal of Psychopharmacology, 26 (8 ), 1047–1057. 10.1177/0269881111405353 21940760
Brysbaert M. (2019). How many participants do we have to include in properly powered experiments? A tutorial of power analysis with reference tables. Journal of Cognition, 2 (1 ), Article 187. 10.5334/joc.72
Button K. S. , Ioannidis J. P. , Mokrysz C. , Nosek B. A. , Flint J. , Robinson E. S. , & Munafò M. R. (2013). Power failure: Why small sample size undermines the reliability of neuroscience. Nature Reviews Neuroscience, 14 (5 ), 365–376. 10.1038/nrn3475 23571845
*2 Chatburn A. , Kohler M. J. , Payne J. D. , & Drummond S. P. (2017). The effects of sleep restriction and sleep deprivation in producing false memories. Neurobiology of Learning and Memory, 137 , 107–113. 10.1016/j.nlm.2016.11.017 27915105
*2 Chee M. W. , Tan J. C. , Parimal S. , & Zagorodnov V. (2010). Sleep deprivation and its effects on object-selective attention. Neuroimage, 49 (2 ), 1903–1910. 10.1016/j.neuroimage.2009.08.067 19761853
Cheung B. Y. , Takemura K. , Ou C. , Gale A. , & Heine S. J. (2021). Considering cross-cultural differences in sleep duration between Japanese and Canadian university students. PLOS ONE, 16 (4 ), Article e0250671. 10.1371/journal.pone.0250671 33901233
Cheung M. W. L. (2014). Modeling dependent effect sizes with three-level meta-analyses: A structural equation modeling approach. Psychological Methods, 19 (2 ), 211–229. 10.1037/a0032968 23834422
*2 Chuah L. Y. , Chong D. L. , Chen A. K. , Rekshan W. R. III , Tan J. C. , Zheng H. , & Chee M. W. (2009). Donepezil improves episodic memory in young individuals vulnerable to the effects of sleep deprivation. Sleep, 32 (8 ), 999–1010. 10.1093/sleep/32.8.999 19725251
Cirelli C. , & Tononi G. (in press). The why and how of sleep-dependent synaptic down-selection. Seminars in Cell and Developmental Biology. 10.1016/j.semcdb.2021.02.007
Cochran W. G. (1954). The combination of estimates from different experiments. Biometrics, 10 (1 ), 101–129. 10.2307/3001666
Correll J. , Mellinger C. , McClelland G. H. , & Judd C. M. (2020). Avoid Cohen’s “small”,“medium”, and “large” for power analysis. Trends in Cognitive Sciences, 24 (3 ), 200–207. 10.1016/j.tics.2019.12.009 31954629
Cousins J. N. , Sasmita K. , & Chee M. W. (2018). Memory encoding is impaired after multiple nights of partial sleep restriction. Journal of Sleep Research, 27 (1 ), 138–145. 10.1111/jsr.12578 28677325
*1 Darsaud A. , Dehon H. , Lahl O. , Sterpenich V. , Boly M. , Dang-Vu T. , Desseilles M. ,Gais S. , Matarazzo L. , Peters F. , Schabus M. , Schmidt C. , Tinguely G. , Vandewalle G. , Luxen A. , Maquet P. , & Collette F. (2011). Does sleep promote false memories?. Journal of Cognitive Neuroscience, 23 (1 ), 26–40. 10.1162/jocn.2010.21448 20146605
Deary I. J. , & Tait R. (1987). Effects of sleep disruption on cognitive performance and mood in medical house officers. British Medical Journal (Clinical Research Ed.), 295 (6612 ), 1513–1516. 10.1136/bmj.295.6612.1513 3122881
*1 Deliens G. , Gilson M. , Schmitz R. , & Peigneux P. (2013). Sleep unbinds memories from their emotional context. Cortex, 49 (8 ), 2221–2228. 10.1016/j.cortex.2012.11.014 23290458
*1 Deliens G. , Schmitz R. , Caudron I. , Mary A. , Leproult R. , & Peigneux P. (2013b). Does recall after sleep-dependent memory consolidation reinstate sensitivity to retroactive interference? PLOS ONE, 8 (7 ), Article e68727. 10.1371/journal.pone.0068727 23874738
Di Stefano J. (2003). How much power is enough? Against the development of an arbitrary convention for statistical power calculations. Functional Ecology, 17 (5 ), 707–709. 10.1046/j.1365-2435.2003.00782.x
Diekelmann S. , & Born J. (2010). The memory function of sleep. Nature Reviews Neuroscience, 11 (2 ), 114–126. 10.1038/nrn2762 20046194
*1 Diekelmann S. , Born J. , & Wagner U. (2010). Sleep enhances false memories depending on general memory performance. Behavioural Brain Research, 208 (2 ), 425–429. 10.1016/j.bbr.2009.12.021 20035789
*1 Diekelmann S. , Landolt H. P. , Lahl O. , Born J. , & Wagner U. (2008). Sleep loss produces false memories. PLOS ONE, 3 (10 ). Article e0250671. 10.1371/journal.pone.0003512
Diekelmann S. , Wilhelm I. , & Born J. (2009). The whats and whens of sleep-dependent memory consolidation. Sleep Medicine Reviews, 13 (5 ), 309–321. 10.1016/j.smrv.2008.08.002 19251443
*1 Diekelmann S. , Wilhelm I. , Wagner U. , & Born J. (2013). Sleep to implement an intention. Sleep, 36 (1 ), 149–153. 10.5665/sleep.2322 23288982
Dinges D. F. , & Powell J. W. (1985). Microcomputer analyses of performance on a portable, simple visual RT task during sustained operations. Behavior Research Methods, Instruments, and Computers, 17 (6 ), 652–655. 10.3758/BF03200977
Downs S. H. , & Black N. (1998). The feasibility of creating a checklist for the assessment of the methodological quality both of randomised and non-randomised studies of health care interventions. Journal of Epidemiology & Community Health, 52 (6 ), 377–384. 10.1136/jech.52.6.377 9764259
*2 Drake C. L. , Roehrs T. A. , Burduvali E. , Bonahoom A. , Rosekind M. , & Roth T. (2001). Effects of rapid versus slow accumulation of eight hours of sleep loss. Psychophysiology, 38 (6 ), 979–987. 10.1111/1469-8986.3860979 12240674
Drosopoulos S. , Wagner U. , & Born J. (2005). Sleep enhances explicit recollection in recognition memory. Learning and Memory, 12 (1 ), 44–51. 10.1101/lm.83805 15687230
Drummond S. P. , & Brown G. G. (2001). The effects of total sleep deprivation on cerebral responses to cognitive performance. Neuropsychopharmacology, 25 (5 ), S68–S73. 10.1016/S0893-133X(01)00325-6 11682277
*2 Drummond S. P. , Brown G. G. , Gillin J. C. , Stricker J. L. , Wong E. C. , & Buxton R. B. (2000). Altered brain response to verbal learning following sleep deprivation. Nature, 403 (6770 ), 655–657. 10.1038/35001068 10688201
*2 Drummond S. P. , Meloy M. J. , Yanagi M. A. , Orff H. J. , & Brown G. G. (2005). Compensatory recruitment after sleep deprivation and the relationship with performance. Psychiatry Research: Neuroimaging, 140 (3 ), 211–223. 10.1016/j.pscychresns.2005.06.007
Dumas-Mallet E. , Button K. S. , Boraud T. , Gonon F. , & Munafò M. R. (2017). Low statistical power in biomedical science: A review of three human research domains. Royal Society Open Science, 4 (2 ), Article 160254. 10.1098/rsos.160254 28386409
Duval S. , & Tweedie R. (2000). Trim and fill: A simple funnel-plot–based method of testing and adjusting for publication bias in meta-analysis. Biometrics, 56 (2 ), 455–463. 10.1111/j.0006-341X.2000.00455.x 10877304
Egger M. , Smith G. D. , Schneider M. , & Minder C. (1997). Bias in meta-analysis detected by a simple, graphical test. British Medical Journal, 315 (7109 ), 629–634. 10.1136/bmj.315.7109.629 9310563
*1 Ertelt D. , Witt K. , Reetz K. , Frank W. , Junghanns K. , Backhaus J. , Tadic V. , Pellicano A. , Born J. , Binkofski F. , & Binkofski F. (2012). Skill memory escaping from distraction by sleep—Evidence from dual-task performance. PLOS ONE, 7 (12 ), Article e50983. 10.1371/journal.pone.0050983 23226554
*2 Esposito M. J. , Occhionero M. , & Cicogna P. (2015). Sleep deprivation and time-based prospective memory. Sleep, 38 (11 ), 1823–1826. 10.5665/sleep.5172 26085303
*2 Falleti M. G. , Maruff P. , Collie A. , Darby D. G. , & McStephen M. (2003). Qualitative similarities in cognitive impairment associated with 24 h of sustained wakefulness and a blood alcohol concentration of 0.05%. Journal of Sleep Research, 12 (4 ), 265–274. 10.1111/j.1365-2869.2003.00363.x 14633237
Faul F. , Erdfelder E. , Lang A. G. , & Buchner A. (2007). G*Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences. Behavior Research Methods, 39 (2 ), 175–191. 10.3758/BF03193146 17695343
*1 Feld G. B. , Weis P. P. , & Born J. (2016). The limited capacity of sleep-dependent memory consolidation. Frontiers in Psychology, 7 , Article 1368. 10.3389/fpsyg.2016.01368 27679589
Fenn K. M. , Gallo D. A. , Margoliash D. , Roediger H. L. III , & Nusbaum H. C. (2009). Reduced false memory after sleep. Learning & Memory, 16 , 509–513. 10.1101/lm.1500808 19706833
*1 Ferrara M. , Iaria G. , De Gennaro L. , Guariglia C. , Curcio G. , Tempesta D. , & Bertini M. (2006). The role of sleep in the consolidation of route learning in humans: A behavioural study. Brain Research Bulletin, 71 (1–3 ), 4–9. 10.1177/1745691612459059 17113921
*1 Ferrara M. , Iaria G. , Tempesta D. , Curcio G. , Moroni F. , Marzano C. , De Gennaro L. , & Pacitti C. (2008). Sleep to find your way: The role of sleep in the consolidation of memory for navigation in humans. Hippocampus, 18 (8 ), 844–851. 10.1002/hipo.20444 18493970
*1*2 Fischer S. , Hallschmid M. , Elsner A. L. , & Born J. (2002). Sleep forms memory for finger skills. Proceedings of the National Academy of Sciences, 99 (18 ), 11987–11991. 10.1073/pnas.182178199
*1 Fischer S. , Nitschke M. F. , Melchert U. H. , Erdmann C. , & Born J. (2005). Motor memory consolidation in sleep shapes more effective neuronal representations. Journal of Neuroscience, 25 (49 ), 11248–11255. 10.1523/JNEUROSCI.1743-05.2005 16339020
*2 Forest G. , & Godbout R. (2000). Effects of sleep deprivation on performance and EEG spectral analysis in young adults. Brain and Cognition, 43 (1–3 ), 195–200.10857693
Fraley R. C. , & Vazire S. (2014). The N-pact factor: Evaluating the quality of empirical journals with respect to sample size and statistical power. PLOS ONE, 9 (10 ), Article e109019. 10.1371/journal.pone.0109019 25296159
Funder D. C. , & Ozer D. J. (2019). Evaluating effect size in psychological research: Sense and nonsense. Advances in Methods and Practices in Psychological Science, 2 (2 ), 156–168. 10.1177/2515245919847202
Gais S. , Albouy G. , Boly M. , Dang-Vu T. T. , Darsaud A. , Desseilles M. , Rauchs G. , Schabus M. , Sterpenich V. , Vandewalle G. , Maquet P. , & Peigneux P. (2007). Sleep transforms the cerebral trace of declarative memories. Proceedings of the National Academy of Sciences, 104 (47 ), 18778–18783. 10.1073/pnas.0705454104
Gais S. , & Born J. (2004). Declarative memory consolidation: Mechanisms acting during human sleep. Learning and Memory, 11 (6 ), 679–685. 10.1101/lm.80504.15576885
*1 Gais S. , Lucas B. , & Born J. (2006). Sleep after learning aids memory recall. Learning and Memory, 13 (3 ), 259–262. 10.1101/lm.132106 16741280
*2 Giacobbo B. L. , Corrêa M. S. , Vedovelli K. , de Souza C. E. B. , Spitza L. M. , Gonçalves L. , Gonçalves L. , Paludo N. , Molina R. D. , da Rosa E. D. , Argimon I. L. , & Bromberg E. (2016). Could BDNF be involved in compensatory mechanisms to maintain cognitive performance despite acute sleep deprivation? An exploratory study. International Journal of Psychophysiology, 99 , 96–102. 10.1016/j.ijpsycho.2015.11.008 26602839
Giuditta A. (2014). Sleep memory processing: The sequential hypothesis. Frontiers in Systems Neuroscience, 8 , Article 219. 10.3389/fnsys.2014.00219 25565985
*2 Gorissen M. , Tielemans M. , & Coenen A. (1997). Alertness and memory after sleep deprivation and diazepam intake. Journal of Psychopharmacology, 11 (3 ), 233–239. 10.1177/026988119701100306 9305415
*1 Griessenberger H. , Hödlmoser K. , Heib D. P. J. , Lechinger J. , Klimesch W. , & Schabus M. (2012). Consolidation of temporal order in episodic memories. Biological Psychology, 91 (1 ), 150–155. 10.1016/j.biopsycho.2012.05.012 22705480
Groch S. , Zinke K. , Wilhelm I. , & Born J. (2015). Dissociating the contributions of slow-wave sleep and rapid eye movement sleep to emotional item and source memory. Neurobiology of Learning and Memory, 122 , 122–130. 10.1016/j.nlm.2014.08.013 25180933
*2 Grundgeiger T. , Bayen U. J. , & Horn S. S. (2014). Effects of sleep deprivation on prospective memory. Memory, 22 (6 ), 679–686. 10.1016/j.biopsycho.2012.05.012 23885855
Guyette F. X. , Morley J. L. , Weaver M. D. , Patterson P. D. , & Hostler D. (2013). The effect of shift length on fatigue and cognitive performance in air medical providers. Prehospital Emergency Care, 17 (1 ), 23–28. 10.3109/10903127.2012.710719 22925035
*1 Harrington M. O. , Nedberge K. M. , & Durrant S. J. (2018). The effect of sleep deprivation on emotional memory consolidation in participants reporting depressive symptoms. Neurobiology of Learning and Memory, 152 , 10–19. 10.1016/j.nlm.2018.04.013 29709569
*2 Harrison Y. , & Horne J. A. (2000a). Sleep loss and temporal memory. The Quarterly Journal of Experimental Psychology: Section A, 53 (1 ), 271–279. 10.1080/713755870
Harrison Y. , & Horne J. A. (2000b). The impact of sleep deprivation on decision making: A review. Journal of Experimental Psychology: Applied, 6 (3 ), 236–249. 10.1037/1076-898X.6.3.236 11014055
*2 Harrison Y. , Horne J. A. , & Rothwell A. (2000). Prefrontal neuropsychological effects of sleep deprivation in young adults—A model for healthy aging? Sleep, 23 (8 ), 1067–1073. 10.1093/sleep/23.8.1f 11145321
Hempel S. , Miles J. N. , Booth M. J. , Wang Z. , Morton S. C. , & Shekelle P. G. (2013). Risk of bias: A simulation study of power to detect study-level moderator effects in meta-analysis. Systematic Reviews, 2 (1 ), 1–10. 10.1186/2046-4053-2-107 23295105
*1 Herzog N. , Friedrich A. , Fujita N. , Gais S. , Jauch-Chara K. , Oltmanns K. M. , & Benedict C. (2012). Effects of daytime food intake on memory consolidation during sleep or sleep deprivation. PLOS ONE, 7 (6 ), Article e40298. 10.1371/journal.pone.0040298 22768272
Higgins J. P. , Altman D. G. , Gøtzsche P. C. , Jüni P. , Moher D. , Oxman A. D. , Savović J. , Schulz K. F. , Weeks L. , & Sterne J. A. C. , (2011). The cochrane collaboration’s tool for assessing risk of bias in randomised trials. British Medical Journal, 343 , Article d5928. 10.1136/bmj.d5928 22008217
Higgins J. P. , & Thompson S. G. (2002). Quantifying heterogeneity in a meta-analysis. Statistics in Medicine, 21 (11 ), 1539–1558. 10.1002/sim.1186 12111919
Hoedlmoser K. (2020). Sleep and memory in children. Current Sleep Medicine Reports, 6 (4 ), 280–289. 10.1007/s40675-020-00194-8
Hu P. , Stylos-Allan M. , & Walker M. P. (2006). Sleep facilitates consolidation of emotional declarative memory. Psychological Science, 17 (10 ), 891–898. 10.1111/j.1467-9280.2006.01799.x 17100790
Hunter J. E. , & Schmidt F. L. (2004). Methods of meta-analysis: Correcting error and bias in research findings. Sage Publications.
*1 Idzikowski C. (1984). Sleep and memory. British Journal of Psychology, 75 (4 ), 439–449. 10.1111/j.2044-8295.1984.tb01914.x 6509282
Inostroza M. , & Born J. (2013). Sleep for preserving and transforming episodic memory. Annual Review of Neuroscience, 36 , 79–102. 10.1146/annurev-neuro-062012-170429
Ioannidis J. P. (2005). Why most published research findings are false. PLoS Medicine, 2 (8 ), Article e124. 10.1371/journal.pmed.0020124 16060722
Jacoby L. L. (1991). A process dissociation framework: Separating automatic from intentional uses of memory. Journal of Memory and Language, 30 (5 ), 513–541. 10.1016/0749-596X(91)90025-F
Johnson B. T. (2021). Toward a more transparent, rigorous, and generative psychology. Psychological Bulletin, 147 (1 ), 1–15. 10.1037/bul0000317 33464105
*2 Kaida K. , Niki K. , & Born J. (2015). Role of sleep for encoding of emotional memory. Neurobiology of Learning and Memory, 121 , 72–79. 10.1016/j.nlm.2015.04.002 25911247
Kilpeläinen A. A. , Huttunen K. H. , Lohi J. J. , & Lyytinen H. (2010). Effect of caffeine on vigilance and cognitive performance during extended wakefulness. The International Journal of Aviation Psychology, 20 (2 ), 144–159. 10.1080/10508411003617847
Kim S. Y. , & Payne J. D. (2020). Neural correlates of sleep, stress, and selective memory consolidation. Current Opinion in Behavioral Sciences, 33 , 57–64. 10.1016/j.cobeha.2019.12.009
King B. R. , Hoedlmoser K. , Hirschauer F. , Dolfen N. , & Albouy G. (2017). Sleeping on the motor engram: The multifaceted nature of sleep-related motor memory consolidation. Neuroscience and Biobehavioral Reviews, 80 , 1–22. 10.1016/j.neubiorev.2017.04.026 28465166
Klinzing J. G. , Niethard N. , & Born J. (2019). Mechanisms of systems memory consolidation during sleep. Nature Neuroscience, 22 , 1598–1610. 10.1038/s41593-019-0467-3 31451802
*1 Kolibius L. D. , Born J. , & Feld G. B. (2021). Vast amounts of encoded items nullify but do not reverse the effect of sleep on declarative memory. Frontiers in Psychology, 11 , Article 3685. 10.3389/fpsyg.2020.607070
Korman M. , Doyon J. , Doljansky J. , Carrier J. , Dagan Y. , & Karni A. (2007). Daytime sleep condenses the time course of motor memory consolidation. Nature Neuroscience, 10 (9 ), 1206–1213. 10.1038/nn1959 17694051
Kumaran D. , Hassabis D. , & McClelland J. L. (2016). What learning systems do intelligent agents need? Complementary learning systems theory updated. Trends in Cognitive Sciences, 20 , 512–534. 10.1016/j.tics.2016.05.004 27315762
*1 Kuriyama K. , Honma M. , Yoshiike T. , & Kim Y. (2013). Memory suppression trades prolonged fear and sleep-dependent fear plasticity for the avoidance of current fear. Scientific Reports, 3 , Article 2227. 10.1038/srep02227 23863955
*1 Kuriyama K. , Soshi T. , & Kim Y. (2010). Sleep deprivation facilitates extinction of implicit fear generalization and physiological response to fear. Biological Psychiatry, 68 (11 ), 991–998. 10.1016/j.biopsych.2010.08.015 20889142
*1 Lahl O. , & Pietrowsky R. (2006). Does the “sleep effect” on memory depend on sleep or on night time? Sleep and Hypnosis, 8 (2 ), 61–70.
Lakens D. (2013). Calculating and reporting effect sizes to facilitate cumulative science: A practical primer for t-tests and ANOVAs. Frontiers in Psychology, 4 , Article 863. 10.3389/fpsyg.2013.00863 24324449
Lakens D. , & Caldwell A. R. (2021). Simulation-based power analysis for factorial analysis of variance designs. Advances in Methods and Practices in Psychological Science, 4 , 1–14. 10.1177/2515245920951503
Lewis P. A. , & Durrant S. J. (2011). Overlapping memory replay during sleep builds cognitive schemata. Trends in Cognitive Sciences, 15 , 343–351. 10.1016/j.tics.2011.06.004 21764357
Lewis P. A. , Knoblich G. , & Poe G. (2018). How memory replay in sleep boosts creative problem-solving. Trends in Cognitive Sciences, 22 , 491–503. 10.1016/j.tics.2018.03.009 29776467
Lim J. , & Dinges D. (2008). Sleep deprivation and vigilant attention. Annals of the New York Academy of Sciences, 1129 (1 ), Article 305. 10.1196/annals.1417.002 18591490
Lim J. , & Dinges D. F. (2010). A meta-analysis of the impact of short-term sleep deprivation on cognitive variables. Psychological Bulletin, 136 (3 ), 375–389. 10.1037/a0018883 20438143
*1 Lin C. C. , & Yang C. M. (2014). Evidence of sleep-facilitating effect on formation of novel semantic associations: An event-related potential (ERP) study. Neurobiology of Learning and Memory, 116 , 69–78. 10.1016/j.nlm.2014.08.011 25172481
Lipinska G. , Stuart B. , Thomas K. G. , Baldwin D. S. , & Bolinger E. (2019). Preferential consolidation of emotional memory during sleep: a meta-analysis. Frontiers in Psychology, 10 , Article 1014. 10.3389/fpsyg.2019.01014 31133940
*2 Lo J. C. , Chong P. L. , Ganesan S. , Leong R. L. , & Chee M. W. (2016). Sleep deprivation increases formation of false memory. Journal of Sleep Research, 25 (6 ), 673–682. 10.1111/jsr.12436 27381857
Lo J. C. , Groeger J. A. , Cheng G. H. , Dijk D. J. , & Chee M. W. (2016). Self-reported sleep duration and cognitive performance in older adults: A systematic review and meta-analysis. Sleep Medicine, 17 , 87–98. 10.1016/j.sleep.2015.08.021 26847980
Lo J. C. , Sim S. K. Y. , Chee M. W. L. (2014). Sleep reduces false memory in healthy older adults. Sleep, 37 , 665–671. 10.5665/sleep.3564 24744453
Lowe C. J. , Safati A. , & Hall P. A. (2017). The neurocognitive consequences of sleep restriction: A meta-analytic review. Neuroscience & Biobehavioral Reviews, 80 , 586–604. 10.1016/j.neubiorev.2017.07.010 28757454
*1 Maddox W. T. , Glass B. D. , Wolosin S. M. , Savarie Z. R. , Bowen C. , Matthews M. D. , & Schnyer D. M. (2009). The effects of sleep deprivation on information-integration categorization performance. Sleep, 32 (11 ), 1439–1448. 10.1093/sleep/32.11.1439 19928383
*2 Maddox W. T. , Glass B. D. , Zeithamova D. , Savarie Z. R. , Bowen C. , Matthews M. D. , & Schnyer D. M. (2011). The effects of sleep deprivation on dissociable prototype learning systems. Sleep, 34 (3 ), 253–260. 10.1093/sleep/34.3.253 21358842
Mander B. A. , Santhanam S. , Saletin J. M. , & Walker M. P. (2011). Wake deterioration and sleep restoration of human learning. Current Biology, 21 (5 ), R183–R184. 10.1016/j.cub.2011.01.019 21377092
Manoach D. S. , & Stickgold R. (2019). Abnormal sleep spindles, memory consolidation, and schizophrenia. Annual Review of Clinical Psychology, 15 , 451–479. 10.1146/annurev-clinpsy-050718-095754
McClelland J. L. , McNaughton B. L. , & O’Reilly R. C. (1995). Why there are complementary learning systems in the hippocampus and neocortex: Insights from the successes and failures of connectionist models of learning and memory. Psychological Review, 102 (3 ), 419–457. 10.1037/0033-295X.102.3.419 7624455
McKeon S. , Pace-Schott E. F. , Spencer R. M. C. (2012). Interaction of sleep and emotional content on the production of false memories. PLOS ONE, 7 , Article e49353. 10.1371/journal.pone.0049353 23145159
*2 McWhirter K. K. , Morrow A. S. , Lee B. A. , Bishu S. , Zametkin A. J. , Balkin T. J. , Smith C. B. , & Picchioni D. (2015). A pilot study on the encoding of a perceptual learning task following sleep deprivation. Perceptual and Motor Skills, 121 (1 ), 80–93. 10.2466/23.PMS.121c11x9 26226287
*1 Mograss M. A. , Guillem F. , Brazzini-Poisson V. , & Godbout R. (2009). The effects of total sleep deprivation on recognition memory processes: A study of event-related potential. Neurobiology of Learning and Memory, 91 (4 ), 343–352. 10.1016/j.nlm.2009.01.008 19340944
*1 Montemayor B. A. (2014). Musical task: Sleep deprivation and its effects on motor learning [Masters dissertation]. University of Houston-Clear Lake. Proquest. https://www.proquest.com/docview/1532140044?pq-origsite=gscholar&fromopenview=true
Morgan D. P. , Tamminen J. , Seale-Carlisle T. M. , & Mickes L. (2019). The impact of sleep on eyewitness identifications. Royal Society Open Science, 6 (12 ), Article 170501. 10.1098/rsos.170501 31903193
*1 Nesca M. , & Koulack D. (1994). Recognition memory, sleep and circadian rhythms. Canadian Journal of Experimental Psychology, 48 (3 ), 359–379. 10.1037/1196-1961.48.3.359 7951197
Newbury C. R. , Monaghan P. (2019). When does sleep affect veridical and false memory consolidation? A meta-analysis. Psychonomic Bulletin and Review, 26 , 387–400. 10.3758/s13423-018-1528-4 30264239
*2 Nilsson L. G. , Bäckman L. , & Karlsson T. (1989). Priming and cued recall in elderly, alcohol intoxicated and sleep deprived subjects: A case of functionally similar memory deficits. Psychological Medicine, 19 (2 ), 423–433. 10.1017/s0033291700012460 2762444
Nosek B. A. , Alter G. , Banks G. C. , Borsboom D. , Bowman S. D. , Breckler S. J. , Buck S. , Chambers C. D. , Chin G. , Christensen G. , Contestabile M. , Dafoe A. , Eich E. , Freese J. , Glennerster R. , Goroff D. , Green D. P. , Hesse B. , Humphreys M. , … Yarkoni T. (2015). Promoting an open research culture. Science, 348 (6242 ), 1422–1425. 10.1126/science.aab2374 26113702
Nosek B. A. , & Lindsay D. S. (2018, February 28). Preregistration becoming the norm in psychological science. APS Observer. https://www.psychologicalscience.org/observer/preregistration-becoming-the-norm-in-psychological-science
*2 Occhionero M. , Cicogna P. , & Esposito M. J. (2017). The effect of sleep loss on dual time-based prospective memory tasks. American Journal of Psychology, 130 (1 ), 93–103. 10.5406/amerjpsyc.130.1.0093
*1 Orban P. , Rauchs G. , Balteau E. , Degueldre C. , Luxen A. , Maquet P. , & Peigneux P. (2006). Sleep after spatial learning promotes covert reorganization of brain activity. Proceedings of the National Academy of Sciences, 103 (18 ), 7124–7129. 10.1073/pnas.0510198103
*2 Pace-Schott E. F. , Hutcherson C. A. , Bemporad B. , Morgan A. , Kumar A. , Hobson J. A. , & Stickgold R. (2009). Failure to find executive function deficits following one night’s total sleep deprivation in university students under naturalistic conditions. Behavioral Sleep Medicine, 7 (3 ), 136–163. 10.1080/15402000902976671 19568965
Pardilla-Delgado E. , & Payne J. D. (2017). The impact of sleep on true and false memory across long delays. Neurobiology of Learning and Memory, 137 , 123–133. 10.1016/j.nlm.2016.11.016 27903437
Payne J. D. , & Kensinger E. A. (2010). Sleep’s role in the consolidation of emotional episodic memories. Current Directions in Psychological Science, 19 , 290–295. 10.1177/0963721410383978
Payne J. D. , Kensinger E. A. , Wamsley E. J. , Spreng R. N. , Alger S. E. , Gibler K. , Schacter D. L. , & Stickgold R. (2015). Napping and the selective consolidation of negative aspects of scenes. Emotion, 15 , 176–186. 10.1037/a0038683 25706830
Payne J. D. , Schacter D. L. , Propper R. E. , Huang L. W. , Wamsley E. J. , Tucker M. A. , Walker M. P. , & Stickgold R. (2009). The role of sleep in false memory formation. Neurobiology of Learning and Memory, 92 , 327–334. 10.1016/j.nlm.2009.03.007 19348959
Payne J. D. , Stickgold R. , Swanberg K. , & Kensinger E. A. (2008). Sleep preferentially enhances memory for emotional components of scenes. Psychological Science, 19 (8 ), 781–788. 10.1111/j.1467-9280.2008.02157.x 18816285
*1 Peigneux P. , Schmitz R. , & Willems S. (2007). Cerebral asymmetries in sleep-dependent processes of memory consolidation. Learning and Memory, 14 (6 ), 400–406. 10.1101/lm.551207 17554084
Piérard C. , Béracochéa D. , Pérès M. , Jouanin J. C. , Liscia P. , Satabin P. , Martin S. , Testylier G. , Guézennec C. Y. , & Beaumont M. (2004). Declarative memory impairments following a military combat course: Parallel neuropsychological and biochemical investigations. Neuropsychobiology, 49 (4 ), 210–217. 10.1159/000077369 15118359
Pilcher J. J. , & Huffcutt A. I. (1996). Effects of sleep deprivation on performance: A meta-analysis. Sleep, 19 (4 ), 318–326. 10.1093/sleep/19.4.318 8776790
Plihal W. , & Born J. (1997). Effects of early and late nocturnal sleep on declarative and procedural memory. Journal of Cognitive Neuroscience, 9 (4 ), 534–547. 10.1162/jocn.1997.9.4.534 23968216
*2 Poh J. H. , & Chee M. W. (2017). Degradation of cortical representations during encoding following sleep deprivation. Neuroimage, 153 , 131–138. 10.1016/j.neuroimage.2017.01.080 28161311
Pollard P. , & Richardson J. T. (1987). On the probability of making Type I errors. Psychological Bulletin, 102 (1 ), 159–163. 10.1037/0033-2909.102.1.159
*1 Porcheret K. , Holmes E. A. , Goodwin G. M. , Foster R. G. , & Wulff K. (2015). Psychological effect of an analogue traumatic event reduced by sleep deprivation. Sleep, 38 (7 ), 1017–1025. 10.5665/sleep.4802 26118556
Rauchs G. , Bertran F. , Guillery-Girard B. , Desgranges B. , Kerrouche N. , Denise P. , Foret J. , & Eustache F. (2004). Consolidation of strictly episodic memories mainly requires rapid eye movement sleep. Sleep, 27 (3 ), 395–401. 10.1093/sleep/27.3.395 15164890
*1 Rauchs G. , Orban P. , Schmidt C. , Albouy G. , Balteau E. , Degueldre C. , Schnackers C. , Sterpenich V. , Tinguely G. , Luxen A. , Maquet P. , & Peigneux P. (2008). Sleep modulates the neural substrates of both spatial and contextual memory consolidation. PLOS ONE, 3 (8 ), Article e2949. 10.1371/journal.pone.0002949 18698363
Robertson E. M. , Pascual-Leone A. , & Press D. Z. (2004). Awareness modifies the skill-learning benefits of sleep. Current Biology, 14 (3 ), 208–212. 10.1016/j.cub.2004.01.027 14761652
*2 Roehrs T. , Burduvali E. , Bonahoom A. , Drake C. , & Roth T. (2003). Ethanol and sleep loss: A “dose” comparison of impairing effects. Sleep, 26 (8 ), 981–985. 10.1093/sleep/26.8.981 14746378
Rohatgi A. (2019). WebPlotDigitizer (Version 4.2). https://automeris.io/WebPlotDigitizer
Rosenthal R. (1979). The file drawer problem and tolerance for null results. Psychological Bulletin, 86 (3 ), 638–641. 10.1037/0033-2909.86.3.638
Rothstein H. R. , Sutton A. J. , & Borenstein M. (Eds. ). (2005). Publication bias in meta-analysis: Prevention, assessment and adjustments. Wiley.
Saletin J. M. , & Walker M. P. (2012). Nocturnal mnemonics: Sleep and hippocampal memory processing. Frontiers in Neurology, 3 , Article 59. 10.3389/fneur.2012.00059 22557988
Sawangjit A. , Oyanedel C. N. , Niethard N. , Salazar C. , Born J. , & Inostroza M. (2018). The hippocampus is crucial for forming non-hippocampal long-term memory during sleep. Nature 564 , 109–113. 10.1038/s41586-018-0716-8 30429612
Schäfer S. K. , Wirth B. E. , Staginnus M. , Becker N. , Michael T. , & Sopp M. R. (2020). Sleep’s impact on emotional recognition memory: A meta-analysis of whole-night, nap, and REM sleep effects. Sleep Medicine Reviews, 51 , Article 101280. 10.1016/j.smrv.2020.101280 32179376
Schapiro A. C. , Reid A. G. , Morgan A. , Manoach D. S. , Verfaellie M. , & Stickgold R. (2019). The hippocampus is necessary for the consolidation of a task that does not require the hippocampus for initial learning. Hippocampus, 29 , 1091–1100. 10.1002/hipo.23101 31157946
Schönauer M. , Geisler T. , & Gais S. (2014). Strengthening procedural memories by reactivation in sleep. Journal of Cognitive Neuroscience, 26 (1 ), 143–153. 10.1162/jocn_a_00471 23984946
*1 Schönauer M. , Grätsch M. , & Gais S. (2015). Evidence for two distinct sleep-related long-term memory consolidation processes. Cortex, 63 , 68–78. 10.1016/j.cortex.2014.08.005 25243990
Siddaway A. P. , Wood A. M. , & Hedges L. V. (2019). How to do a systematic review: A best practice guide for conducting and reporting narrative reviews, meta-analyses, and meta-syntheses. Annual Review of Psychology, 70 , 747–770. 10.1146/annurev-psych-010418-102803
Stepan M. E. , Dehnke T. M. , & Fenn K. M. (2017). Sleep and eyewitness memory: Fewer false identifications after sleep when the target is absent from the lineup. PLOS ONE, 12 , Article e0182907. 10.1371/journal.pone.0182907 28877169
Sterne J. A. , Sutton A. J. , Ioannidis J. P. , Terrin N. , Jones D. R. , Lau J. , Carpenter J. , Rücker G. , Harbord R. M. , Schmid C. H. , Tetzlaff J. , Deeks J. J. , Peters J. , Macaskill P. , Schwarzer G. , Duval S. , Altman D. G. , Moher D. , & Higgins J. P. T. (2011). Recommendations for examining and interpreting funnel plot asymmetry in meta-analyses of randomised controlled trials. British Medical Journal, 343 , Article d4002. 10.1136/bmj.d4002 21784880
*1 Sterpenich V. , Albouy G. , Boly M. , Vandewalle G. , Darsaud A. , Balteau E. , Dang-Vu T. T. , Desseilles M. , D’Argembeau A. , Gais S. , Rauchs G. , Schabus M. , Degueldre C. , Luxen A. , Collette F. , & Maquet P. (2007). Sleep-related hippocampo-cortical interplay during emotional memory recollection. PLoS Biology, 5 (11 ), Article e282. 10.1371/journal.pbio.0050282 17958471
*1 Sterpenich V. , Albouy G. , Darsaud A. , Schmidt C. , Vandewalle G. , Vu T. T. D. , Desseilles M. , Phillips C. , Degueldre C. , Balteau E. , Collette F. , Luxen A. , & Maquet P. (2009). Sleep promotes the neural reorganization of remote emotional memory. Journal of Neuroscience, 29 (16 ), 5143–5152. 10.1523/JNEUROSCI.0561-09.2009 19386910
*1 Sterpenich V. , Ceravolo L. , & Schwartz S. (2017). Sleep deprivation disrupts the contribution of the hippocampus to the formation of novel lexical associations. Brain and Language, 167 , 61–71. 10.1016/j.bandl.2016.12.007 28173964
*1 Stickgold R. , James L. , & Hobson J. A. (2000). Visual discrimination learning requires sleep after training. Nature Neuroscience, 3 (12 ), 1237–1238. 10.1038/81756.11100141
Stickgold R. , & Walker M. P. (2013). Sleep-dependent memory triage: Evolving generalization through selective processing. Nature Neuroscience, 16 , 139–145. 10.1038/nn.3303 23354387
Stone J. C. , Glass K. , Munn Z. , Tugwell P. , & Doi S. A. (2020). Comparison of bias adjustment methods in meta-analysis suggests that quality effects modeling may have less limitations than other approaches. Journal of Clinical Epidemiology, 117 , 36–45. 10.1016/j.jclinepi.2019.09.010 31541691
*2 Stricker J. L. , Brown G. G. , Wetherell L. A. , & Drummond S. P. (2006). The impact of sleep deprivation and task difficulty on networks of fMRI brain response. Journal of the International Neuropsychological Society, 12 (5 ), 591–597. 10.1017/S1355617706060851 16961940
Szucs D. , & Ioannidis J. P. (2017). Empirical assessment of published effect sizes and power in the recent cognitive neuroscience and psychology literature. PLoS Biology, 15 (3 ), Article e2000797. 10.1371/journal.pbio.2000797 28253258
Talamini L. M. , Nieuwenhuis I. L. , Takashima A. , & Jensen O. (2008). Sleep directly following learning benefits consolidation of spatial associative memory. Learning and Memory, 15 (4 ), 233–237. 10.1101/lm.771608 18391183
*1*2 Tamminen J. , Newbury C. R. , Crowley R. , Vinals L. , Cevoli B. , & Rastle K. (2020). Generalisation in language learning can withstand total sleep deprivation. Neurobiology of Learning and Memory, 173 , Article 107274. 10.1016/j.nlm.2020.107274 32653634
*1 Tempesta D. , De Gennaro L. , Natale V. , & Ferrara M. (2015). Emotional memory processing is influenced by sleep quality. Sleep Medicine, 16 (7 ), 862–870. 10.1016/j.sleep.2015.01.024 26008959
*2 Tempesta D. , Socci V. , Coppo M. , Ioio G. D. , Nepa V. , De Gennaro L. , & Ferrara M. (2016). The effect of sleep deprivation on the encoding of contextual and non-contextual aspects of emotional memory. Neurobiology of Learning and Memory, 131 , 9–17. 10.1016/j.nlm.2016.03.007 26976090
*1 Tempesta D. , Socci V. , Ioio G. D. , De Gennaro L. , & Ferrara M. (2017). The effect of sleep deprivation on retrieval of emotional memory: A behavioural study using film stimuli. Experimental Brain Research, 235 (10 ), 3059–3067. 10.1007/s00221-01705043-z 28741085
Tononi G. , & Cirelli C. (2003). Sleep and synaptic homeostasis: A hypothesis. Brain Research Bulletin, 62 (2 ), 143–150. 10.1016/j.brainresbull.2003.09.004 14638388
Tononi G. , & Cirelli C. (2012). Time to be SHY? Some comments on sleep and synaptic homeostasis. Neural Plasticity, 12 , 1–12. 10.1155/2012/415250
Twenge J. M. , Krizan Z. , & Hisler G. (2017). Decreases in self-reported sleep duration among US adolescents 2009–2015 and association with new media screen time. Sleep Medicine, 39 , 47–53. 10.1155/2012/415250 29157587
Valentine J. C. (2009). Judging the quality of primary research. In The handbook of research synthesis and meta-analysis (2nd ed., pp. 129–146). Sage Publications.
Van Der Werf Y. D. , Altena E. , Schoonheim M. M. , Sanz-Arigita E. J. , Vis J. C. , De Rijke W. , & Van Someren E. J. (2009). Sleep benefits subsequent hippocampal functioning. Nature Neuroscience, 12 (2 ), 122–123. 10.1038/nn.2253 19151712
*1 van Heugten–van der Kloet D. , Giesbrecht T. , & Merckelbach H. (2015). Sleep loss increases dissociation and affects memory for emotional stimuli. Journal of Behavior Therapy and Experimental Psychiatry, 47 , 9–17. 10.1016/j.jbtep.2014.11.002 25462597
*1 Vargas I. , Payne J. D. , Muench A. , Kuhlman K. R. , & Lopez-Duran N. L. (2019). Acute sleep deprivation and the selective consolidation of emotional memories. Learning and Memory, 26 (6 ), 176–181. 10.1101/lm.049312.119 31092550
Vargas I. P. , Aguiar S. A. , & Barela J. A. (2017). Effects of sleep deprivation on sustained attention in young adults. Brazilian Journal of Motor Behavior, 11 (1 ), 1–9.10.20338/bjmb.v11i1.96
Vidya S. , Patlolla V. R. P. , Kamuju N. R. , Ampalam P. , & Kalyan V. K. S. N. (2019). Impact of shift work on sleep and quality of life in industrial workers: A cross sectional study. Archives of Mental Health, 20 (2 ), Article 45. 10.4103/AMH.AMH_3_19
Viechtbauer W. (2010). Conducting meta-analyses in R with the metafor package. Journal of Statistical Software, 36 (3 ), 1–48. 10.18637/jss.v036.i03
Viechtbauer W. , & Cheung M. W. L. (2010). Outlier and influence diagnostics for meta-analysis. Research Synthesis Methods, 1 (2 ), 112–125. 10.1002/jrsm.11 26061377
Voderholzer U. , Piosczyk H. , Holz J. , Landmann N. , Feige B. , Loessl B. , Kpasz M. , Doerr J. P. , Riemann D. , & Nissen C. (2011). Sleep restriction over several days does not affect long–term recall of declarative and procedural memories in adolescents. Sleep Medicine, 12 (2 ), 170–178. 10.1016/j.sleep.2010.07.017 21256802
Wagner U. , Gais S. , & Born J. (2001). Emotional memory formation is enhanced across sleep intervals with high amounts of rapid eye movement sleep. Learning & Memory, 8 (2 ), 112–119. 10.1101/lm.36801 11274257
Wagner U. , Hallschmid M. , Rasch B. , & Born J. (2006). Brief sleep after learning keeps emotional memories alive for years. Biological Psychiatry, 60 (7 ), 788–790. 10.1016/j.biopsych.2006.03.061 16806090
Walker M. P. , Brakefield T. , Morgan A. , Hobson J. A. , & Stickgold R. (2002). Practice with sleep makes perfect: Sleep-dependent motor skill learning. Neuron, 35 (1 ), 205–211. 10.1016/S0896-6273(02)00746-8 12123620
Walker M. P. , & Stickgold R. (2006). Sleep, memory, and plasticity. Annual Review of Psychology, 57 , 139–166. 10.1146/annurev.psych.56.091103.070307
Walker M. P. , Stickgold R. , Alsop D. , Gaab N. , & Schlaug G. (2005). Sleep-dependent motor memory plasticity in the human brain. Neuroscience, 133 (4 ), 911–917. 10.1016/j.neuroscience.2005.04.007 15964485
Wilson B. M. , Harris C. R. , & Wixted J. T. (2020). Science is not a signal detection problem. Proceedings of the National Academy of Sciences, 117 (11 ), 5559–5567. 10.1073/pnas.1914237117
Yonelinas A. P. (2002). The nature of recollection and familiarity: A review of 30 years of research. Journal of Memory and Language, 46 (3 ), 441–517. 10.1006/jmla.2002.2864
*2 Yoo S. S. , Hu P. T. , Gujar N. , Jolesz F. A. , & Walker M. P. (2007). A deficit in the ability to form new human memories without sleep. Nature Neuroscience, 10 (3 ), 385–392. 10.1038/nn1851 17293859

