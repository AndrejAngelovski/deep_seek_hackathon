
==== Front
Front Hum Neurosci
Front Hum Neurosci
Front. Hum. Neurosci.
Frontiers in Human Neuroscience
1662-5161
Frontiers Media S.A.

10.3389/fnhum.2021.687288
Neuroscience
Original Research
Large-Scale Brain Functional Network Integration for Discrimination of Autism Using a 3-D Deep Learning Model
Yang Ming 123†
Cao Menglin 123†

Chen Yuhao 123
Chen Yanni 4

Fan Geng 123
Li Chenxi 123
Wang Jue 123

Liu Tian 123*

1The Key Laboratory of Biomedical Information Engineering of Ministry of Education, Institute of Health and Rehabilitation Science, School of Life Sciences and Technology, Xi’an Jiaotong University, Xi’an, China
2National Engineering Research Center for Healthcare Devices, Guangzhou, China
3The Key Laboratory of Neuro-informatics and Rehabilitation Engineering of Ministry of Civil Affairs, Xi’an, China
4Xi’an Children’s Hospital, Xi’an, China
Edited by: Seung-Hwan Lee, Inje University Ilsan Paik Hospital, South Korea

Reviewed by: Han Zhang, University of North Carolina at Chapel Hill, United States; Heung-Il Suk, Korea University, South Korea

*Correspondence: Tian Liu, tianliu@xjtu.edu.cn
†These authors have contributed equally to this work and share first authorship

This article was submitted to Brain Imaging and Stimulation, a section of the journal Frontiers in Human Neuroscience

02 6 2021
2021
15 68728829 3 2021
03 5 2021
Copyright © 2021 Yang, Cao, Chen, Chen, Fan, Li, Wang and Liu.
2021
Yang, Cao, Chen, Chen, Fan, Li, Wang and Liu
https://creativecommons.org/licenses/by/4.0/ This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.
Goal

Brain functional networks (BFNs) constructed using resting-state functional magnetic resonance imaging (fMRI) have proven to be an effective way to understand aberrant functional connectivity in autism spectrum disorder (ASD) patients. It is still challenging to utilize these features as potential biomarkers for discrimination of ASD. The purpose of this work is to classify ASD and normal controls (NCs) using BFNs derived from rs-fMRI.

Methods

A deep learning framework was proposed that integrated convolutional neural network (CNN) and channel-wise attention mechanism to model both intra- and inter-BFN associations simultaneously for ASD diagnosis. We investigate the effects of each BFN on performance and performed inter-network connectivity analysis between each pair of BFNs. We compared the performance of our CNN model with some state-of-the-art algorithms using functional connectivity features.

Results

We collected 79 ASD patients and 105 NCs from the ABIDE-I dataset. The mean accuracy of our classification algorithm was 77.74% for classification of ASD versus NCs.

Conclusion

The proposed model is able to integrate information from multiple BFNs to improve detection accuracy of ASD.

Significance

These findings suggest that large-scale BFNs is promising to serve as reliable biomarkers for diagnosis of ASD.

autism spectrum disorder
functional MRI
convolutional neural network
brain functional network
classification
==== Body
Introduction

Autism spectrum disorder (ASD) represents a complex developmental disorder characterized by social deficits and restrictive or repetitive behaviors. Unlike other fields of medicine, psychiatry disorders lack valid physiological diagnostic criteria based on validated biomarkers (American Psychiatric Association, 2013). Mostly, ASD is diagnosed by subjective judgment of clinical symptoms and behaviors by clinicians. However, these methods require doctors to have high level of professional knowledge, and the diagnosis results are susceptible to doctors’ subjectivity. To find a more objective biomarker for identification of ASD, many researchers focus on deriving effective biomarkers such as genetics, epigenetics, body metabolism, and neuroimaging (Goldani et al., 2014). Neuroimaging is regarded as a promising non-invasive technique to uncover latent patterns of human brains. A human brain can be modeled as a complex system with various regions performing different structures and functions by using structural magnetic resonance imaging (sMRI), functional magnetic resonance imaging (fMRI), and positron emission tomography (PET) et.al. Previous neuroimaging studies have revealed alternation in both structural and functional connectivity of the brain among neurological or psychiatric disease populations (Mueller et al., 2013). Among all kinds of examination approaches, fMRI, especially resting state fMRI (rs-fMRI) recoding the changes of blood oxygen level-dependent (BOLD) signals, has been widely used for investigating mental disorders such as Alzheimer’s disease (Qureshi et al., 2019b), schizophrenia (Yan et al., 2019), and ASD (Abraham et al., 2017).

Functional magnetic resonance imaging data is organized in a 4-D matrix format with high dimensionality (∼1 million) containing both spatial and temporal information. This makes it a difficult task to directly utilize the original data as input for classification algorithms. To address the high dimensionality of the data, many dimensionality reduction technologies have been proposed (Abdi and Williams, 2010; Suk et al., 2015; Soussia and Rekik, 2018). Instead of using original fMRI data, some have proposed brain function network analysis characterizing the “relationship” between regions of interest (ROIs). Based on the fact that the cerebral blood flow refreshes the neural activity across regions of the brain, modeling functional connectivity (FC) is helpful for understanding the neural basis of mental disorder (Lindquist, 2008). The most commonly used FC model is Pearson’s correlation, which can be calculated using BOLD signals between two brain regions. A brain functional network (BFN) is constructed based on the strength of the FC of all locations predefined by an atlas. BFN construction approaches explicitly reduced the dimensionality from 4-D into a 1-D vector. Many machine learning (ML) methods have been successfully employed in the automated classification of altered BFNs related to ASD (Uddin et al., 2013; Abraham et al., 2017). Some methods adopted sparse methods to implement implicit dimension reduction by adding an extra sparse regularization term [e.g., Lasso (Tibshirani, 1996) or the Elastic Net (Zou and Hastie, 2005)] to the loss function.

However, the commonly used correlation for describing FC between ROIs just captures a linear relationship and is not suitable for characterizing high-order or non-linear features (Shojaee et al., 2019). Furthermore, collapsing the data into a feature vector (Vectorization) discards the spatial information of the brain regions (Kong et al., 2019). In addition, traditional classification algorithms such as support vector machine (SVM) (Cortes and Vapnik, 1995), Random Forest (Liaw and Wiener, 2002), and Naive Bayes (Rish, 2001) belong to a shallow model, which limits their capacity to extract the structural information hidden in BFNs.

To derive BFNs with both functional connectivity and spatial information, independent component analysis (ICA) has been widely used (Rajapakse et al., 2006; Nickerson et al., 2017). ICA is a pure data-driven method, which can generate highly reproducible large-scale brain networks (Damoiseaux et al., 2006). However, the ICA components do not correspond exactly to meaningful brain networks. Usually, these components will be inspected by experienced clinicians or researchers to remove artifact components. Here, we use an automatic clustering algorithm (Beckmann et al., 2009; Filippini et al., 2009) to perform the selection of ICA components. The selected meaningful components can be used for deriving each subject’s subject-specific spatial maps by dual regression. Each individual spatial map captures variabilities in both the shape and amplitude of the corresponding resting state network between groups (Nickerson et al., 2017). This kind of feature representation in BFNs employs a 3-D functional rs-fMRI modality, which contains more information than FC coefficients.

Recently, deep learning has gained much attention in various computer vision tasks (Redmon et al., 2016; Krizhevsky et al., 2017; Ledig et al., 2017). Deep learning has also been applied in medical image analysis, such as lesion segmentation (Isensee et al., 2018), MRI reconstruction (Schlemper et al., 2018), and registration (Yang et al., 2017). The deep neural network (DNN) is powerful for its capability to directly learn useful features from raw data and eliminate the need to manually design features in many other machine learning algorithms. Several studies have used stacking auto-encoders to build a DNN for classification of brain disorders such as Alzheimer’s disease (Suk et al., 2015), autism (Heinsfeld et al., 2018) and schizophrenia (Kim et al., 2016). In addition, recurrent neural network (RNN) and graph convolutional neural network (GCN) are also used in the early diagnosis of mental diseases. Dvornek et al. (2017) used long short-term memory (LSTM) to classify the time series data of resting-state fMRI, and the accuracy of cross-validation reached 68.5%. Yan et al. (2019) designed a multi-scale convolutional neural network-gated recurrent unit (CNN-GRU) model to learn the time series obtained from ICA and realized the classification of schizophrenia based on multi-site data. Ktena et al. (2017) took advantage of the spectral method of GCN to learn the similarity of brain functional connectivity networks and applied it to the early diagnosis of ASD. Unlike the methods mentioned above, 3-D convolutional neural network (3-D CNN) takes 3-D images as input rather than FC vector or time series data, capturing hierarchical features by integrating multi scales of features with different layers for spatial pattern representation and recognition (LeCun et al., 2015). In recent years, 3-D CNN has been successfully used in the classification of Alzheimer’s disease (Qureshi et al., 2019b), schizophrenia (Qureshi et al., 2019a), and early MCI (Kam et al., 2018), which achieved competitive performance of approximately 74–98% accuracy compared to traditional machine learning algorithms. Nevertheless, to date, 3-D CNN has not been used to classify large-scale BFNs in ASD, and the abnormal organization of the large-scale BFN in ASD subjects is not well understood. For these reasons, in the present study, we take the group ICA features as input and build a 3-D CNN architecture to model the differences in both “shape” (e.g., spatial activation patterns) and amplitude (e.g., the magnitude of the BOLD activity) of one or more BFNs, and we investigate both intra- and inter-BFN association changes to find a reliable and objective biomarker for diagnosis.

The contributions of our work can be summarized in three aspects. (1) We used group ICA and dual regression to derive 3-D functional network spatial maps as potential biomarkers for identification of ASD. (2) We developed a variant of the VGG network, which involves channel attention mechanism, to integrate both intra- and inter-BFN association changes to find a reliable and objective biomarker for diagnosis. (3) A systematic comparison of our method with traditional machine learning framework has also been implemented. Our proposed model can improve detection accuracy of ASD.

Materials and Methods

Figure 1 illustrates the overall framework for discrimination of ASD. We first preprocessed all rs-fMRI data from the NYU site using the C-PAC pipeline. The preprocessed data were used to perform group ICA to generate 30 independent components. The good components were filtered by clustering and template matching, which would be used for further analysis (Figure 1A). Second, we took the selected components to perform dual regression for each subject. Eight subject-specific spatial maps were generated and concatenated for each subject, which would be used as input for classification (Figure 1B). We then randomly split all subjects into training and validation sets. The subject-specific spatial maps were fed into a 3-D CNN model. Finally, a 10-fold cross validation strategy was adopted for the classification performance evaluation (Figure 1C).

FIGURE 1 Illustration of the proposed framework for ASD diagnosis. (A) All rs-fMRI data were preprocessed using the C-PAC pipeline. The independent components were derived using Group-ICA, and further inspected to identify eight well defined brain function networks (BFNs). (B) The selected BFNs were used to extract subject-specific spatial maps using dual regression. Eight subject-specific spatial maps were then concatenated together as input to the classifier. (C) The data were randomly split into training and validation sets. A total of 10-fold cross validation strategy was used for evaluating classification performance. The details of 3-D CNN model will be introduced later.

Dataset

We ran our study on the Autism Brain Imaging Data Exchange (ABIDE) (Di Martino et al., 2014), which is a publicly available multi-site data repository. The first phase of ABIDE (ABIDE-I) compiles a dataset of 1112 individuals from 17 sites and consists of 539 individuals with ASD and 573 typical controls. Since the scan parameters vary across sites, ABIDE is a highly heterogeneous dataset. To avoid the impact of data heterogeneity, we collected raw rs-fMRI data from the whole NYU site, consisting of 79 ASD subjects and 105 normal controls (NCs). Table 1 presents the complete demographic of the selected data.

TABLE 1 Demographics characteristics of the selected subjects.

	Autism spectrum disorder	Normal control	p-Value	
	N = 79; 11 F/68 M	N = 105; 26 F/79 M		
Age	14.52 ± 6.97	15.81 ± 6.25	0.039	
Full IQ	107.91 ± 16.62	113.15 ± 13.12	0.022	
Verbal IQ	105.81 ± 16.13	113.13 ± 12.60	0.001	
Performance IQ	108.81 ± 17.42	110.06 ± 13.67	0.600	
ADOS total	11.30 ± 4.08			
ADOS communication score	3.54 ± 1.55			
ADOS social score	7.76 ± 2.97			
ADOS, autism diagnostic observation schedule.

Structural Data Acquisition

All participants were scanned with a Siemens 3 Tesla Allegra scanner. An MPRAGE sequence was used with the following parameters: TR/TE/TI = 2530/3.25/1100 ms, flip angle = 7°, FoV read = 256 mm, slice thickness = 1.33 mm, voxel size = 1.3 × 1.0 × 1.3 mm, matrix = 256 × 256 × 171, bandwidth = 200 Hz/Px, and total scan time = 8:07 min.

Functional Data Acquisition

Resting state functional MRI data were acquired using a 2-D echo-planar imaging (EPI) acquisition type with the following parameters: TR/TE = 2000/15 ms, flip angle = 90°, FoV read = 240 mm, slice thickness = 4 mm, voxel size = 3.0 × 3.0 × 4.0 mm, bandwidth = 3906 Hz/Px, and total scan time = 6.00 min. During the rs-fMRI scan, most participants were asked to relax with their eyes open and look at a cross-hair on a black background screen. Data were also included for some participants who were asked to keep their eyes closed.

Pre-processing of Functional MRI Data

We preprocessed the data using a widely adopted pipeline called Configurable Pipeline for the Analysis of Connectomes (C-PAC) (Craddock et al., 2013), which involves skull striping, slice timing correction, realignment to correct for motion, and bandpass filtering (0.01–0.1 Hz). The functional images were smoothed with a 5-mm full width half maximum (FWHM) Gaussian kernel, registered to a standard anatomical space (MNI152) and resampled to 4 mm.

Independent Component Analysis

We used FSL Multivariate Exploratory Linear Optimized Decomposition into Independent Components (MELODIC1) version 3.15 to perform group ICA. Preprocessed data were concatenated and entered into a group ICA to identify large-scale functional networks across the population. Usually, more than 20 components are necessary for identification of meaningful components, whereas model orders >100 showed a decrease in ICA repeatability (Abou-Elseoud et al., 2010). The number of independent components was set to 30. Variance normalization and thresholding were further used to fit a Gaussian and 2 Gamma mixture model to the intensity histogram of the Z-transformed IC spatial maps.

Finally, MELODIC yielded 30 independent component maps with the local false-discovery rate p < 0.5. Among the 30 independent components, we used an automatic clustering tool, FSLNets2, to divide these independent components into good networks and noise and/or artifacts. Second, we inspected the power spectra graph for each good independent component. The power spectrum of a typical network is in the low-frequency range, whereas an artifact power spectrum shows a multipeak pattern in the 0–0.1 Hz range. Furthermore, we used an FSL utility, fslcc, to spatially correlate all 15 good components derived by FSLNets to some set of reference networks. The reference networks we used are from the Stanford Functional Imaging in Neuropsychiatric Disorders Lab3 (Shirer et al., 2012). The names of reference networks are shown in Table 2. Finally, eight functional networks were filtered as the output of group ICA. Figure 2 shows all 30 components. The dendrogram contains two major branches representing good functional networks (in blue and green color) and noise and/or artifacts (in red color). All these functional networks served as templates to generate subject-specific brain function networks in the next step.

TABLE 2 The names of reference networks.

Number	Reference network	
1	Anterior insula/dorsal ACC (anterior salience network)	
2	Auditory network	
3	Basal ganglia network	
4	PCC/MPFC (dorsal default mode network)	
5	Higher visual network	
6	Language network	
7	Left DLPFC/parietal (left executive control network)	
8	Sensorimotor network	
9	Posterior insula (posterior salience network)	
10	Precuneus network	
11	Primary visual network	
12	Right DLPFC/parietal (right executive control network)	
13	Retrosplenial cortex/medial temporal lobe (ventral default mode network)	
14	Intraparietal sulcus/frontal eye fields (visuospatial network)	

FIGURE 2 Automated clustering dendrograms of the independent component-based brain functional networks acquired through Melodic ICA. The right branch depicted in red line represents noise or artifacts. The left branch contains good components that will be further inspected via power spectrum.

Dual Regression

To evaluate individual differences in BFNs, we applied the dual regression (Beckmann et al., 2009; Nickerson et al., 2017) approach in FSL v6.0.14. This method has been widely used in comparing large-scale BFNs between groups (Filippini et al., 2009; Nickerson et al., 2017). Dual regression decomposes each subject’s 4-D fMRI data into a set of spatial maps and corresponding time courses. Dual regression is an effective approach to investigate network shape and amplitude in functional connectivity analyses (Nickerson et al., 2017). Dual regression analysis proceeds in two steps. First, for each subject, a set of template networks is regressed into the subject’s 4-D spatial-temporal dataset. This results in a set of subject-specific time courses, corresponding to each IC template. Second, the network-specific time courses are used as predictors in a multivariable multiple linear regression into the same 4-D dataset, resulting in a set of subject-specific 3-D spatial maps. The template network can be derived using FSL’s group ICA, from an atlas, or using functional localizers. Based on these 3-D spatial maps of BFNs for each subject, we build a 3-D CNN model to learn sophisticated feature representation for classification.

3-D CNN Architecture for Classification

In the present study, we implemented stratified 10-fold cross validation to evaluate the effectiveness of our algorithm. This method of splitting data ensures that the proportion of ASDs and NCs was the same across all folds.

Backbone Structure

A variant of VGG-net (Simonyan and Zisserman, 2014) was used for our task. VGG-net is a popular convolution network model that has been used in many studies (Qureshi et al., 2019a,b; Duc et al., 2020). Instead of using 2-D convolution in vanilla VGG, 3-D convolution was adopted in our network. Batch Normalization (Ioffe and Szegedy, 2015) and Leaky Rectified Linear Unit (LeakyReLU) (Maas et al., 2013) were used as activation functions. Because CNN is a highly non-convex function, poor initialization strategy may induce the CNN into a local sub-optimal solution, resulting in bad generalization performance. To alleviate this problem, we initiated our 3-D CNN with the initialization strategy proposed by He et al. (2015). The overview of our proposed CNN is shown in Figure 3.

FIGURE 3 Modified VGG-Net 3-D CNN architecture with SE module integrated.

Channel Attention Module

Vanilla VGG achieved good performance in image classification by stacking a series of convolution layers with the same kernel size of 3 × 3 × 3 and interleaved with non-linear activation and max-pooling layers. This kind of hierarchical architecture can capture local spatial patterns along all input channels. To model the independencies between channels, channel switching, combination (Zhang et al., 2017, 2018) or using reinforcement learning to reorganize the network paths (Ahmed and Torresani, 2017), channel-wise attention was proposed to bias the allocation of resources to the most informative channels (Hu et al., 2018). The squeeze and excitation (SE) module is an efficient component that can be added to any CNN model easily. The key point of SE module is that it can calibrate the feature map and emphasize important channels by learning a channel-specific descriptor. We integrated several SE blocks into the variant VGG structure to boost classification performance.

The SE module consists of two parts, squeeze and excitation. A diagram of an SE building block is depicted in Figure 4. Let us assume that U = [u1, u2,…,uF] is an input feature map, where ufϵℝH×W×D is a single channel with size H × W × D. H,W and D are the spatial height, width, and depth, respectively. Channel squeeze is performed via a global average pooling layer, productor vector zϵℝ1×1×1×F, with the f-th element given by:

FIGURE 4 Architecture of squeeze and excitation (SE) module.

(1) zf=1H×W×D⁢∑h=1H∑w=1W∑d=1D[uf]i,j,k

This operation embeds the global spatial information into vector z. To make full use of the information hidden in z, an excitation operation is designed. Two fully connected layers, the ReLU (Nair and Hinton, 2010) function δ and a sigmoid activation function σ(⋅), are used to transform z:

(2) s=σ⁢(W1⁢δ⁢(W2⁢z))

where W1⁢ϵ⁢ℝFr×F, W2⁢ϵ⁢ℝF×Fr and r is the reduction ratio to limit the model complexity and aid generalization. s encodes the channel-wise dependencies and is used to excite or recalibrate U to:

(3) U^=Fs⁢c⁢a⁢l⁢e⁢(uf,sf)=sf⋅uf,for⁢f=1,2,⋯,F

where Fs⁢c⁢a⁢l⁢e⁢(uf,z^f) for the channel-wise multiplication between the feature map ufϵℝH×W×D and the scalar sf. The importance of the i-th channel is indicated by sf ∈ [0,1].

Here, we inserted three SE blocks into the 3-D VGG net. The reduction ratio was set to 16. Details of our model are presented in Table 3.

TABLE 3 Details of the proposed MCSE-VGG architecture.

Layer	Feature map	Stride	Kernel	Activation structure	
Convolution	32	1 ×1 ×1	3 ×3 ×3	Conv	
SE block			
Convolution	32	1 ×1 ×1	3 ×3 ×3	BN + LReLU + Conv	
Max-pooling		2 ×2 ×2	2 ×2 ×2		
SE block	32		
Convolution	64	1 ×1 ×1	3 ×3 ×3	BN + LReLU + Conv	
Convolution	64	1 ×1 ×1	3 ×3 ×3	BN + LReLU + Conv	
Max-pooling	64	2 ×2 ×2	2 ×2 ×2		
SE block					
Convolution	128	1 ×1 ×1	3 ×3 ×3	BN + LReLU + Conv	
Convolution	128	1 ×1 ×1	3 ×3 ×3	BN + LReLU + Conv	
Convolution	128	1 ×1 ×1	3 ×3 ×3	BN + LReLU + Conv	
Max-pooling		2 ×2 ×2	2 ×2 ×2		
Convolution	256	1 ×1 ×1	3 ×3 ×3	BN + LReLU + Conv	
Convolution	256	1 ×1 ×1	3 ×3 ×3	BN + LReLU + Conv	
Convolution	156	1 ×1 ×1	3 ×3 ×3	BN + LReLU + Conv	
Max-pooling		2 ×2 ×2	2 ×2 ×2		
Convolution	256	1 ×1 ×1	3 ×3 ×3	BN + LReLU + Conv	
Convolution	256	1 ×1 ×1	3 ×3 ×3	BN + LReLU + Conv	
Convolution	256	1 ×1 ×1	3 ×3 ×3	BN + LReLU + Conv	
Convolution	2048	1 ×1 ×1	3 ×3 ×3	Dropout + Conv + LReLU	
Convolution	1024	1 ×1 ×1	1 ×1 ×1	Dropout + Conv + LReLU	
Dense	2		
MCSE-VGG, multi channel squeeze and excitation VGG-net; LReLU, Leaky Rectified Linear Unit.

Performance Evaluation

For performance evaluation, we adopted accuracy (ACC), precision, recall, and F1 score as quantitative metrics. TP, TN, FP, FN, PPV, and NPV denote true positive, true negative, false positive, false negative, positive predictive value, and negative predictive value, respectively. These metrics are defined as below:

A⁢C⁢C=T⁢P+T⁢NT⁢P+T⁢N+F⁢P+F⁢N

P⁢r⁢e⁢c⁢i⁢s⁢i⁢o⁢n=T⁢PT⁢P+F⁢N

R⁢e⁢c⁢a⁢l⁢l=T⁢NT⁢N+F⁢P

F⁢1=2×Precision×RecallP⁢r⁢e⁢c⁢i⁢s⁢i⁢o⁢n+R⁢e⁢c⁢a⁢l⁢l

Results

Large-Scale Brain Functional Networks

In total, eight components (Figure 5) were identified as BFNs from group ICA. The eight selected resting state functional networks included the primary visual network (PVN), dorsal default mode network (dDMN), ventral default mode network (vDMN), precuneus network (PCUN), sensorimotor network (SMN), anterior salience network (SN), left central executive network (LCEN), and right central executive network (RCEN). They were used to perform dual regression to generate subject-specific time courses for connectivity analysis and spatial maps for classification.

FIGURE 5 Eight large-scale resting state brain functional networks derived using group independent component analysis (gICA): primary visual network (A), dorsal default mode (B), ventral default mode (C), precuneus network (D), sensorimotor network (E), anterior salience (F), left central executive (G), right central executive (H).

Network Configuration

We applied PyTorch (Paszke et al., 2019) 1.0 framework to implement our model. Training and testing of this model used one NVIDIA RTX 2080Ti graphical processing unit (GPU). During the training phase, an ADAM (Kingma and Ba, 2014) optimizer was used with an initial learning rate of 0.0005. The initialization strategy proposed by He et al. (2015) was adopted to initiate the 3-D CNN model. The learning rate was decayed by 0.1 if the validation loss did not decrease after 10 epochs. The batch size was set to 12, and the negative slope LeakyReLU was set as 0.01. We used L2 norm regularization on the convolution kernel parameters with a weight of 1e-5. Dropout was set as 0.7. The cross-entropy loss function is applied to the output units to predict the probability of a subject belonging to the NC or ASD group. The results of the validation set of each fold will be shown in the next section.

Performance Evaluation

Baseline

First, we padded subject-specific spatial maps of each BFN into 48 × 56 × 48 and then concatenated them into a 4-D tensor of 8 × 48 × 56 × 48 for each subject. The first dimension represents the number of selected BFNs. All eight selected components are associated with high-level recognition functions, which include the primal visual network, PCUN, default mode network (DMN), SN, executive control networks and SMN. We took this 4-D tensor as input to train a vanilla VGG model as baseline.

Channel Attention Based 3-D CNN

Here, we conducted two kinds of 3-D CNN integrated with the SE module. One consists of taking each BFN separately into SE-VGG to construct a single channel SE-VGG (SCSE-VGG) diagnosis model. Figure 6 shows the ability to discriminate ASD from NC based on spatial maps corresponding to each of the 8 functional networks for each subject using SE-VGG. Another option is to concatenate 8 BFNs as multi-channel input to SE-VGG (MCSE-VGG). In Table 4, we summarize the performance of our proposed method. Our experiments showed that the MCSE-VGG model outperformed other models by achieving a mean accuracy of 77.74%, which significantly boosted the performance of the baseline model by ∼8%. Compared to various SCSE-VGG models using only one BFN, the proposed MCSE-VGG improved the accuracy by ∼4–12%. The results showed that our proposed method could effectively capture the relationship within multiple BFNs. In addition, the SE block could assist the 3-D CNN learning from multiple BFNs and effectively model the channel-interdependencies information. Among all 8 SESE-VGG models, SESE-VGG with the PCUN, dDMN, and SN showed higher accuracy than those with other BFNs. This indicated that these three networks might play an important role in the development of ASD.

FIGURE 6 Classification accuracy for each identified brain function network (BFN). Each BFN spatial map was used as input features and fed into SCSE-VGG model for classification. The precuneus network achieved the highest accuracy at 74%.

TABLE 4 Classification results comparison of different network architectures using 10-fold cross-validation.

Method	Functional network	ACC (%)	Precision (%)	Recall (%)	F1 score	
Baseline	All	69.58	69.43	65.54	67.43	
SCSE-VGG	PVN	65.21	68.10	50.54	50.02	
	PCUN	74.01	71.76	77.32	74.44	
	dDMN	71.18	73.38	68.57	70.89	
	vDMN	68.49	64.22	65.54	64.87	
	LCEN	68.53	70.67	56.96	63.08	
	RCEN	68.68	66.62	89.82	76.50	
	SN	71.16	77.06	61.96	68.69	
	SMN	69.57	71.19	64.82	67.86	
MCSE-VGG	All	77.74	76.74	78.57	75.33	
The baseline and MCSE-VGG models use all the eight brain functional networks. MCSE-VGG and SCSE-VGG models are inserted with SE module. SCSE-VGG models are evaluated for each brain functional network.

Compared Methods

We compared the proposed SCSE-VGG with several state-of-the-art methods including both traditional machine learning algorithms and deep learning methods. We extracted the mean time series for ROI defined by the CC200 functional parcellation atlas of the brain. The functional connectivity was calculated by Pearson correlation between each pair of brain regions and generated a correlation matrix. The upper triangle values of the correlation matrix were vectorized as features and fed into an Autoencoder and Multilayer Perceptron (AE-MLP) model. We modified the code from Heinsfeld et al. (2018) and implemented three algorithms, e.g., deep neural network (Heinsfeld et al., 2018), SVM (Cortes and Vapnik, 1995) and random forest (RF) (Liaw and Wiener, 2002), on the NYU dataset. Bengs et al. (2020) used the 4-D fMRI image data and modeled the spatial-temporal information by 3-D convolutional GRU and 3-D CNN. We reported their experimental results on the NYU dataset. We show the results from these models in Table 5.

TABLE 5 Performance comparison of the proposed and previous methods.

Method	ACC (%)	F1 score	
AE-MLP	68.56	73.87	
SVM	62.97	74.24	
Random forest	60.62	71.37	
convGRU-CNN3D (Bengs et al., 2020)	67.00	71.00	
VGG (ours)	69.58	67.43	
MCSE-VGG (ours)	77.74	75.33	
The results of convGRU-CNN3D were reported on the paper (Bengs et al., 2020).

Deep learning-based classification frameworks (including AE-MLP, convGRU-CNN3D, and our proposed model) showed better performance than traditional machine learning-based frameworks (including SVM and RF). The results showed that our proposed model (MCSE-VGG) outperformed other models by achieving a mean accuracy and F1 score of 77.74 and 75.33%, respectively, which surpassed previous studies by ∼9–17 and ∼1–8%. This improvement may be due to the ability of 3-D CNN to make use of the features hidden in both inter- and intra-BFN. 3-D convolution kernel is powerful for extracting spatial information within each BFN, and the channel attention mechanism can further recalibrate the importance of spatial features extracted by convolution layers.

Inter-Network Connectivity Analysis

Although our experiments have shown good performances compared to existing methods, the deep learning framework lacks interpretability. To further validate the effectiveness of our selected BFNs to serve as reliable imaging biomarkers for ASD diagnosis, we performed an inter-network analysis on the basis of the dual regression results using the FSLNets package5. The time courses derived by stage one of the dual regression were used as input for the modeling network. Artifactual components were regressed out over the corresponding time courses, and only the selected eight components were preserved and considered for subsequent statistical analysis. We took ridge regression partial correlation (PC) as a measure of direct connections (Smith et al., 2011) between each pair of components. The correlation coefficients were then transformed into Z-values via the standard Fisher’s transform. The PC matrices were used as input to the general linear model (GLM) analysis, and an unpaired nonparametric test with 5000 permutations was run to test differences in connection strength between ASD and NC.

We selected the most significant network edges (p = 0.05) from the GLM output and created boxplots for the two groups as illustrated in Figure 7. As a result, the strengths of connectivity were significantly increased between the SN and dDMN in ASD patients compared to controls. A similar result was also found between the SN and LCEN. Furthermore, a reduced connective strength was obtained between the PCUN and dDMN.

FIGURE 7 Box plot of the connectivity differences in ASD versus NC. Connectivity strength is shown for the brain functional networks (BFN) between (A) anterior salience network (SN) and dorsal default mode network (dDMN) and (B) SN and left central executive network (LCEN), and (C) precuneus network (PCUN) and dDMN.

Discussion

In this study, we proposed a novel framework to model inter- and intra-associations of multiple large-scale BFNs derived from rs-fMRI by using a 3-D CNN deep learning architecture for ASD diagnosis. Instead of using 1-D time-series information, we used subject-specific BFN spatial maps to capture the spatial patterns via 3-D convolution. Channel attention blocks were integrated into our CNN model to fuse the deep features of multiple BFNs. We evaluated our proposed method on a public dataset and achieved the best performance compared with previous classifications (Heinsfeld et al., 2018; Bengs et al., 2020). Our proposed framework can be easily generalized to the diagnosis of other mental illnesses such as Alzheimer’s, schizophrenia and depression.

Our results showed a mean test accuracy of 77.74% in a 10-fold cross validation experiment using the MCSE-VGG deep learning algorithm. In our proposed algorithm, the input data is multi-channel tensor, and each channel corresponds to one subject-specific BFN. Convolutional layers extract the most important spatial information from these BFNs in a hierarchical way with different layers. The SE module can further integrate and recalibrate these spatial features from different BFNs before they are fed into the next transformation. The introduction of the SE module improves the accuracy of the VGG model by ∼8%. Heinsfeld et al. (2018) proposed to use deep autoencoder network for the classification of ASD. They built a multilayer perceptron (MLP) and applied the encoder weights to the MLP. Only the last layer of MLP was adjusted to output the expected classes. They used functional connectivity features calculated by correlation between each pair of ROIs, which was different from our input features. Some works also used 3-D BFNs as features and developed a 3-D CNN for discrimination of mental illness, e.g., Alzheimer’s dementia (Qureshi et al., 2019b) and schizophrenia (Qureshi et al., 2019a). These studies treated every BFN equally and did not model the contribution of different brain networks to classification results.

The ultimate goal of our proposed framework is to identify a collection of reliable biomarkers for ASD diagnosis. Although deep learning has shown great potential in classification, the lack of interpretability restricts its application in the clinic. To determine the effect of each BFN on the neural network, we used each individual BFN as input features to train a SCSE-VGG model. The results showed that dDMN, PCUN, and SN achieved better accuracies than others. These three brain networks might be the most important features that can boost the performance of MCSE-VGG significantly. Table 6 lists Brodmann areas of these networks.

TABLE 6 Anatomical labels of the identified brain functional networks.

BFN	Anatomical location of functional ROIs	Brodmann areas	
PCC/MPFC (dDMN)	Medial prefrontal cortex, anterior cingulate cortex, orbitofrontal cortex	9, 10, 24, 32, 11	
	Right superior frontal gyrus	9	
	Posterior cingulate cortex, precuneus	23, 30	
	Midcingulate cortex	23	
	Left and right angular gyrus	39	
	Left and right thalamus	N/A	
	Left and right hippocampus	20, 36, 30	
PCUN	Midcingulate cortex, posterior cingulate cortex	23	
	Precuneus	7, 19	
	Left and right angular gyrus	7, 40	
Insula/dACC (SN)	Left middle frontal gyrus	9, 46	
	Left and right insula	48, 47	
	Anterior cingulate cortex, medial prefrontal cortex, supplementary motor area	23, 32, 8, 6	
	Right middle frontal gyrus	46, 9	
	Left lobule VI, crus I	N/A	
	Right lobule VI, crus I	N/A	

Both dDMN and PCUN are subnetworks of the DMN comprising the posterior cingulate cortex (PCC), precuneus, medial prefrontal cortex (MPFC), temporoparietal junction (TPJ), and hippocampus (Raichle et al., 2001; Buckner et al., 2008). The DMN is engaged in a range of social cognitive processes including self-referential and autobiographical processing and mentalizing and theory of mind (Padmanabhan et al., 2017). In particular, the PCC and MPFC, the two most notable nodes of the DMN, are involved with social cognition (Schilbach et al., 2008; Spreng et al., 2009; Mars et al., 2012). The PCC is considered to be the core functional node with a high basal metabolic rate (Raichle et al., 2001). The PCC is mainly engaged in both self-relevant and other-relevant processing and evaluating and processing mental states of others (Gusnard and Raichle, 2001; Schiller et al., 2009; Spreng et al., 2009; Kuzmanovic et al., 2012). The MPFC is linked to monitoring of the mental state of both oneself and others (Gusnard and Raichle, 2001; Schilbach et al., 2008). There is a large amount of literature indicating that abnormal DMN organization is related to social deficits in individuals with ASD (Lynch et al., 2013; Yerys et al., 2015; Ypma et al., 2016). Increased within-network connectivity between the PCC and the MPFC was commonly observed in childhood ASD, while no consistent evidence was found for DMN connectivity across a whole ASD cohort (Doyle-Thomas et al., 2015).

In addition to the DMN and PCUN, the SN has achieved higher classification accuracy at 71.16%. The SN is identified as an intrinsic network that guides behaviors to internal and environmental stimuli (Seeley et al., 2007). The SN exhibited hyper connectivity in children with ASD (Uddin et al., 2013). The anterior insula (AI) and dorsal anterior cingulate cortex (dACC) serve as the two most notable hubs of the SN. The AI is linked to emotion processing and is hypo-activated in ASD cohorts when performing a series of social cognitive tasks (Di Martino et al., 2009). The dACC has showed reduced cognitive control over behavior in ASD (Agam et al., 2010). Restrictive and repetitive behaviors in ASD may be due to the dysfunction of the salience network, which atypically allocates attention to extraneous sensory stimuli rather than relevant social stimuli (Uddin et al., 2013). Our experiments on each individual BFN suggest that the dDMN, PCUN, and SN are highly different between ASD and NC, which is consistent with previous studies. These three most significant brain networks have the potential to be reliable biomarkers for the identification of ASD.

To further validate that our proposed method can capture the interaction between different BFNs, we also considered the relationship between BFNs. A quantitative measure of the connectivity strength value was calculated between each pair of BFNs. The results of statistical analysis suggested that there were significant differences in three pairs of BFNs (at a p-value < 0.05). The SN-dDMN and SN-LCEN pairs showed increased connectivity strength in ASD, and hypo-connectivity was observed in the PCUN-dDMN pair of ASD. The SN is thought to play a role in detecting and coordinating a response to salient interoceptive and exteroceptive stimuli, including modulating the DMN and CEN as necessary (Menon, 2011), while aberrant interactions between these networks may lead to various mental illnesses. The enhanced connectivity between the SN and DMN and between the SN and CEN in ASD compared to NC may suggest the aberrant function of the SN, resulting in abnormal saliency mapping of internal mental events and external stimuli. Our work is consistent with the evidence implicating SN dysfunction in psychopathology in ASD (Uddin, 2015; Burrows et al., 2017). Both the PCUN and dDMN include brain regions previously regarded as being part of the DMN (Broyd et al., 2009). The decreased connectivity within the DMN has also been found in previous literature (Assaf et al., 2010). Our findings support the under-connectivity hypnosis in autism proposed by Just et al. (2004). Although no significant differences were found in other pairs of BFNs, the proposed MCSE-VGG is potentially able to capture the interactions among these BFNs, which take both inter- and intra-BFN information into consideration.

Our work still has a few limitations. First, a separate validation dataset is unavailable. The dataset we used is a part of the ABIDE-I dataset, which contained the largest samples with the same scan parameters. However, ABIDE-I is a highly heterogeneous dataset in which the scanning parameters, especially TR and the total scan time of each site, are different from each other. This leads to difficulty in performing group-ICA and dual regression. Yan et al. (2019) developed an RNN framework for discriminating schizophrenia using multi-site fMRI data. However, in their study, the scan protocols were set up by the same experts across all sites, which overcomes the heterogeneity over multi-sites. Therefore, we evaluated our framework only in the NYU dataset and showed ten-fold cross-validation results. Data augmentation has been widely used in many other computer vision tasks, but it is not suitable for neuroimaging data. We do not think synthesized data and real data have the same distribution. Second, motion effects can mimic amplitude effects and may have an impact on the results of dual regression (Nickerson et al., 2017). Motion effects may still remain even though we performed motion correction in the preprocessing procedures. ICA-based denoising technology was proposed to derive reproducible group-level resting state network spatial maps (Pruim et al., 2015), which we will consider using in the preprocessing stage. Another limitation is that deep learning-based classification framework is lacking in interpretation but is important, especially in the medical field. To overcome this issue, we statistically analyzed the differences between each pair of BFNs between ASD and NC. In the future, we will pay more attention to developing a framework integrating both structural and functional MRI data to achieve better classification accuracy, which may provide us with more insights into ASD.

Conclusion

In conclusion, we proposed a novel framework to model the spatial patterns of BFNs and associations between BFNs, simultaneously. We demonstrated the effectiveness of the introduction of the SE module, which is useful for modeling large-scale brain networks. Aberrant inter-network connectivity was observed in ASD, which may be related to the disorder of brain function. Our work has great application potential in the discrimination of other mental illnesses, not just ASD.

Data Availability Statement

The original contributions presented in the study are included in the article/supplementary material, further inquiries can be directed to the corresponding author/s.

Author Contributions

MY and MC had equal contributions in data preparation, data analysis, and preparing the first draft of the manuscript. YuC and YaC interpreted the data and proofread the manuscript. GF and CL put forward some useful suggestions for the project. JW and TL conceptualized, directed the overall project, and prepared the final version. All authors contributed to the article and approved the submitted version.

Conflict of Interest

The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.

Funding. This work has been supported by the National Natural Science Foundation of China (Grant 61503295); the Natural Science Foundation of Shaanxi Province (Grant 2018JM7080); China Postdoctoral Science Foundation (Grant No. 2018M643672); and Fundamental Research Funds for the Central Universities (Grant No. xjh012019049).

1 http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/MELODIC

2 https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSLNets

3 http://findlab.stanford.edu/research

4 http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/DualRegression

5 http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSLNets
==== Refs
References

Abdi H. Williams L. J. (2010). Principal component analysis. WIREs Comput. Stat. 2 433–459. 10.1002/wics.101
Abou-Elseoud A. Starck T. Remes J. Nikkinen J. Tervonen O. Kiviniemi V. (2010). The effect of model order selection in group PICA. Hum. Brain Mapp. 31 1207–1216. 10.1002/hbm.20929 20063361
Abraham A. Milham M. P. Di Martino A. Craddock R. C. Samaras D. Thirion B. (2017). Deriving reproducible biomarkers from multi-site resting-state data: an autism-based example. Neuroimage 147 736–745. 10.1016/j.neuroimage.2016.10.045 27865923
Agam Y. Joseph R. M. Barton J. J. S. Manoach D. S. (2010). Reduced cognitive control of response inhibition by the anterior cingulate cortex in autism spectrum disorders. Neuroimage 52 336–347. 10.1016/j.neuroimage.2010.04.010 20394829
Ahmed K. Torresani L. (2017). Connectivity learning in multi-branch networks. arXiv [Preprint] arXiv:1709.09582,
American Psychiatric Association (2013). Diagnostic and Statistical Manual of Mental Disorders (DSM-5®). Washington, DC: American Psychiatric Pub.
Assaf M. Jagannathan K. Calhoun V. D. Miller L. Stevens M. C. Sahl R. (2010). Abnormal functional connectivity of default mode sub-networks in autism spectrum disorder patients. Neuroimage 53 247–256. 10.1016/j.neuroimage.2010.05.067 20621638
Beckmann C. F. Mackay C. E. Filippini N. Smith S. M. (2009). Group comparison of resting-state FMRI data using multi-subject ICA and dual regression. Neuroimage 47 S39–S41. 10.1016/S1053-8119(09)71511-3
Bengs M. Gessert N. Schlaefer A. (2020). 4D spatio-temporal deep learning with 4d fmri data for autism spectrum disorder classification. arXiv [Preprint] arXiv:2004.10165,
Broyd S. J. Demanuele C. Debener S. Helps S. K. James C. J. Sonuga-Barke E. J. S. (2009). Default-mode brain dysfunction in mental disorders: a systematic review. Neurosci. Biobehav. Rev. 33 279–296. 10.1016/j.neubiorev.2008.09.002 18824195
Buckner R. L. Andrews-Hanna J. R. Schacter D. L. (2008). “The brain’s default network: anatomy, function, and relevance to disease,” in The Year in Cognitive Neuroscience 2008. Annals of the New York Academy of Sciences, eds Kingstone A. Miller M. B. (Hoboken, NJ: Blackwell Publishing), 1–38.
Burrows C. A. Timpano K. R. Uddin L. Q. (2017). Putative brain networks underlying repetitive negative thinking and comorbid internalizing problems in autism. Clin. Psychol. Sci. 5 522–536. 10.1177/2167702616683506 28603665
Cortes C. Vapnik V. (1995). Support-vector networks. Mach. Learn. 20 273–297. 10.1007/BF00994018
Craddock C. Sikka S. Cheung B. Khanuja R. Ghosh S. S. Yan C. (2013). Towards automated analysis of connectomes: the configurable pipeline for the analysis of connectomes (c-pac). Front. Neuroinform. 42 :10.3389 . 10.3389/conf.fninf.2014.08.00117
Damoiseaux J. S. Rombouts S. A. R. B. Barkhof F. Scheltens P. Stam C. J. Smith S. M. (2006). Consistent resting-state networks across healthy subjects. Proc. Natl. Acad. Sci. U.S.A. 103 13848–13853. 10.1073/pnas.0601417103 16945915
Di Martino A. Ross K. Uddin L. Q. Sklar A. B. Castellanos F. X. Milham M. P. (2009). Functional brain correlates of social and nonsocial processes in autism spectrum disorders: an activation likelihood estimation meta-analysis. Biol. Psychiatry 65 63–74. 10.1016/j.biopsych.2008.09.022 18996505
Di Martino A. Yan C.-G. Li Q. Denio E. Castellanos F. X. Alaerts K. (2014). The autism brain imaging data exchange: towards a large-scale evaluation of the intrinsic brain architecture in autism. Mol. Psychiatry 19 659–667. 10.1038/mp.2013.78 23774715
Doyle-Thomas K. A. R. Lee W. Foster N. E. V. Tryfon A. Ouimet T. Hyde K. L. (2015). Atypical functional brain connectivity during rest in autism spectrum disorders. Ann. Neurol. 77 866–876. 10.1002/ana.24391 25707715
Duc N. T. Ryu S. Qureshi M. N. I. Choi M. Lee K. H. Lee B. (2020). 3D-deep learning based automatic diagnosis of Alzheimer’s disease with joint MMSE prediction using resting-state fMRI. Neuroinformatics 18 71–86. 10.1007/s12021-019-09419-w 31093956
Dvornek N. C. Ventola P. Pelphrey K. A. Duncan J. S. (2017). “Identifying Autism from Resting-State fMRI Using Long Short-Term Memory Networks BT–Machine Learning in Medical Imaging,” in International Workshop on Machine Learning in Medical Imaging, eds Wang Q. Shi Y. Suk H.-I. Suzuki K. (Cham: Springer International Publishing), 362–370.
Filippini N. MacIntosh B. J. Hough M. G. Goodwin G. M. Frisoni G. B. Smith S. M. (2009). Distinct patterns of brain activity in young carriers of the APOE-ε4 allele. Proc. Natl. Acad. Sci. U.S.A. 106 7209–7214. 10.1073/pnas.0811879106 19357304
Goldani A. A. S. Downs S. R. Widjaja F. Lawton B. Hendren R. L. (2014). Biomarkers in autism. Front. Psychiatry 5 :100 . 10.3389/fpsyt.2014.00100 25161627
Gusnard D. A. Raichle M. E. (2001). Searching for a baseline: functional imaging and the resting human brain. Nat. Rev. Neurosci. 2 685–694. 10.1038/35094500 11584306
He K. Zhang X. Ren S. Sun J. (2015). “Delving deep into rectifiers: surpassing human-level performance on imagenet classification,” in Proceedings of the IEEE International Conference on Computer Vision, Santiago, Chile, 1026–1034.
Heinsfeld A. S. Franco A. R. Craddock R. C. Buchweitz A. Meneguzzi F. (2018). Identification of autism spectrum disorder using deep learning and the ABIDE dataset. Neuroimage Clin. 17 16–23. 10.1016/j.nicl.2017.08.017 29034163
Hu J. Shen L. Sun G. (2018). “Squeeze-and-excitation networks,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, 7132–7141.
Ioffe S. Szegedy C. (2015). “Batch Normalization: accelerating Deep Network Training by Reducing Internal Covariate Shift,” in Proceedings of the International Conference on Machine Learning, eds Bach F. Blei D. (Lille: PMLR), 448–456.
Isensee F. Kickingereder P. Wick W. Bendszus M. Maier-Hein K. H. (2018). “Brain tumor segmentation and radiomics survival prediction: contribution to the BRATS 2017 Challenge,” in International MICCAI Brainlesion Workshop, eds Crimi A. Bakas S. Kuijf H. Menze B. Reyes M. (Cham: Springer International Publishing), 287–297.
Just M. A. Cherkassky V. L. Keller T. A. Minshew N. J. (2004). Cortical activation and synchronization during sentence comprehension in high-functioning autism: evidence of underconnectivity. Brain 127 1811–1821. 10.1093/brain/awh199 15215213
Kam T.-E. Zhang H. Shen D. (2018). “A Novel Deep Learning Framework on Brain Functional Networks for Early MCI Diagnosis,” in Medical Image Computing and Computer Assisted Intervention–MICCAI 2018, eds Frangi A. F. Schnabel J. A. Davatzikos C. Alberola-López C. Fichtinger G. (Cham: Springer International Publishing), 293–301.
Kim J. Calhoun V. D. Shim E. Lee J.-H. (2016). Deep neural network with weight sparsity control and pre-training extracts hierarchical features and enhances classification performance: evidence from whole-brain resting-state functional connectivity patterns of schizophrenia. Neuroimage 124 127–146. 10.1016/j.neuroimage.2015.05.018 25987366
Kingma D. P. Ba J. (2014). Adam: a method for stochastic optimization. arXiv [Preprint] arXiv:1412.6980,
Kong R. Li J. Orban C. Sabuncu M. R. Liu H. Schaefer A. (2019). Spatial topography of individual-specific cortical networks predicts human cognition, personality, and emotion. Cereb. Cortex 29 2533–2551. 10.1093/cercor/bhy123 29878084
Krizhevsky A. Sutskever I. Hinton G. E. (2017). ImageNet classification with deep convolutional neural networks. Commun. ACM 60 84–90. 10.1145/3065386
Ktena S. I. Parisot S. Ferrante E. Rajchl M. Lee M. Glocker B. (2017). “Distance metric learning using graph convolutional networks: Application to functional brain networks,” in International Conference on Medical Image Computing and Computer-Assisted Intervention. Cham: Springer, 469–477.
Kuzmanovic B. Bente G. von Cramon D. Y. Schilbach L. Tittgemeyer M. Vogeley K. (2012). Imaging first impressions: distinct neural processing of verbal and nonverbal social information. Neuroimage 60 179–188. 10.1016/j.neuroimage.2011.12.046 22227133
LeCun Y. Bengio Y. Hinton G. (2015). Deep learning. Nature 521 436–444. 10.1038/nature14539 26017442
Ledig C. Theis L. Huszár F. Caballero J. Cunningham A. Acosta A. (2017). “Photo-realistic single image super-resolution using a generative adversarial network,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Hawaii, 4681–4690.
Liaw A. Wiener M. (2002). Classification and regression by randomForest. R News 2 18–22.
Lindquist M. A. (2008). The statistical analysis of fMRI data. Stat. Sci. 23 439–464. 10.1214/09-STS282
Lynch C. J. Uddin L. Q. Supekar K. Khouzam A. Phillips J. Menon V. (2013). Default mode network in childhood autism: posteromedial cortex heterogeneity and relationship with social deficits. Biol. Psychiatry 74 212–219. 10.1016/j.biopsych.2012.12.013 23375976
Maas A. L. Hannun A. Y. Ng A. Y. (2013). “Rectifier nonlinearities improve neural network acoustic models,” in Proceedings of the International Conference on Machine Learning (ICML), (Princeton, NJ: Citeseer), 3.
Mars R. Neubert F.-X. Noonan M. Sallet J. Toni I. Rushworth M. (2012). On the relationship between the “default mode network” and the “social brain.”. Front. Hum. Neurosci. 6 :189 . 10.3389/fnhum.2012.00189 22737119
Menon V. (2011). Large-scale brain networks and psychopathology: a unifying triple network model. Trends Cogn. Sci. 15 483–506. 10.1016/j.tics.2011.08.003 21908230
Mueller S. Keeser D. Samson A. C. Kirsch V. Blautzik J. Grothe M. (2013). Convergent findings of altered functional and structural brain connectivity in individuals with high functioning autism: a multimodal MRI study. PLoS One 8 :e67329 . 10.1371/journal.pone.0067329 23825652
Nair V. Hinton G. E. (2010). “Rectified linear units improve restricted boltzmann machines,” in Proceedings of the 27th International Conference on International Conference on Machine Learning Icml, Haifa.
Nickerson L. D. Smith S. M. Öngür D. Beckmann C. F. (2017). Using dual regression to investigate network shape and amplitude in functional connectivity analyses. Front. Neurosci. 11 :115 . 10.3389/fnins.2017.00115 28348512
Padmanabhan A. Lynch C. J. Schaer M. Menon V. (2017). The default mode network in autism. Biol. Psychiatry Cogn. Neurosci. Neuroimaging 2 476–486. 10.1016/j.bpsc.2017.04.004 29034353
Paszke A. Gross S. Massa F. Lerer A. Bradbury J. Chanan G. (2019). Pytorch: an imperative style, high-performance deep learning library. arXiv [Preprint] arXiv:1912.01703,
Pruim R. H. R. Mennes M. Buitelaar J. K. Beckmann C. F. (2015). Evaluation of ICA-AROMA and alternative strategies for motion artifact removal in resting state fMRI. Neuroimage 112 278–287. 10.1016/j.neuroimage.2015.02.063 25770990
Qureshi M. N. I. Oh J. Lee B. (2019a). 3D-CNN based discrimination of schizophrenia using resting-state fMRI. Artif. Intell. Med. 98 10–17. 10.1016/j.artmed.2019.06.003 31521248
Qureshi M. N. I. Ryu S. Song J. Lee K. H. Lee B. (2019b). Evaluation of functional decline in Alzheimer’s dementia using 3D deep learning and group ICA for rs-fMRI measurements. Front. Aging Neurosci. 11 :8 . 10.3389/fnagi.2019.00008 30804774
Raichle M. E. MacLeod A. M. Snyder A. Z. Powers W. J. Gusnard D. A. Shulman G. L. (2001). A default mode of brain function. Proc. Natl. Acad. Sci. U.S.A. 98 676–682. 10.1073/pnas.98.2.676 11209064
Rajapakse J. C. Tan C. L. Zheng X. Mukhopadhyay S. Yang K. (2006). Exploratory analysis of brain connectivity with ICA. IEEE Eng. Med. Biol. Mag. 25 102–111. 10.1109/MEMB.2006.1607674 16568942
Redmon J. Divvala S. Girshick R. Farhadi A. (2016). “You only look once: Unified, real-time object detection,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, NV, 779–788.
Rish I. (2001). “An empirical study of the naive Bayes classifier,” in Proceedings of the IJCAI 2001 Workshop on Empirical Methods in Artificial Intelligence, (New York, NY: IBM), 41–46.
Schilbach L. Eickhoff S. B. Rotarska-Jagiela A. Fink G. R. Vogeley K. (2008). Minds at rest? Social cognition as the default mode of cognizing and its putative relationship to the “default system” of the brain. Conscious. Cogn. 17 457–467. 10.1016/j.concog.2008.03.013 18434197
Schiller D. Freeman J. B. Mitchell J. P. Uleman J. S. Phelps E. A. (2009). A neural mechanism of first impressions. Nat. Neurosci. 12 :508 . 10.1038/nn.2278 19270690
Schlemper J. Caballero J. Hajnal J. V. Price A. N. Rueckert D. (2018). A deep cascade of convolutional neural networks for dynamic MR image reconstruction. IEEE Trans. Med. Imaging 37 491–503. 10.1109/TMI.2017.2760978 29035212
Seeley W. W. Menon V. Schatzberg A. F. Keller J. Glover G. H. Kenna H. (2007). Dissociable intrinsic connectivity networks for salience processing and executive control. J. Neurosci. 27 2349–2356. 10.1523/JNEUROSCI.5587-06.2007 17329432
Shirer W. R. Ryali S. Rykhlevskaia E. Menon V. Greicius M. D. (2012). Decoding subject-driven cognitive states with whole-brain connectivity patterns. Cereb. Cortex 22 158–165. 10.1093/cercor/bhr099 21616982
Shojaee A. Li K. Atluri G. (2019). “A machine learning framework for accurate functional connectome fingerprinting and an application of a siamese network,” in International Workshop on Connectomics in Neuroimaging, eds Schirmer M. D. Venkataraman A. Rekik I. Kim M. Chung A. W. (Cham: Springer International Publishing), 83–94.
Simonyan K. Zisserman A. (2014). Very deep convolutional networks for large-scale image recognition. arXiv [Preprint] arXiv:1409.1556,
Smith S. M. Miller K. L. Salimi-Khorshidi G. Webster M. Beckmann C. F. Nichols T. E. (2011). Network modelling methods for FMRI. Neuroimage 54 875–891. 10.1016/j.neuroimage.2010.08.063 20817103
Soussia M. Rekik I. (2018). Unsupervised manifold learning using high-order morphological brain networks derived from T1-w MRI for autism diagnosis. Front. Neuroinform. 12 :70 . 10.3389/fninf.2018.00070 30459585
Spreng R. N. Mar R. A. Kim A. S. N. (2009). The common neural basis of autobiographical memory, prospection, navigation, theory of mind, and the default mode: a quantitative meta-analysis. J. Cogn. Neurosci. 21 489–510. 10.1162/jocn.2008.21029 18510452
Suk H.-I. Lee S.-W. Shen D. Initiative T. A. D. N. (2015). Latent feature representation with stacked auto-encoder for AD/MCI diagnosis. Brain Struct. Funct. 220 841–859. 10.1007/s00429-013-0687-3 24363140
Tibshirani R. (1996). Regression shrinkage and selection via the lasso. J. R. Stat. Soc. Ser. B 58 267–288. 10.1111/j.2517-6161.1996.tb02080.x
Uddin L. Q. (2015). Salience processing and insular cortical function and dysfunction. Nat. Rev. Neurosci. 16 55–61. 10.1038/nrn3857 25406711
Uddin L. Q. Supekar K. Lynch C. J. Khouzam A. Phillips J. Feinstein C. (2013). Salience network–based classification and prediction of symptom severity in children with autism. JAMA Psychiatry 70 869–879. 10.1001/jamapsychiatry.2013.104 23803651
Yan W. Calhoun V. Song M. Cui Y. Yan H. Liu S. (2019). Discriminating schizophrenia using recurrent neural network applied on time courses of multi-site FMRI data. EBioMedicine 47 543–552. 10.1016/j.ebiom.2019.08.023 31420302
Yang X. Kwitt R. Styner M. Niethammer M. (2017). Quicksilver: fast predictive image registration–a deep learning approach. Neuroimage 158 378–396. 10.1016/j.neuroimage.2017.07.008 28705497
Yerys B. E. Gordon E. M. Abrams D. N. Satterthwaite T. D. Weinblatt R. Jankowski K. F. (2015). Default mode network segregation and social deficits in autism spectrum disorder: evidence from non-medicated children. Neuroimage Clin. 9 223–232. 10.1016/j.nicl.2015.07.018 26484047
Ypma R. J. F. Moseley R. L. Holt R. J. Rughooputh N. Floris D. L. Chura L. R. (2016). Default mode hypoconnectivity underlies a sex-related autism spectrum. Biol. Psychiatry Cogn. Neurosci. Neuroimaging 1 364–371. 10.1016/j.bpsc.2016.04.006 27430030
Zhang T. Qi G.-J. Xiao B. Wang J. (2017). “Interleaved group convolutions,” in Proceedings of the IEEE International Conference on Computer Vision, Venice, 4373–4382.
Zhang X. Zhou X. Lin M. Sun J. (2018). “Shufflenet: An extremely efficient convolutional neural network for mobile devices,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, 6848–6856.
Zou H. Hastie T. (2005). Regularization and variable selection via the elastic net. J. R. Stat. Soc. Ser. B 67 301–320. 10.1111/j.1467-9868.2005.00503.x

