
==== Front
Comput Intell Neurosci
Comput Intell Neurosci
cin
Computational Intelligence and Neuroscience
1687-5265
1687-5273
Hindawi

10.1155/2021/4392702
Research Article
Multiset Canonical Correlations Analysis of Bidimensional Intrinsic Mode Functions for Automatic Target Recognition of SAR Images
https://orcid.org/0000-0003-1060-9787
Ding Yong dingyong@zjiet.edu.cn

Zhejiang Institute of Economics and Trade, Hangzhou 310018, China
Academic Editor: Mario Versaci

2021
25 8 2021
2021 43927027 7 2021
5 8 2021
Copyright © 2021 Yong Ding.
2021
https://creativecommons.org/licenses/by/4.0/ This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.
A novel feature generation algorithm for the synthetic aperture radar image is designed in this study for automatic target recognition. As an adaptive 2D signal processing technique, bidimensional empirical mode decomposition is employed to generate multiscale bidimensional intrinsic mode functions from the original synthetic aperture radar images, which could better capture the broad spectral information and details of the target. And, the combination of the original image and decomposed bidimensional intrinsic mode functions could promisingly provide more discriminative information for correct target recognition. To reduce the high dimension of the original image as well as bidimensional intrinsic mode functions, multiset canonical correlations analysis is adopted to fuse them as a unified feature vector. The resultant feature vector highly reduces the high dimension while containing the inner correlations between the original image and decomposed bidimensional intrinsic mode functions, which could help improve the classification accuracy and efficiency. In the classification stage, the support vector machine is taken as the basic classifier to determine the target label of the test sample. In the experiments, the 10-class targets in the moving and stationary target acquisition and recognition dataset are classified to investigate the performance of the proposed method. Several operating conditions and reference methods are setup for comprehensive evaluation.

Zhejiang Institute of Economics and Trade20KJTPY01 Project of All China Federation of Supply and Marketing CooperativesGX1556
==== Body
pmc1. Introduction

With the fast progress in SAR technologies, the massive radar measurements can hardly be interpreted by mere human intervention. In this context, the ATR system is developed, which comprises an integrated gallery of algorithms handling different tasks [1–3]. In the SAIP system [2], the famous three-stage processors were designed for SAR ATR, i.e., detection, discrimination, and classification. The detector locates the ROI by searching through a large-scene image, which may cover several square kilometers of ground. Afterwards, the discriminator operates the preliminary classification to distinguish the man-made objects and natural clutters. And, those ROIs assumed to be natural clutters are discarded. The classification procedure is performed finally to obtain target labels. As the core index of a SAR ATR system, the recognition performance is directly related to the used classification scheme. In the past decades, a rich collection of available feature extraction algorithms and classifiers were used for SAR ATR owing to the progress in modern pattern recognition techniques. The features are first extracted from the original SAR images before the classification, which are used to describe the target characteristics. The hand-crafted features for SAR ATR are obtained via inheriting the optical image processing techniques as well as considering the unique properties of SAR images, such as geometrical, transformation, and scattering features. Geometrical features are classical ones, which have been adopted in optical image processing for a long time [4–9]. Also, they are used to describe the geometric properties of SAR targets such as sizes and shapes. In [4], the descriptors of target outline, i.e., EFS, were extracted for classification. Amoon and Clemente generated the moments' features, i.e., Zernike [5] and Krawtchouk [6] moments, respectively, from the binary target regions segmented from SAR images, which were afterwards classified for target recognition. Ding et al. directly matched two binary target regions from the test sample and corresponding templates for SAR target recognition [7]. The transformation features are constructed via mathematical projection or signal processing to depict the intensity distribution or spectral properties of the original images [10–17]. The manifold learning algorithms are applied to SAR image feature extraction including linear and nonlinear ones. Typical examples of linear methods are LDA [10], PCA [10, 11], and NMF [12]. To handle the possible nonlinearity embedded in the data, some nonlinear manifold algorithms are also developed for feature extraction [13, 14]. Several signal processing techniques are extended to image processing such as wavelet analysis [15] and monogenic signal [16, 17]. In [16, 17], the researchers introduced monogenic signal analysis to feature extraction of SAR images, which is demonstrated highly effective for SAR ATR. Unlike the optical imaging mechanism, SAR images reflect the electromagnetic scatterings of the target [18]. In this sense, the scattering features, e.g., attributed scattering centers, are also sufficiently descriptive to distinguish different kinds of targets, which provide locally relevant descriptions of the target structures. The effectiveness of attributed scattering centers was experimentally investigated in some previous works [19–21]. The classifiers were also greatly enriched over the past decades. The SAIP system employed the template matching as the baseline classifier. In [22], Zhao and Principe introduced SVM into SAR ATR, which became one the most popular classifier in this field [4, 5, 23, 24]. The development in compressive sensing theory produced a robust classifier called SRC [25–28], which was used by Thiagarajan et al. to handle SAR ATR issues. Other classifiers such as AdaBoost [29], discriminative graphic model [30], modified polar mapping classifier [31], and HMM [9] were also investigated in the field of SAR ATR. As the deep learning methodology is getting mature, the deep classifiers for image interpretation, e.g., CNN [32–37], were validated highly effective for SAR ATR. However, the performance of CNN is highly dependable on the amount of available training samples. As a remedy, some CNN-based methods sought performance enhancement via proper data augmentations [34, 35].

In this paper, we propose a new way of generating discriminative features for SAR ATR via BEMD [38] and MCCA [39]. EMD adaptively decomposes 1D nonstationary signals, which was proposed by Huang et al. [40]. With no prior assumptions on the data properties, e.g., linearity or stationarity, EMD could keep its effectiveness and robustness under different conditions. As a natural extension, BEMD is capable of analyzing 2D signals, e.g., images, to learn more details. Via the sifting process, the generated BIMFs could provide complementary information for the original image, thus beneficial for image interpretation such as image denoising and image fusion [41–46]. Owing to these merits, we introduce BEMD to SAR feature extraction. In this way, much broader spectral properties of the original SAR images can be captured by the BIMFs for the following classification tasks. The BIMFs are also images with the same sizes of the original one. As a result, they significantly increase the computational burden of classification. As a feasible solution, some feature extraction algorithms could be used to reduce their dimensions independently, such as the down-sampling strategy for the multiscale monogenic components used in [16]. However, such strategies neglect the inner correlations between the original image and BIMFs, which are also beneficial to distinguish different classes. As a remedy, this study employs MCCA to fuse the original SAR image and decomposed BIMFs as a unified feature vector. CCA provides a statistical way to analyze the relationship between two random variables and find the best projection matrices to keep their correlations [47]. MCCA extends CCA to multiple random variables [48–52]. The resulted feature vector could significantly reduce the high dimension of the original image and BIMFs, while maintaining their inner correlations; thus, both the efficiency and effectiveness of the following classification can be promisingly enhanced. To perform the classification task, SVM is adopted as the classifier. SVM is one of the most popular classifiers used in SAR ATR. In the previous literature, SVM was employed to classify various kinds of features, e.g., target outline descriptors, region moments, and PCA feature vectors, with good performance. Therefore, we use SVM to classify the fused feature vector via MCCA to determine the target label of the test sample. The main contribution of this study is that a novel feature extraction method is proposed via the combination of BEMD and MCCA. The resulted features can maintain the discrimination in the original image and its BIMFs with a significantly low dimension. Therefore, the highly discriminative features can effectively improve the classification performance.

The remaining sections of this paper are organized as follows. Section 2 introduces the main methodology of the proposed method including BEMD, MCCA, and SVM. In Section 3, experimental investigations are conducted on the MSTAR dataset to evaluate the performance of the proposed method. Section 4 discusses the experimental results, and Section 5 draws some conclusions to summarize this paper. The acronyms used throughout the whole paper are summarized in Table 1.

2. Methodologies of the Proposed Method

2.1. BEMD

Different from stationary signals, nonstationary ones vary along with time thus much difficult to be reliably analyzed. Proposed by Huang et al. [41], EMD provides an adaptive way to decompose 1D signals. Unlike traditional signal decomposition algorithms, e.g., Fourier transform and wavelet analysis, EMD does not design predetermined basis functions but adaptively conducts the decomposition according to the properties of the data.

The IMFs are decomposed from EMD, which could be used to better analyze the time-frequency properties of the original image. Owing to its adaptivity and stability, EMD has been successfully applied to process different kinds of signals including biological, medical, and astronomy ones. Given an original signal as f(t), the decomposition process of EMD (often called “sifting”) is formulated as follows:(1) ft=∑k=1KJkt+rKt,

where Jk(t), k=1,2,…, K, represents the IMFs and rK denotes the residue.

To handle 2D signals such as images, Nunes et al. generalized the original EMD to BEMD. Similarly, via BEMD, an image is decomposed to several BIMFs to provide more detailed descriptions for it. According to Nunes et al. [38], for a given image I(i, j) with the sizes of M × N, the sifting process of BEMD is summarized as the following steps:Step 1. Identify the locations of the local extrema (including the maxima and minima) in I(i, j).

Step 2. Generate the envelopes according to the maxima and minima point sets via 2D interpolation, respectively. Afterwards, the local mean m is computed as the average of the upper (from the maxima points) and lower (from the minima points) envelopes.

Step 3. Subtract the local mean from the original image to get a proto-BIMF as r=I − m. If r is judged to be a BIMF, go to Step 4. On the contrary, it is used as the input to repeat Steps 1 and 2 until the latest proto-BIMF becomes a BIMF.

EMD sifting was iterated based on the Cauchy standard deviation criterion designed by Huang et al. For the case of BEMD, the criterion is updated as follows:(2) SD=∑i=1M∑j=1Nrki,j−rk−1i,j2rk−12i,j,

where rk(i, j) is the output in the kth iteration and rk−1(i, j) is the result from the (k − 1)th iteration. Based on the calculated SD value, the sifting process is judged to continue or stop. When the SD is larger than a predefined threshold ε, the sifting process continues by repeating Steps 1 to 3 with rk(i, j) as the input. On the contrary, rk(i, j) is judged to be a BIMF dk(i, j), which is output. According to the analysis in [35], we set ε=0.12 in this paper as a suitable choice of the threshold.

Step 4. Take the proto-BIMF r as the input and repeat Steps 1 to 3 to obtain the next BIMF until the process can be looped further.

After the sifting process, the original image can be represented as the combination of the BIMFs as follows:(3) Ii,j=∑k=1Kdki,j+rKi,j.

In equation (3), dk(i, j) denotes the kth BIMF and rK(i, j) represents the final residual. Among all the BIMFs, d1 describes the highest frequency of I and rK(i, j) represents the lowest frequential component. Therefore, the multiscale BIMFs could provide more comprehensive descriptions of the spectral properties of the original image. In addition, some details can be better embodied in the BIMFs, which cannot be remarkably reflected in the original image. Therefore, by proper use of the BIMFs, more information of the original image can be exploited for the interpretation tasks such as image denoising, image fusion, and image classification.

The advantages of BEMD inspires us to apply it to feature extraction of the SAR image for target recognition. Figure 1 intuitively displays the effectiveness of BEMD on the SAR target image chips from the MSTAR dataset, in which the first three BIMFs are shown. It can be observed that some details (e.g., the dominant scattering centers) in the original images can be better reflected in the first two BIMFs. In the third BIMF, the target related descriptions become blurry. As a result, it provides very limited discrimination for target recognition. Accordingly, only the first two BIMFs are used for target recognition in the following.

2.2. MCCA

CCA provides a statistical way to identify the association between two sets of random variables. As a generalization of CCA, MCCA is capable of analyzing the relationships among more sets of variables [48–52]. Assume that there are n random vectors Xi ∈ Rpi(i=1,2,…, n) and each of them is centralized to have E(Xi)=0, in which pi corresponds to the dimension of Xi. MCCA aims to find the linear combinations U=[U1, U2,…, Un] of XT=[X1T, X2T,…, XnT] given by(4) U1=α1TX1,VarU1=α1TS11α1,U1=α1TX1,VarU1=α1TS11α1, ⋮  ⋮   ⋮Un=αnTXn,VarUn=αnTSnnαn,

with the dispersion matrix as follows:(5) ΣU=α1TS11α1…α1TS1nαn⋮⋱⋮αnTSn1αn…αnTSnnαn,

where Sij represents the covariance matrix between Xi(i=1,2,…, n) and Xj(j=1,2,…, n) and Sii denotes the covariance matrix of vector Xi, and the vector αi ∈ Rpi. MCCA searches for the projection vectors α1, α2,…, αn, which maximize the correlations between the canonical variables U1, U2,…, Un. A measure to evaluated their correlations can be formulated in terms of the covariance matrices. Then, the measure of ΣU can be optimized by imposing special criteria with some constraints. One of the well-known criteria called “SUMCOR” is exhibited in the following equation:(6) α1,α2,…,αn=maxα1,α2,…,αn∑i=1n∑j=1nαiTSijαj,s.t. ∑i=1nαiTSiiαi=1.

To solve the problem in equation (6), the Lagrange multiplier technique can be used. It can be reformulated as equation (7) as solving the generalized eigenvalue problem:(7) S11…S1n⋮⋱⋮Sn1…Snnα1⋮αn=λS11…0⋮⋱⋮0…Snnα1⋮αn.

The optimal projections vectors for Xi are calculated as the conjugate eigenvectors αi1, αi2,…, αid corresponding to the first d=min(p1, p2,…, pn) eigenvalues λi1 ≥ λi2 ≥ ⋯≥λid in equation (7). Afterwards, the multiset canonical correlation vectors can be obtained as the following equation:(8) Ui=αi1TXi,αi2TXi,…,αidTXi,=αi1,αi2,…,αidTXi=WiTXi,

where Wi=[αi1, αi2,…,αi  d]pi×d(i=1,2,…, n) represents the projection matrix for each set of the random variables.

As discussed above, MCCA is capable of exploiting the within-set and between-set correlations among multiple vectors. Therefore, it can be used to fuse multiple random variables to reduce the redundancy, while maintaining the correlations. In this work, the serial fusion strategy (Peng et al. [48]) is adopted as the following equation:(9) Z=W1TX1+W2TX2+⋯+WnTXn,

where Z denotes the fused feature vector.

2.3. Target Recognition via SVM

SVM is chosen as the classifier to classify the generated features for target recognition. Since the first proposal by Vapnik et al. in 1995, SVM has been widely used in the pattern recognition problems. In 2001, it is introduced into SAR ATR by Zhao and Principe [22]. After then, SVM became one of the most popular classifiers in SAR ATR. According to the structural risk minimization principle, the preliminary SVM finds a hyperplane to separate patterns from two different classes. The decision function for a test sample x in SVM can be formulated as follows:(10) fx=∑i=1MwiyiKxi,x+b, αi≥0,∀i.

In equation (10), xi(i=1,…, M) denotes a support vector from the training samples and yi=±1 is its corresponding label. wi(i=1,…, M) and b (bias) are the parameters estimated during the training. K(·) represents the kernel function. With different choices of kernel functions, the trained SVM can handle different kinds of classification problems including linear and nonlinear ones. The polynomial kernel and RBF kernel are two typical kernel functions in SVM.

Researchers generalized the two-class SVM to multiclass one via the one-versus-one or one-versus-rest strategies. In this way, SVM can be directly used to classify many types of targets simultaneously. The famous LIBSVM [53] is an excellent toolbox to employ SVM for different usages, which is also used in this work. The multiclass SVM with the RBF kernel is adopted to perform the classification tasks based on the generated features.

The novel feature vectors generated by BEMD and MCCA are classified by SVM, as shown in Figure 2. Considering that the original image and BIMFs are all 2D matrices, they are reshaped as 1D vectors. Afterwards, MCCA is employed to fuse them as a unified feature vector. In detail, the following steps are implemented to perform the target recognition task.  Step 1: BEMD is used to extract the multiscale BIMFs from the training samples

  Step 2: the first two BIMFs and original image are taken as random variables to calculate the projection matrices using MCCA

  Step 3: each of the training samples and its corresponding BIMFs are fused based on the projection matrices from Step 2 to build a new training set

  Step 4: the fused feature vector of the test sample is obtained using BEMD and MCCA in the same way with the training samples

  Step 5: the feature vector of the test sample is classified by SVM to determine the target label

3. Experiments

3.1. Dataset and Methods for Comparison

The MSTAR dataset is employed for experimental evaluation in this study, which is widely used to develop and test SAR ATR algorithms. There are 10 representative ground targets contained in the dataset, whose optical appearances are displayed as Figure 3. SAR images of these targets are acquired by X-band sensors with the resolution of 0.3 m × 0.3 m. The aspect angles of each target cover full 0°∼360° at different depression angles, e.g., 15°, 17°, 30°, and 45°. In addition, some targets (e.g., BMP2 and T72) have several different configurations with some structural modifications.

As a necessary part of validating the performance of the proposed method, some baseline algorithms, which are widely used in SAR ATR, are compared. Their implementation details are itemed as follows.SVM + PCA [11]: the 80-dimension projection features extracted by PCA are used to represent the original SAR images. SVM is used as the classifier in the classification stage.

SVM + Zernike [5]: the Zernike moments of the binary target region are used as the basic features. SVM is used as the classifier in the classification stage.

SVM + EFS [4]: the descriptors of target outline, i.e., EFS, are used as the basic features. SVM is used as the classifier in the classification stage.

SRC [25]: random projection is adopted to reduce SAR images to 1024-dimension feature vectors. SVM is used as the classifier in the classification stage.

A-ConvNet [32]: the raw image intensities are directly used to represent the original images. The all-convolutional networks are taken as the classifier.

ESENet [33]: the ESENet is employed for SAR ATR.

JSRDeep [36]: the CNN is developed for feature learning to generate multilayer feature maps. Afterwards, the joint sparse representation is employed to classify the deep feature vectors.

Specifically, this paper employs the LIBSVM package developed by Lin et al. to perform the multiclass SVM classification. The SparseLab package [54] is employed to solve the sparse representation problem in SRC. And, CNN is trained on the TensorFlow platform.

The following experiments are conducted under both the SOC and EOCs to fully evaluate the effectiveness of the proposed method. At last, the performance of the proposed method and baseline algorithms are compared under different conditions to reach more intuitive evaluations on the proposed method.

3.2. Results under SOC

The proposed method is first investigated under SOC, which can be regarded as a preliminary verification. Table 2 shows the training and test samples from the 10 classes under SOC. Images at 17° depression angle are trained for the classification of 15°-depression-angle test samples. Specifically, the test images of BMP2 and T72 contain two more configurations (i.e., SNs) than their training sets, respectively. The confusion matrix is used to display the classification results by the proposed method as Figure 4, in which the X and Y coordinates represent the predicted and actual labels, respectively. It shows that each class can be classified with a recognition rate over 97.5%. And, the overall recognition rate of the 10 targets is averaged to be 99.03%. Because of the existing configuration differences between the training and test sets, BMP2 and T72 get the lowest two recognition rates among all the targets. According to the reported results, the high performance of the proposed method under SOC is quantitively validated. The BIMFs generated by BEMD are discriminative features, which could maintain the original target characteristics. Furthermore, MCCA combines the original image and its multiscale BIMFs as a unified feature vector, while keeping the inner discrimination. Finally, as a high-performance classification scheme, SVM makes decisions on the target labels based on the fused features. All these factors contribute to the excellent performance of the proposed method under SOC.

3.3. Recognition under EOC

EOCs are common situations in SAR ATR. As illustrated in Table 2, the same target may have different configurations. Moreover, due to the variations of backgrounds and sensors, other EOCs such as depression angle variance and noise corruption are also severe obstacles to the smooth implementation of SAR ATR systems. Consequently, in this part, three typical EOCs are setup to test the robustness of the proposed method. The first EOC is configuration variance and the training and test samples are displayed in Table 3. For BMP2 and T72, their test samples are from totally different SNs with the training ones. In addition, BDRM2 and BTR70 are used as two confuser targets in the training set, which further increases the difficulty of correct classification. The training and test samples for the second EOC are presented in Table 4 including SAR images of four targets (2S1, BDRM2, ZSU23/4, and T72 (SN_A64)) from different depression angles. Samples at 17° depression angle are trained for the classification of test samples at 30° and 45° depression angles, respectively. The relatively large depression angle variances between the training and test samples decrease their similarities in SAR images [55], as shown in Figure 5. The third EOC is noted as “noise corruption.” According to ideas in [16, 32], the noisy samples are obtained by adding random noises into the original test images in Table 2. In detail, a certain percentage of pixels in the original SAR images are replaced by impulses, i.e., pixels with large intensities. Figure 6 illustrates some noisy samples at different noise levels.

Based on the aforementioned EOC experimental setups, the robustness of the proposed method is tested. Table 5 displays the classification results of the proposed method under EOC-1. The test configurations of BMP2 and T72 can all be classified with recognition rates over 96%. And, the overall recognition rate is 98.08%. As shown in Figure 1, the multiscale BIMFs can better reflect the detailed information in the original SAR image. The local variations caused by configuration variances can be possibly embodied in the BIMFs. Therefore, the combination of the original image and BIMFs can help improve the classification accuracy under configuration variance. The classification results of the proposed method under EOC-2 are presented in Table 6. The average recognition rates at 30° and 45° depression angles achieved by the proposed method are 98.18% and 73.43%, respectively. The great decrease in recognition rate at 45° depression angle is probably caused by the low similarities between the training and test samples, which can be observed in Figure 5. Table 7 lists the average recognition rates at different noise levels, which shows the sensitivity of the recognition performance to random noise corruption. At 20% noise level, the overall recognition rate jumps to 62.12%, which is significantly lower than that on the original test samples. As a summary, the proposed method is investigated under both SOC and three typical EOCs. Compared with EOCs, the performance under SOC is much better because the test samples are much more similar with the training ones. In each EOC, the classification accuracy is closely related to the deterioration degree, which can be directly seen from the results in EOC-2 and EOC-3.

3.4. Performance Comparison with Baseline Algorithms

In this part, the proposed method is evaluated against the baseline algorithms under different operating conditions. Table 8 compares the performance of all the methods under SOC and EOC-1. The proposed method outperforms the others under both situations. In contrast to other three SVM-based methods, the proposed method achieves 2.11%, 2.89%, and 2.61% increments in the recognition rate over PCA, Zernike, and EFS features under SOC. And, the increments change to 3.21%, 2.94%, and 2.88% under EOC-1. The better performance achieved by the proposed method verifies the superior effectiveness of the features used in the classification stage. Therefore, the generated features via combination of BIMFs and MCCA are more discriminative than the projection features extracted by PCA, region features (e.g., Zernike moments), and target outlines (e.g., EFS descriptors). Figure 7 simultaneously compares the recognition rates of all the methods at different depression angles. With a similar trend occurred in the proposed method, the baseline algorithms all decrease sharply when the depression angle switches from 30° to 45°. At each depression angle, the proposed method gains the highest accuracy mainly because the generated features can better reflect the local variations caused by depression angle variance. Especially at 45° depression angle, the predominance of our approach becomes much more obvious and the least increment in the recognition rate is over 3.41% in comparison with the baseline algorithms. The performance of different methods under random noise corruptions is shown in Figure 8. Although decreasing with the aggravation of the noise level, the recognition rates of the proposed method keep higher than those of the baseline algorithms. So, the generated features are more robust than the other features according to the experimental results. The Zernike and EFS features perform relatively better among the baseline algorithms because the two types of features are extracted based on the binary target region, which keeps more robust than the intensity distributions under random noises. For the CNN-based methods, they are relatively more vulnerable to random noise corruption than the remaining ones. According to the deep learning classification scheme, the performance is highly attributed to the coverage of the training set. Under high levels of random noises, the operating conditions of the test samples cannot be covered by the original training samples. As a result, the classification accuracy decreases sharply. According to the results of performance comparison, the superiority of the proposed method under both SOC and EOCs is validated. And, the main reasonability of the good performance lies in the high discriminability of the generated features via the combination of BIMFs and MCCA.

4. Discussions

Some discussions are made in this section to further explain the experimental results on the MSTAR dataset, which quantitively verified the superior performance of the proposed method. The reasonability and feasibility of the results can be discussed from following aspects.The high discrimination capability of the generated feature via BEMD and MCCA: the multiscale BIMFs extracted by BEMD can capture broader spectral information of SAR images. As displayed in Figure 1, more details of the target can be reflected in the BIMFs than the original image. Therefore, by combining the original image and decomposed BIMFs, more discriminative information is available for the following classification. As a statistical information fusion algorithm, MCCA could fuse the original image and decomposed BIMFs as a unified feature vector with a low dimension, while maintaining the inner correlations among them. Therefore, the generated features via BEMD and MCCA are discriminative for SAR ATR.

The effectiveness and robustness of SVM for target classification: SVM is a classical and popular classifier in pattern recognition applications. Also, it has been widely employed in SAR ATR with good extension capability to different types of features. Therefore, it is a suitable classifier for the generated features in our study.

Experimental results under SOC: SOC refers to the operating condition, under which the test and training samples keep high similarities. Therefore, it is predictable that the recognition algorithms could perform well under SOC. The proposed method attains a recognition rate of 99.12% under SOC, higher than those of the baseline algorithms. The results validate the superiority of the proposed method.

Experimental results under EOCs: EOC refers to the operating condition, under which the test and training samples have notable differences. As a result, it is a much harder classification task than SOC problems. Three typical EOCs (configuration variance, depression angle variance, and random noise corruption) are setup to comprehensively examine the robustness of the proposed. Compared with the baseline algorithms, the proposed one achieves better performance under different types of EOCs.

5. Conclusions

This paper proposes a feature generation method for SAR images for target recognition. The multiscale BIMFs are first obtained from the original image by BEMD, which provide more detail information of the target. To enhance the classification accuracy and efficiency in the following stage, MCCA is employed to combine the original image and decomposed BIMFs as a unified feature vector. Because MCCA constructs the projection matrices by considering the relationship between different components, the resulted feature vector actually reflects the inner correlations of the original image and decomposed BIMFs. SVM is adopted as the classifier to classify the generated feature vector. According to the experimental investigations on the MSTAR dataset under different kinds of operating conditions, several conclusions could be reached as follows: (1) BEMD could extract discriminative representations, i.e., BIMFs, from SAR images. The multiscale BIMFs help capture broader spectral information and reflect more details of the original image. So, they can complement the original image to provide more discrimination to improve the recognition performance. (2) MCCA is an effective method to combine the original SAR image and decomposed BIMFs. The generated low-dimensional feature vector contains the inner correlations between different components. (3) As an overall evaluation, the proposed achieves better performance than some baseline SAR ATR methods. Especially, the robustness of the proposed method under several typical EOCs including configuration variance, depression angle variance, and random noise corruption is much more superior. In the future, in order to better handle the uncertainties caused by EOCs, feature extraction, etc., the fuzzy theory [56, 57] may be a potential way to further improve the recognition performance.

Acknowledgments

This work was funded by 2020 Science and Technology Commissioner Training Project of Zhejiang Institute of Economics and Trade “Quzhou Campus Food Direct Supply Technology Service Project” (20KJTPY01) and Project of All China Federation of Supply and Marketing Cooperatives “Exploration and Research on the Incubation Mode of New Rural E-Commerce Practical Talents under the ‘New Normal'” (GX1556).

Data Availability

The MSTAR dataset is publicly available.

Conflicts of Interest

The author declares that there are no conflicts of interest regarding the publication of this paper.

Figure 1 Feature extraction of the SAR image by BEMD.

Figure 2 Implementation of target recognition based on the features generated by BEMD and MCCA.

Figure 3 Optical appearances of the 10 targets in MSTAR dataset. (a) BMP2, (b) BTR70, (c) T72, (d) T62, (e) BRDM2, (f) BTR60, (g) ZSU23/4, (h) D7, (i) ZIL131, and (j) 2S1.

Figure 4 Classification results of the proposed method under SOC.

Figure 5 Comparison of SAR images from different depression angles. (a) 17°. (b) 30°. (c) 45°.

Figure 6 Exemplar images with different levels of random noises under EOC-3: noise corruption. (a) 0%; (b) 5%; (c) 10%; (d) 15%; (e) 20%.

Figure 7 Comparison under EOC-2.

Figure 8 Comparison under EOC-3.

Table 1 The acronyms used in this paper.

Full name	Acronyms	
Synthetic aperture radar	SAR	
Automatic target recognition	ATR	
Semiautomated image intelligence processing	SAIP	
Region of interests	ROI	
Elliptical Fourier series	EFS	
Linear discriminant analysis	LDA	
Principal component analysis	PCA	
Nonnegative matrix factorization	NMF	
Support vector machine	SVM	
Sparse representation-based classification	SRC	
Adaptive boosting	AdaBoost	
Hidden Markov model	HMM	
Convolutional neural networks	CNN	
Bidimensional empirical mode decomposition	BEMD	
Multiset canonical correlations analysis	MCCA	
Empirical mode decomposition	EMD	
Canonical correlations analysis	CCA	
Bidimensional intrinsic mode function	BIMF	
Intrinsic mode function	IMF	
Moving and stationary target acquisition and recognition	MSTAR	
Radial basis function	RBF	
Standard operating condition	SOC	
Extended operating condition	EOC	
Serial number	SN	

Table 2 Training and test samples under SOC.

 	BMP2	BTR70	T72	T62	BDRM2	BTR60	ZSU23/4	D7	ZIL131	2S1	
Training	233 (SN_9563)	233	232 (SN_132)	299	298	256	299	299	299	299	
	
Test	195 (SN_9563)	196	196 (SN_132)	273	274	195	274	274	274	274	
196 (SN_9566)	195 (SN_812)	
196 (SN_C21)	191 (SN_S7)	

Table 3 Training and test samples for EOC-1: configuration variance.

 	BMP2	BDRM2	BTR70	T72	
Training (17°)	233 (SN_9563)	298	233	232 (SN_132)	
	
Test (15°, 17°)	428 (SN_9566)	0	0	426 (SN_812)	
429 (SN_C21)	
573 (SN_A04)	
573 (SN_A05)	
573 (SN_A07)	

Table 4 Training and test samples for EOC-2: depression angle variance.

 	Depr.	2S1	BDRM2	ZSU23/4	T72 (SN_A64)	
Training	17°	299	298	299	299	
	
Test	30°	288	287	288	288	
45°	303	303	303	303	

Table 5 Results of the proposed method under EOC-1.

Class	Configuration	BMP2	BRDM2	BTR70	T72	Recognition rate (%)	
BMP2	SN_9566	420	3	2	3	98.13	
SN_C21	424	1	1	3	98.83	
	
T72	SN_812	1	3	3	417	98.36	
SN_A04	5	1	3	564	98.43	
SN_A05	7	4	2	560	97.73	
SN_A07	9	1	4	559	97.56	
SN_A10	8	3	3	553	97.53	
	
Overall	 	 	 	 	 	98.08	

Table 6 Results of the proposed method under EOC-2.

Depr.	Actual	Predicted	Recognition rate (%)	Overall (%)	
2S1	BRDM2	ZSU23/4	T72	
30°	2S1	283	1	3	1	98.26	98.18	
BDRM2	2	284	0	1	98.95	
ZSU23/4	4	1	281	2	97.57	
T72	2	4	0	282	97.92	
	
45°	2S1	216	47	23	17	71.29	73.43	
BDRM2	29	234	21	19	77.23	
ZSU23/4	18	43	213	29	70.30	
T72	20	25	31	227	74.92	

Table 7 Results of the proposed method under EOC-3.

Noise level (%)	5	10	15	20	
Recognition rate (%)	93.54	86.67	75.38	62.12	

Table 8 Comparison with baseline algorithms under SOC and EOC-1.

Method	SOC (%)	EOC-1 (%)	
Proposed	99.03	98.08	
SVM + PCA	96.52	94.87	
SVM + Zernike	95.84	95.14	
SVM + EFS	96.02	95.20	
SRC	95.64	94.22	
A-ConvNet	98.24	96.70	
ESENet	98.76	97.23	
JSRDeep	98.92	97.64
==== Refs
1 El-Darymli K. Gill E. W. Mcguire P. Power D. Moloney C. Automatic target recognition in synthetic aperture radar imagery: a state-of-the-art review IEEE Access 2016 4 6014 6058 10.1109/access.2016.2611492 2-s2.0-84994791414
2 Novak L. M. Owirka G. J. Brower W. S. The automatic target‐recognition system in SAIP Lincoln Laboratory Journal 1997 10 2 187 202
3 Keydel E. R. Lee S. W. Moore J. T. MSTAR extended operating conditions: a tutorial Algorithms for Synthetic Aperture Radar Imagery III 1996 2757 1 5
4 Anagnostopulos G. C. SVM-based target recognition from synthetic aperture radar images using target region outline descriptors Nonlinear Analysis 2009 71 12 e2934 e2939 10.1016/j.na.2009.07.030 2-s2.0-72149124220
5 Amoon M. Rezai‐rad G. A. Automatic target recognition of synthetic aperture radar (SAR) images based on optimal selection of Zernike moments features IET Computer Vision 2014 8 2 77 85 10.1049/iet-cvi.2013.0027 2-s2.0-84897057812
6 Clemente C. Pallotta L. Gaglione D. De Maio A. Soraghan J. J. Automatic target recognition of military vehicles with Krawtchouk moments IEEE Transactions on Aerospace and Electronic Systems 2017 53 1 493 500 10.1109/taes.2017.2649160 2-s2.0-85019054605
7 Ding B. Wen G. Ma C. Yang X. Target recognition in synthetic aperture radar images using binary morphological operations Journal of Applied Remote Sensing 2016 10 4 046006 10.1117/1.jrs.10.046006 2-s2.0-84994474443
8 Papson S. Narayanan R. M. Classification via the shadow region in SAR imagery IEEE Transactions on Aerospace and Electronic Systems 2017 48 2 969 980 10.1109/TAES.2012.6178042 2-s2.0-84859830841
9 Park J.-I. Park S.-H. Kim K.-T. New discrimination features for SAR automatic target recognition IEEE Geoscience and Remote Sensing Letters 2013 10 3 476 480 10.1109/lgrs.2012.2210385 2-s2.0-84870552741
10 Mishra K. Validation of PCA and LDA for SAR ATR Proceedings of the TENCON 2008–2008 IEEE Region 10 Conference November 2008 Hyderabad, India 1 6 10.1109/tencon.2008.4766807 2-s2.0-63049135365
11 He Z. Lu J. Kuang G. A fast SAR target recognition approach using PCA features Proceedings of the Fourth International Conference on Image and Graphics (ICIG 2007) August 2007 Chengdu, China 1 5 10.1109/icig.2007.134 2-s2.0-47349089366
12 Cui Z. Cao Z. Yang J. Feng J. Ren H. Target recognition in synthetic aperture radar images via non‐negative matrix factorisation IET Radar, Sonar & Navigation 2015 9 9 1376 1385 10.1049/iet-rsn.2014.0407 2-s2.0-84949786829
13 Huang Y. Yanga J. Wang B. Liu X. Neighborhood geometric center scaling embedding for SAR ATR IEEE Transactions on Aerospace and Electronic Systems 2014 50 1 180 192 10.1109/taes.2013.110769 2-s2.0-84900863340
14 Yu M. Dong G. Fan H. Kuang G. SAR target recognition via local sparse representation of multi-manifold regularized low-rank approximation Remote Sensing 2018 10 2 211 10.3390/rs10020211 2-s2.0-85042536761
15 Wang H. Li S. Zhou Y. Chen S. SAR automatic target recognition using a roto-translational invariant wavelet-scattering convolution network Remote Sensing 2018 10 4 501 10.3390/rs10040501 2-s2.0-85045979082
16 Dong G. Kuang G. Wang N. Zhao L. Lu J. SAR target recognition via joint sparse representation of monogenic signal IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 2015 8 7 3316 3328 10.1109/jstars.2015.2436694 2-s2.0-85027948718
17 Ning C. Liu W. Zhang G. Yin J. Ji X. Enhanced synthetic aperture radar automatic target recognition method based on novel features Applied Optics 2016 55 31 8893 8904 10.1364/ao.55.008893 2-s2.0-84994462673 27828291
18 Potter L. C. Moses R. L. Attributed scattering centers for SAR ATR IEEE Transactions on Image Processing 1997 6 1 79 91 10.1109/83.552098 2-s2.0-0030779418 18282880
19 Ding B. Wen G. Zhong J. Ma C. Yang X. Robust method for the matching of attributed scattering centers with application to synthetic aperture radar automatic target recognition Journal of Applied Remote Sensing 2016 10 1 016010 10.1117/1.jrs.10.016010 2-s2.0-84959421948
20 Ding B. Wen G. Ma C. Yang X. Decision fusion based on physically relevant features for SAR ATR IET Radar, Sonar & Navigation 2017 11 4 682 690 10.1049/iet-rsn.2016.0357 2-s2.0-85018651424
21 Ding B. Wen G. Huang X. Ma C. Yang X. Target recognition in synthetic aperture radar images via matching of attributed scattering centers IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 2017 10 7 3334 3347 10.1109/jstars.2017.2671919 2-s2.0-85015905310
22 Zhao Q. Principe J. C. Support vector machines for SAR automatic target recognition IEEE Transactions on Aerospace and Electronic Systems 2001 37 2 643 654 10.1109/7.937475 2-s2.0-0035300682
23 Liu H. Li S. Decision fusion of sparse representation and support vector machine for SAR image target recognition Neurocomputing 2013 113 97 104 10.1016/j.neucom.2013.01.033 2-s2.0-84877622257
24 Wagner S. A. SAR ATR by a combination of convolutional neural network and support vector machines IEEE Transactions on Aerospace and Electronic Systems 2016 52 6 2861 2872 10.1109/taes.2016.160061 2-s2.0-85013498768
25 Thiagaraianm J. Ramamurthy K. Knee P. Sparse representations for automatic target classification in SAR images Proceedings of the 4th International Symppsium on Communications, Control and Signal Processing March 2010 Limassol, Cyprus 1 4 10.1109/ISCCSP.2010.5463416 2-s2.0-77953847761
26 Song S. Xu B. Yang J. SAR target recognition via supervised discriminative dictionary learning and sparse representation of the SAR-Hog feature Remote Sensing 2016 8 8 683 10.3390/rs8080683 2-s2.0-84983786211
27 Song H. Ji K. Zhang Y. Xing X. Zou H. Sparse representation-based SAR image target classification on the 10-class MSTAR data set Applied Sciences 2016 6 1 p. 26 10.3390/app6010026 2-s2.0-84973661549
28 Karine A. Toumi A. Khenchaf A. El Hassouni M. Target recognition in radar images using weighted statistical dictionary-based sparse representation IEEE Geoscience and Remote Sensing Letters 2017 14 12 2403 2407 10.1109/lgrs.2017.2766225 2-s2.0-85035143483
29 Sun Y. Liu Z. Todorovic S. Li J. Adaptive boosting for SAR automatic target recognition IEEE Transactions on Aerospace and Electronic Systems 2007 43 1 112 125 10.1109/taes.2007.357120 2-s2.0-34248636550
30 Srinivas U. Monga V. Raj R. G. SAR automatic target recognition using discriminative graphical models IEEE Transactions on Aerospace and Electronic Systems 2014 50 1 591 606 10.1109/taes.2013.120340 2-s2.0-84900565951
31 Park J.-I. Kim K.-T. Modified polar mapping classifier for SAR automatic target recognition IEEE Transactions on Aerospace and Electronic Systems 2014 50 2 1092 1107 10.1109/taes.2013.120378 2-s2.0-84904740760
32 Chen S. Wang H. Xu F. Jin Y. Target classification using the deep convolutional networks for SAR images IEEE Transaction on Geoscience and Remote Sensing 2016 47 6 1685 1697 10.1109/tgrs.2016.2551720 2-s2.0-84992303973
33 Wang L. Bai X. Zhou F. SAR ATR of ground vehicles based on ESENet Remote Sensing 2019 11 11 1316 10.3390/rs11111316 2-s2.0-85067389277
34 Malmgren-Hansen D. Kusk A. Dall J. Nielsen A. A. Engholm R. Skriver H. Improving SAR automatic target recognition models with transfer learning from simulated data IEEE Geoscience and Remote Sensing Letters 2017 14 9 1484 1488 10.1109/lgrs.2017.2717486 2-s2.0-85023192136
35 Lv J. Liu Y. Data augmentation based on attributed scattering centers to train robust CNN for SAR ATR IEEE Access 2019 7 25459 25473 10.1109/access.2019.2900522 2-s2.0-85066834969
36 Lv J. Exploiting multi-level deep features via joint sparse representation with application to SAR target recognition International Journal of Remote Sensing 2020 41 1 320 338 10.1080/01431161.2019.1641246
37 Zhu X. X. Tuia D. Mou L. Deep learning in remote sensing: a comprehensive review and list of resources IEEE Geoscience and Remote Sensing Magazine 2017 5 4 8 36 10.1109/mgrs.2017.2762307 2-s2.0-85040367775
38 Nunes J. C. Guyot S. Delechelle E. Texture analysis based on local analysis of the bidimensional empirical mode decomposition Machine Vision and Applications 2005 16 3 177 188 10.1007/s00138-004-0170-5 2-s2.0-17744387148
39 Hardoon D. R. Szedmak S. Shawe-Taylor J. Canonical correlation analysis: an overview with application to learning methods Neural Computation 2004 16 12 2639 2664 10.1162/0899766042321814 2-s2.0-10044285992 15516276
40 Nunes J. C. Deechelle E. Empirical mode decomposition: application on signal and image processing Advances in Adaptive Data Analysis 2009 1 1 125 175 10.1142/s1793536909000059 2-s2.0-77957826217
41 Huang N. E. Shen Z. Long S. R. The empirical mode decomposition and the Hilbert spectrum for nonlinear and non-stationary time series analysis Proceedings of the Royal Society of London. Series A: Mathematical, Physical and Engineering Sciences 1998 454 1971 903 995 10.1098/rspa.1998.0193 2-s2.0-5444236478
42 Qin Y. Qiao L. Wang Q. Ren X. Zhu C. Bidimensional empirical mode decomposition method for image processing in sensing system Computers & Electrical Engineering 2018 68 215 224 10.1016/j.compeleceng.2018.03.033 2-s2.0-85045255493
43 Chen W.-K. Lee J.-C. Han W.-Y. Shih C.-K. Chang K.-C. Iris recognition based on bidimensional empirical mode decomposition and fractal dimension Information Sciences 2013 221 439 451 10.1016/j.ins.2012.09.021 2-s2.0-84884202130
44 Nunes J. C. Bouaoune Y. Delechelle E. Niang O. Bunel P. Image analysis by bidimensional empirical mode decomposition Image and Vision Computing 2003 21 12 1019 1026 10.1016/s0262-8856(03)00094-5 2-s2.0-0141887031
45 Lahmiri S. Image denoising in bidimensional empirical mode decomposition domain: the role of Student’s probability distribution function Healthcare Technology Letters 2016 3 1 67 71 10.1049/htl.2015.0007 2-s2.0-84995917098 27222723
46 Riffi J. Mohamed Mahraz A. Tairi H. Medical image registration based on fast and adaptive bidimensional empirical mode decomposition IET Image Processing 2013 7 6 567 574 10.1049/iet-ipr.2012.0034 2-s2.0-84884804492
47 Hotelling H. Relations between two sets of variates Biometrika 1936 28 3/4 321 377 10.2307/2333955
48 Peng J. Li Q. Abd El-Latif A. A. Niu X. Linear discriminant multi-set canonical correlations analysis (LDMCCA): an efficient approach for feature fusion of finger biometrics Multimedia Tools and Applications 2015 74 13 4469 4486 10.1007/s11042-013-1817-x 2-s2.0-84934301245
49 Nielsen A. A. Multiset canonical correlations analysis and multispectral, truly multitemporal remote sensing data IEEE Transactions on Image Processing 2002 11 3 293 305 10.1109/83.988962 2-s2.0-0036505017 18244632
50 Yuan Y. Sun Q. Multiset canonical correlations using globality preserving projections with applications to feature extraction and recognition IEEE Transactions on Neural Networks and Learning Systems 2014 25 6 1131 1146 10.1109/tnnls.2013.2288062 2-s2.0-84901447705
51 Liang Sun L. Jieping Ye S. Ye J. Canonical correlation analysis for multilabel classification: a least-squares formulation, extensions, and analysis IEEE Transactions on Pattern Analysis and Machine Intelligence 2011 33 1 194 200 10.1109/tpami.2010.160 2-s2.0-78649325096 20733223
52 Correa N. M. Li Y.-O. Adali T. Calhoun V. D. Canonical correlation analysis for feature-based fusion of biomedical imaging modalities and its application to detection of associative networks in schizophrenia IEEE Journal of Selected Topics in Signal Processing 2008 2 6 998 1007 10.1109/jstsp.2008.2008265 2-s2.0-60549115613 19834573
53 Chang C. Lin C. LIBSVM: a library for support vector machines ACM Transactions on Intelligent Systems and Technology 2011 2 3 296 389 10.1145/1961189.1961199 2-s2.0-79955702502
54 SparseLab 2.0 2019 https://sparselab.stanford.edu
55 Ravichandran B. Gandhe A. Smith R. Mehra R. Robust automatic target recognition using learning classifier systems Information Fusion 2007 8 3 252 265 10.1016/j.inffus.2006.03.001 2-s2.0-33947672844
56 Postorino M. N. Versaci M. A geometric fuzzy-based approach for airport clustering Advances in Fuzzy System 2014 2014 201243 10.1155/2014/201243 2-s2.0-84934943341
57 Versaci M. Morabito F. C. Angiulli G. Adaptive image contrast enhancement by computing distances into a 4-Dimensional fuzzy unit hypercube IEEE Access 2017 5 26922 26931 10.1109/access.2017.2776349 2-s2.0-85035795365

